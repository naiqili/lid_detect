{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.dataset import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fac82fdea30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "ds_train10 = torchvision.datasets.MNIST('./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]));\n",
    "print(ds_train10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(ds_train10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54051\n"
     ]
    }
   ],
   "source": [
    "ln = len(ds_train10);\n",
    "train_y = np.zeros(ln);\n",
    "for idx, (data, target) in enumerate(ds_train10):\n",
    "    train_y[idx] = target.numpy()\n",
    "\n",
    "idx = np.where(train_y <= 8)[0]\n",
    "ds_train9 = Subset(ds_train10, idx)\n",
    "print(len(ds_train9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48200\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(train_y <= 7)[0]\n",
    "ds_train8 = Subset(ds_train10, idx)\n",
    "print(len(ds_train8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test10 = torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(ds_test10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8991\n"
     ]
    }
   ],
   "source": [
    "ln = len(ds_test10);\n",
    "test_y = np.zeros(ln);\n",
    "for idx, (data, target) in enumerate(ds_test10):\n",
    "    test_y[idx] = target.numpy()\n",
    "\n",
    "idx = np.where(test_y <= 8)[0]\n",
    "ds_test9 = Subset(ds_test10, idx)\n",
    "print(len(ds_test9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8017\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(test_y <= 7)[0]\n",
    "ds_test8 = Subset(ds_test10, idx)\n",
    "print(len(ds_test8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader10 = torch.utils.data.DataLoader(\n",
    "    ds_train10,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader10 = torch.utils.data.DataLoader(\n",
    "    ds_test10,\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 49 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader10)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "example_data.shape\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(50):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader8 = torch.utils.data.DataLoader(\n",
    "    ds_train8,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader8 = torch.utils.data.DataLoader(\n",
    "    ds_test8,\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 49 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader8)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "\n",
    "example_data.shape\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(50):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30596\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(train_y <= 4)[0]\n",
    "ds_train5 = Subset(ds_train10, idx)\n",
    "print(len(ds_train5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5139\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(test_y <= 4)[0]\n",
    "ds_test5 = Subset(ds_test10, idx)\n",
    "print(len(ds_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader5 = torch.utils.data.DataLoader(\n",
    "    ds_train5,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader5 = torch.utils.data.DataLoader(\n",
    "    ds_test5,\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12665\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(train_y <= 1)[0]\n",
    "ds_train2 = Subset(ds_train10, idx)\n",
    "print(len(ds_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2115\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(test_y <= 1)[0]\n",
    "ds_test2 = Subset(ds_test10, idx)\n",
    "print(len(ds_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader2 = torch.utils.data.DataLoader(\n",
    "    ds_train2,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    ds_test2,\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network using 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, train_loader, epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()            \n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), './results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network, test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()            \n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Net().cuda()\n",
    "optimizer = optim.SGD(net1.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader10.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3111, Accuracy: 956/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.296428\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.275135\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.290798\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.282064\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.258089\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.213377\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.210812\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.159625\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.076725\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.050290\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.919861\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.947154\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.758680\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.462732\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.574901\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.556828\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.358212\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.291479\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.280410\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.277229\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.308324\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.015913\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.025623\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.074849\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.741426\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.801734\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.763562\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.916458\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.944048\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.814832\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.818485\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.978244\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.760019\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.577024\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.723613\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.797211\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.686379\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.661267\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.644604\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.647441\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.648140\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.662356\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.589510\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.551239\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.830040\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.618606\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.534584\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.682513\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.686321\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.583150\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.912355\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.542294\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.393084\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.395951\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.600859\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.605380\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.439086\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.464384\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.795138\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.467232\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.379787\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.379007\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.508491\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.447111\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.521136\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.695111\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.476410\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.556339\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.517720\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.527631\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.339316\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.516312\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.560687\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.337115\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.443773\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.508009\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.650681\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.752692\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.691802\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.592376\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.506953\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.463697\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.400113\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.419800\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.371261\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.391785\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.636782\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.514687\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.326159\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.285463\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.414964\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.355005\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.439178\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.273592\n",
      "\n",
      "Test set: Avg. loss: 0.1765, Accuracy: 9472/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.520088\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.253862\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.267326\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.352786\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.453673\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.486581\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.485173\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.318915\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.366181\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.529433\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.423549\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.601731\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.344543\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.388404\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.456412\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.412187\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.619169\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.513397\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.250908\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.392966\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.243193\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.246909\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.455916\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.208360\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.334172\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.319938\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.236887\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.238457\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.501826\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.382048\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.498156\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.433150\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.288271\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.356007\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.583433\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.331204\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.229191\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.402938\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.326276\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.367282\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.415168\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.422994\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.406749\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.420138\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.213106\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.516101\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.298303\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.354013\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.198423\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.387806\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.319410\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.448150\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.414148\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.301019\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.320064\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.289879\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.417323\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.376329\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.226505\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.376860\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.198500\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.346880\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.312764\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.431920\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.233393\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.339553\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.331647\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.289751\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.431618\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.350002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.278168\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.439769\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.217291\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.258742\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.265625\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.213628\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.313699\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.251113\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.186378\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.455516\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.274573\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.302203\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.222525\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.245448\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.493234\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.495537\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.373417\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.215059\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.200566\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.423534\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.332534\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.269204\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.309091\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.192906\n",
      "\n",
      "Test set: Avg. loss: 0.1161, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.314261\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.324782\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.355188\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.246325\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.263608\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.276694\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.350033\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.416056\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.209097\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.165673\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.250029\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.404920\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.227504\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.361764\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.426461\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.313792\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.247018\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.239493\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.408884\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.640995\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.076577\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.247619\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.267913\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.418921\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.147289\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.289240\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.245274\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.285021\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.362075\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.277580\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.239292\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.229244\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.349333\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.410480\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.305458\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.179228\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.205975\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.365922\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.316004\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.267440\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.264206\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.228817\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.505664\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.211607\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.327224\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.267466\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.236977\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.292757\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.335345\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.115842\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.239779\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.161688\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.340200\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.300434\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.186593\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.347181\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.324403\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.518653\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.151185\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.224485\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.387928\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.262151\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.130385\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.133013\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.334191\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.157135\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.193581\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.336871\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.193506\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.246527\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.443405\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.304672\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.327669\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.303423\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.178482\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.228087\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.102686\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.334732\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.206721\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.215812\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.219619\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.344315\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.392475\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.312541\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.279461\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.412644\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.272314\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.279230\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.149919\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.275839\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.358075\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.369055\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.339248\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.165161\n",
      "\n",
      "Test set: Avg. loss: 0.0902, Accuracy: 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.339799\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.110301\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.173920\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.208128\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.170454\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.543395\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.130080\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.207226\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.278699\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.158952\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.250982\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.377914\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.466713\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.224756\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.378635\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.193292\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.156525\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.246255\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.556860\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.416481\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.286166\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.400160\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.288908\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.111409\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.225853\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.293735\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.247169\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.189516\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.122194\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.109866\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.310687\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.238842\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.619609\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.334187\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.314447\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.289722\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.401514\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.361206\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.398268\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.243558\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.146588\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.315016\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.225920\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.286327\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.269631\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.110679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.380068\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.149398\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.274498\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.291689\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.339421\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.226408\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.271932\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.328961\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.332856\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.337463\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.212005\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.345667\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.058675\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.305580\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.159506\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.321072\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.261939\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.378035\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.208678\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.431637\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.199144\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.289297\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.233961\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.159530\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.358694\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.094580\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.203900\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.298008\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.222242\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.248070\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.355300\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.317884\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.228633\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.184910\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.252473\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.078049\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.259585\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.222341\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.279097\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.339799\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.115093\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.174757\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.160893\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.296402\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.333116\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.082894\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.359358\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.228086\n",
      "\n",
      "Test set: Avg. loss: 0.0749, Accuracy: 9760/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.155105\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.084926\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.346387\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.109063\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.130008\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.108213\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.236642\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.360335\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.380174\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.258226\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.096693\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.257113\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.296871\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.181286\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.384628\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.217443\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.110507\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.192498\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.208078\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.098305\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.214016\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.222483\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.307751\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.173320\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.164605\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.148095\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.186393\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.247289\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.238618\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.232561\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.278122\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.209725\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.165740\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.224075\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.106937\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.197660\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.312363\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.392146\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.226711\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.226655\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.270365\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.109277\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.221682\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.230825\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.231832\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.365822\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.289398\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.133185\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.218713\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.304694\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.199429\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.100663\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.269360\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.300014\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.113563\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.159535\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.330515\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.248865\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.275554\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.099238\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.149538\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.283332\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.069060\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.177534\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.331812\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.116129\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.188362\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.432145\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.307836\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.121785\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.269419\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.088228\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.382377\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.130285\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.152708\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.327428\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.177863\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.279767\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.354753\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.221903\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.135490\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.259834\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.173927\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.165129\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.322619\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.412343\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.124356\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.282746\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.306904\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.077965\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.208386\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.080176\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.170409\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.197491\n",
      "\n",
      "Test set: Avg. loss: 0.0681, Accuracy: 9777/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.247709\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.172963\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.294730\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.297724\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.250866\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.369711\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.203204\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.134014\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.098832\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.093354\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.327953\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.207318\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.139937\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.232598\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.215772\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.228195\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.102535\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.191091\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.223165\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.339698\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.227317\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.300516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.465941\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.252868\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.120264\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.134791\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.137490\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.254618\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.502740\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.134832\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.412872\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.099467\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.129690\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.062403\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.307494\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.153802\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.324872\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.196463\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.264732\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.133931\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.470937\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.344596\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.258461\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.088655\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.132008\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.224545\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.213638\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.283065\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.199064\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.123062\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.382903\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.235748\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.097440\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.178233\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.226602\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.437706\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.114407\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.229368\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.439491\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.145852\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.170325\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.170918\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.485234\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.242301\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.281718\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.230453\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.228435\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.221079\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.253199\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.178526\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.148581\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.098097\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.184719\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.158918\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.255133\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.311121\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.182967\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.400957\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.166704\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.170060\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.363521\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.159741\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.186561\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.088625\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.207078\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.109036\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.077976\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.246726\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.318050\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.365802\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.111556\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.230885\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.162511\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.287442\n",
      "\n",
      "Test set: Avg. loss: 0.0644, Accuracy: 9786/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.100236\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.087230\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.112681\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.171713\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.338018\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.397210\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.206801\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.099104\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.331196\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.140717\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.311067\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.143551\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.300724\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.233251\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.181721\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.180541\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.174773\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.174981\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.128126\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.247511\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.165777\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.323999\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.149340\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.107689\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.268362\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.315149\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.146562\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.126739\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.224899\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.116158\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.356423\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.108004\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.202193\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.259755\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.217746\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.188172\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.228621\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.235728\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.174059\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.247285\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.282636\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.247217\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.169541\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.262255\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.262788\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.201123\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.224056\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.097368\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.115538\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.159964\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.258379\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.128878\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.063205\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.102465\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.199139\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.097689\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.201792\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.234906\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.231686\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.176893\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.108012\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.245990\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.418916\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.226459\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.285442\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.192649\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.076898\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.235320\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.375144\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.111469\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.126083\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.100263\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.044297\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.215176\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.125817\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.311701\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.216516\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.225914\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.167234\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.106902\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.195077\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.110363\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.196489\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.148717\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.099121\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.212708\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.382192\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.142022\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.098383\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.173268\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.279564\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.152868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.205250\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.074272\n",
      "\n",
      "Test set: Avg. loss: 0.0593, Accuracy: 9816/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.195859\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.183627\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.131834\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.069188\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.254059\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.077695\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.283479\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.224602\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.148367\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.232872\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.252813\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.219346\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.188102\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.243118\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.243987\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.075515\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.217166\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.137308\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.122748\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.131824\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.112568\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.191841\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.478123\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.336827\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.218344\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.125975\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.151924\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.177826\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.164730\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.081578\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.175606\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.196779\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.192868\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.130051\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.119773\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.210665\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.118113\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.362806\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.051317\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.131481\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.231524\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.296596\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.141739\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.232905\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.038360\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.115911\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.302940\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.138168\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.063589\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.137951\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.165648\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.188700\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.181345\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.205023\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.133612\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.082785\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.187446\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.135976\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.218381\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.128075\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.129748\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.288460\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.188007\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.349514\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.266871\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.229377\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.349697\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.131740\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.101804\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.149093\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.082566\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.091057\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.163399\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.217538\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.146057\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.128090\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.120640\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.130083\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.122641\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.122239\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.176304\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.109321\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.341900\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.278768\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.285733\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.107691\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.164375\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.166051\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.067364\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.189297\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.124508\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.262848\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.330982\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.172160\n",
      "\n",
      "Test set: Avg. loss: 0.0569, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.185907\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.194102\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.211391\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.062013\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.248813\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.129168\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.131990\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.343215\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.101587\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.103351\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.305406\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.106514\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.255825\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.306508\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.216042\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.290034\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.117371\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.154095\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.083285\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.229213\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.143439\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.153410\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.292036\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.149533\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.222718\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.069049\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.200355\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.150314\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.152647\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.082392\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.166856\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.215561\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.104828\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.121373\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.086103\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.092052\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.077594\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.322882\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.076481\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.168969\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.223827\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.024388\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.130262\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.222876\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.156030\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.368086\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.166711\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.278211\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.248268\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.155037\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.064788\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.231738\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.131868\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.149723\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.099343\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.212119\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.252037\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.267782\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.365772\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.111552\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.188080\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.219074\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.134249\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.125930\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.224080\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.233634\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.082370\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.191483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.127651\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.119514\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.280890\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.174676\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.312178\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.087110\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.134723\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.242130\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.133048\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.094104\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.305479\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.239999\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.050261\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.062300\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.149544\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.219416\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.134464\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.140804\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.276580\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.130013\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.162159\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.241778\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.236493\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.217472\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.199458\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.166163\n",
      "\n",
      "Test set: Avg. loss: 0.0543, Accuracy: 9837/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.106044\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.086618\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.180702\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.258715\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.110176\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.091619\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.252277\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.116751\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.203112\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.193405\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.215201\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.176474\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.180864\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.200961\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.098066\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.258470\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.161597\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.037561\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.166566\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.306151\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.137730\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.314837\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.101308\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.415811\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.177253\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.215319\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.134949\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.186911\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.144259\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.082886\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.112218\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.086370\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.308134\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.115812\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.087683\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.197324\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.218039\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.201315\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.020183\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.072819\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.250605\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.119559\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.134688\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.117126\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.095703\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.141184\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.147965\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.097925\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.146482\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.448839\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.044592\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.235677\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.252823\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.125418\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.134680\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.102097\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.106036\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.213301\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.034393\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.145279\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.263406\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.243519\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.204465\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.111620\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.211984\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.139259\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.103239\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.086146\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.251986\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.067047\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.270114\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.114828\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.172130\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.181764\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.052484\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.158272\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.106488\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.056998\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.487811\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.278297\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.219924\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.095738\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.125215\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.182189\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.078810\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.248977\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.209920\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.128940\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.221385\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.059084\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.077744\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.218377\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.208406\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.077406\n",
      "\n",
      "Test set: Avg. loss: 0.0515, Accuracy: 9844/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net1, test_loader10)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net1, train_loader10, epoch)\n",
    "    test(net1, test_loader10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.1654e-01, 9.7179e-01, 4.9124e-01,  ..., 4.2477e-01,\n",
      "           2.2299e-01, 8.4291e-01],\n",
      "          [5.2902e-01, 4.3635e-01, 3.6457e-02,  ..., 6.9386e-02,\n",
      "           5.2910e-01, 6.2618e-02],\n",
      "          [9.0178e-01, 7.3611e-01, 5.5311e-01,  ..., 4.3923e-01,\n",
      "           4.2466e-01, 6.6996e-01],\n",
      "          ...,\n",
      "          [2.8626e-01, 5.7789e-02, 9.9723e-02,  ..., 9.8694e-01,\n",
      "           9.0332e-01, 9.1501e-01],\n",
      "          [8.4994e-01, 1.1725e-01, 1.6346e-01,  ..., 8.2650e-01,\n",
      "           5.3172e-01, 6.6479e-03],\n",
      "          [9.0715e-02, 6.3028e-01, 4.6070e-02,  ..., 4.0643e-03,\n",
      "           1.1211e-01, 6.7317e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.6023e-02, 2.7601e-01, 5.1060e-03,  ..., 9.9962e-01,\n",
      "           6.8794e-01, 5.2147e-01],\n",
      "          [4.0335e-01, 6.0134e-01, 9.2850e-01,  ..., 8.4041e-02,\n",
      "           1.7467e-01, 3.5758e-01],\n",
      "          [6.8115e-01, 3.9177e-01, 7.9013e-01,  ..., 6.9970e-01,\n",
      "           6.1563e-01, 8.6991e-01],\n",
      "          ...,\n",
      "          [9.1025e-01, 5.5306e-01, 3.7287e-02,  ..., 8.5207e-01,\n",
      "           6.6084e-02, 4.5539e-01],\n",
      "          [5.5603e-01, 4.8523e-01, 4.0688e-01,  ..., 1.9228e-01,\n",
      "           2.2711e-01, 7.2997e-01],\n",
      "          [8.2259e-01, 6.5918e-02, 1.3840e-01,  ..., 3.3788e-01,\n",
      "           4.9313e-01, 4.9899e-01]]],\n",
      "\n",
      "\n",
      "        [[[8.8824e-01, 8.0977e-02, 3.7871e-01,  ..., 3.9891e-01,\n",
      "           3.1155e-01, 8.7238e-01],\n",
      "          [3.2330e-03, 6.3057e-01, 5.3479e-01,  ..., 8.2900e-01,\n",
      "           5.1681e-01, 2.8352e-01],\n",
      "          [8.1516e-01, 4.5711e-01, 3.9218e-01,  ..., 7.9065e-02,\n",
      "           3.4966e-01, 3.6649e-01],\n",
      "          ...,\n",
      "          [4.0227e-01, 2.2752e-01, 1.8320e-02,  ..., 4.0568e-01,\n",
      "           1.4468e-01, 4.1591e-01],\n",
      "          [8.1729e-01, 7.3074e-01, 6.9876e-01,  ..., 1.4809e-01,\n",
      "           1.3698e-01, 5.5259e-01],\n",
      "          [7.0097e-01, 1.3696e-01, 2.6184e-01,  ..., 4.6573e-01,\n",
      "           1.7715e-04, 2.5091e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[9.6561e-01, 9.1746e-01, 3.3065e-03,  ..., 3.9309e-02,\n",
      "           5.4669e-01, 8.6461e-01],\n",
      "          [9.3493e-01, 9.5176e-01, 5.1323e-01,  ..., 1.8959e-01,\n",
      "           4.1878e-01, 1.4680e-01],\n",
      "          [4.9924e-01, 6.3762e-02, 1.0360e-01,  ..., 6.9109e-01,\n",
      "           9.8225e-01, 9.0174e-01],\n",
      "          ...,\n",
      "          [8.6434e-02, 7.4234e-01, 7.9869e-01,  ..., 6.5771e-02,\n",
      "           1.0676e-01, 2.6034e-01],\n",
      "          [4.4376e-01, 9.0976e-01, 3.7988e-01,  ..., 7.6516e-01,\n",
      "           2.6544e-01, 8.0260e-01],\n",
      "          [9.6916e-01, 1.7200e-01, 8.1749e-01,  ..., 1.0403e-01,\n",
      "           1.7391e-01, 9.9041e-03]]],\n",
      "\n",
      "\n",
      "        [[[7.8956e-01, 7.5212e-01, 6.0599e-01,  ..., 2.5066e-01,\n",
      "           9.6577e-01, 3.4938e-01],\n",
      "          [1.1485e-02, 5.2465e-01, 3.2320e-01,  ..., 4.5473e-01,\n",
      "           3.7857e-01, 8.2016e-01],\n",
      "          [4.6400e-01, 5.2454e-01, 5.4623e-01,  ..., 1.1405e-01,\n",
      "           5.5090e-01, 5.1534e-01],\n",
      "          ...,\n",
      "          [7.5588e-01, 1.9775e-01, 9.7479e-01,  ..., 2.7360e-01,\n",
      "           3.1455e-01, 6.4441e-01],\n",
      "          [4.5564e-01, 1.0562e-01, 2.4069e-01,  ..., 2.4727e-01,\n",
      "           9.6876e-01, 1.3585e-01],\n",
      "          [4.1118e-01, 3.3582e-01, 1.3238e-01,  ..., 1.8315e-01,\n",
      "           7.7874e-01, 5.1990e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.6801e-01, 4.4602e-01, 2.3372e-01,  ..., 4.4709e-01,\n",
      "           9.1668e-01, 3.4453e-01],\n",
      "          [9.6950e-01, 1.1486e-01, 9.0373e-01,  ..., 7.4254e-01,\n",
      "           8.0118e-01, 4.7911e-01],\n",
      "          [2.2719e-01, 4.0734e-01, 7.6406e-01,  ..., 9.2882e-01,\n",
      "           4.3839e-01, 5.4971e-01],\n",
      "          ...,\n",
      "          [7.0583e-01, 8.9939e-01, 1.5142e-01,  ..., 7.6201e-01,\n",
      "           6.5913e-01, 7.4448e-01],\n",
      "          [5.7760e-01, 5.5693e-01, 6.8600e-01,  ..., 1.6927e-01,\n",
      "           9.0225e-01, 5.6393e-01],\n",
      "          [5.7274e-01, 3.5742e-01, 8.2584e-01,  ..., 1.7330e-01,\n",
      "           8.7019e-01, 3.7858e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "b = 2000;\n",
    "noise = torch.rand(b, 1, 28, 28)\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "output = net1(noise.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 50])\n"
     ]
    }
   ],
   "source": [
    "ll = net1.last\n",
    "print(ll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lid import LID\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net1_c10 = LID(ll, ll, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00389483, 0.00778965, 0.01168448, 0.00778965, 0.02336896,\n",
       "        0.01557931, 0.01947414, 0.02336896, 0.02726379, 0.04673793,\n",
       "        0.07400172, 0.05063275, 0.07010689, 0.12463447, 0.0856862 ,\n",
       "        0.14021378, 0.14021378, 0.14021378, 0.13631895, 0.18695171,\n",
       "        0.2142155 , 0.20253102, 0.26095342, 0.24147929, 0.24147929,\n",
       "        0.29600687, 0.28821722, 0.31548101, 0.23758446, 0.23368963,\n",
       "        0.2142155 , 0.22979481, 0.23758446, 0.22979481, 0.24147929,\n",
       "        0.2142155 , 0.18305688, 0.1713724 , 0.18695171, 0.18695171,\n",
       "        0.1285293 , 0.18305688, 0.10905516, 0.12073964, 0.16358274,\n",
       "        0.09347585, 0.13631895, 0.10905516, 0.07010689, 0.06621206,\n",
       "        0.07789654, 0.05063275, 0.07010689, 0.04673793, 0.04673793,\n",
       "        0.06231724, 0.03115862, 0.03894827, 0.03115862, 0.02336896,\n",
       "        0.01947414, 0.01168448, 0.01557931, 0.01168448, 0.01557931,\n",
       "        0.00389483, 0.00389483, 0.01168448, 0.00778965, 0.00778965,\n",
       "        0.00389483, 0.00778965, 0.00389483, 0.00389483, 0.00778965,\n",
       "        0.00389483, 0.00778965, 0.        , 0.00389483, 0.00389483,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00389483, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00389483, 0.        , 0.        , 0.        , 0.00389483]),\n",
       " array([ 5.29793662,  5.42631202,  5.55468742,  5.68306282,  5.81143822,\n",
       "         5.93981362,  6.06818901,  6.19656441,  6.32493981,  6.45331521,\n",
       "         6.58169061,  6.71006601,  6.83844141,  6.96681681,  7.0951922 ,\n",
       "         7.2235676 ,  7.351943  ,  7.4803184 ,  7.6086938 ,  7.7370692 ,\n",
       "         7.8654446 ,  7.99382   ,  8.12219539,  8.25057079,  8.37894619,\n",
       "         8.50732159,  8.63569699,  8.76407239,  8.89244779,  9.02082319,\n",
       "         9.14919859,  9.27757398,  9.40594938,  9.53432478,  9.66270018,\n",
       "         9.79107558,  9.91945098, 10.04782638, 10.17620178, 10.30457717,\n",
       "        10.43295257, 10.56132797, 10.68970337, 10.81807877, 10.94645417,\n",
       "        11.07482957, 11.20320497, 11.33158037, 11.45995576, 11.58833116,\n",
       "        11.71670656, 11.84508196, 11.97345736, 12.10183276, 12.23020816,\n",
       "        12.35858356, 12.48695895, 12.61533435, 12.74370975, 12.87208515,\n",
       "        13.00046055, 13.12883595, 13.25721135, 13.38558675, 13.51396215,\n",
       "        13.64233754, 13.77071294, 13.89908834, 14.02746374, 14.15583914,\n",
       "        14.28421454, 14.41258994, 14.54096534, 14.66934073, 14.79771613,\n",
       "        14.92609153, 15.05446693, 15.18284233, 15.31121773, 15.43959313,\n",
       "        15.56796853, 15.69634392, 15.82471932, 15.95309472, 16.08147012,\n",
       "        16.20984552, 16.33822092, 16.46659632, 16.59497172, 16.72334712,\n",
       "        16.85172251, 16.98009791, 17.10847331, 17.23684871, 17.36522411,\n",
       "        17.49359951, 17.62197491, 17.75035031, 17.8787257 , 18.0071011 ,\n",
       "        18.1354765 ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lid_net1_c10, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net2 similar to net, but last layer dim=100, instead of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Net2().cuda()\n",
    "n_epochs = 10\n",
    "optimizer = optim.SGD(net2.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader10.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3074, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.288522\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.310102\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.290101\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.284409\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.290248\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.298102\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.282577\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.248449\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.245279\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.243803\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.204534\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.181953\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.168794\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.102715\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.055047\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.916580\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.738268\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.468500\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.407731\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.161059\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.293398\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.281642\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.271985\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.238611\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.015480\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.026598\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.866228\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.855466\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.787713\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.832617\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.718624\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.794481\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.938590\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.575992\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.704798\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.701243\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.709272\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.764580\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.774855\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.576155\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.734603\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.690096\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.719757\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.631400\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.578059\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.485465\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.661133\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.572866\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.532655\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.510595\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.519701\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.702215\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.566760\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.469520\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.457977\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.484039\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.603955\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.662566\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.341123\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.557903\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.461643\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.394537\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.393837\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.451749\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.751732\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.440589\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.555500\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.307684\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.577361\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.343328\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.408429\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.337049\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.414562\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.614529\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.615332\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.406876\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.477274\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.633530\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.595147\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.533283\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.485747\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.556611\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.288065\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.335823\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.285699\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.345907\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.348869\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.357434\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.668119\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.588712\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.472577\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.271303\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.329271\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.370872\n",
      "\n",
      "Test set: Avg. loss: 0.1792, Accuracy: 9432/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.342679\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.268852\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.546361\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.444367\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.379766\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.429833\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.558894\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.549987\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.240424\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.394991\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.502497\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.480638\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.232534\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.369290\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.405829\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.198329\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.421872\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.281621\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.301701\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.415444\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.399012\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.387244\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.462777\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.153916\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.277027\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.275905\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.160257\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.383216\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.358128\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.252735\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.370450\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.382694\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.163671\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.463101\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.263565\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.246080\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.391558\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.407885\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.373332\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.348258\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.300217\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.328426\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.265519\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.407420\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.269475\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.246340\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.462775\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.378574\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.272579\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.248954\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.258854\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.193592\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.405590\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.201548\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.126069\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.422749\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.227252\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.249479\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.284311\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.205016\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.226236\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.346501\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.234416\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.345918\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.287128\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.096277\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.380114\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.308756\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.291520\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.290873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.266035\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.185744\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.290547\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.134534\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.217128\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.278396\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.333344\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.431278\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.349911\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.414125\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.141687\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.490166\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.198963\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.294182\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.166205\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.180784\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.164786\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.362507\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.146096\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.353935\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.107746\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.392046\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.267754\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.455978\n",
      "\n",
      "Test set: Avg. loss: 0.1144, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.131153\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.220945\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.326146\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.283036\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.519229\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.284807\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.167652\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.276154\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.204479\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.266616\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.297174\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.200008\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.189196\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.388018\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.324218\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.296662\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.358194\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.234079\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.181031\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.199123\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.171761\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.164580\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.182809\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.158946\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.272131\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.360539\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.132209\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.296968\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.414779\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.208581\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.256989\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.314158\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.339934\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.202713\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.160159\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.401370\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.422194\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.265530\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.340238\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.213185\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.197781\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.319736\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.298211\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.420726\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.320387\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.264285\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.236857\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.240864\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.093426\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.172005\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.217057\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.149232\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.207177\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.146429\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.194459\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.267292\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.109748\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.167625\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.338198\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.155214\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.217537\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.301398\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.132401\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.149388\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.347787\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.360835\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.128134\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.198966\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.103232\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.178607\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.274727\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.266384\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.137243\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.166823\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.298777\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.157988\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.100879\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.163900\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.112765\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.129706\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.322465\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.218685\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.088348\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.347473\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.418906\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.284851\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.281062\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.202119\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.175036\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.167292\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.140143\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.237633\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.391964\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.172945\n",
      "\n",
      "Test set: Avg. loss: 0.0889, Accuracy: 9715/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.231703\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.207697\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.226841\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.321845\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.197487\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.116468\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.065151\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.250991\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.326699\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.159443\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.258220\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.077106\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.229460\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.135477\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.174408\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.151180\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.419914\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.375968\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.178017\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.219951\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.255620\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.065985\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.161741\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.199038\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.092484\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.177335\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.329349\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.146385\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.336088\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.289323\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.120261\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.246353\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.296761\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.121508\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.320479\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.171068\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.394675\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.236904\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.261805\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.332138\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.124045\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.278183\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.315706\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.122140\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.279608\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.267076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.185238\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.215423\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.212814\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.171681\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.141145\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.223571\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.242784\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.164667\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.154460\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.121669\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.105415\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.346812\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.083585\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.210093\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.315057\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.188002\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.228438\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.259277\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.108278\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.251671\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.235873\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.098594\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.214171\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.261477\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.122151\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.131696\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.291153\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.289226\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.088141\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.174997\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.193926\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.389670\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.089783\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.216568\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.295568\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.218533\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.123509\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.106021\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.074689\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.139322\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.120331\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.150938\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.136014\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.137258\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.338032\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.084888\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.083454\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.090653\n",
      "\n",
      "Test set: Avg. loss: 0.0760, Accuracy: 9777/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.212010\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.217759\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.148232\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.174532\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.382034\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.343651\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.163677\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.174227\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.073923\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.245766\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.215862\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.297836\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.313294\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.539596\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.226558\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.165823\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.124406\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.182269\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.293863\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.195125\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.125484\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.117681\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.129663\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.120547\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.153791\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.315063\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.190021\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.103474\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.310491\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.064730\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.165186\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.380720\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.363018\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.156172\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.255880\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.213146\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.150611\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.027940\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.098065\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.254185\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.185539\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.110902\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.082526\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.329837\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.174864\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.229194\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.173224\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.240568\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.148907\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.049039\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.304763\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.192217\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.219635\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.211864\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.232112\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.553201\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.066706\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.163184\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.133452\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.202536\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.177879\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.356270\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.133210\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.477797\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.125129\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.325026\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.258034\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.328672\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.260562\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.128254\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.222784\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.056136\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.143717\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.195972\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.269506\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.148769\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.095561\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.120888\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.210355\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.214182\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.374667\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.065459\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.153439\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.060002\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.069007\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.213789\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.302755\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.093510\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.102349\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.246184\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.121676\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.303903\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.168998\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.143556\n",
      "\n",
      "Test set: Avg. loss: 0.0639, Accuracy: 9793/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.282795\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.142586\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.113331\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.182874\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.102047\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.182508\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.071632\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.076944\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.063511\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.305380\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.131402\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.206086\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.068685\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.195714\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.150783\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.151186\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.140513\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.195304\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.218983\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.370050\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.065811\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.238116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.062279\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.130699\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.156980\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.072087\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.415923\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.124832\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.155165\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.079360\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.099484\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.182737\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.079778\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.218099\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.089105\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.347106\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.331802\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.161071\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.161372\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.083050\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.171177\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.170312\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.336992\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.119907\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.113547\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.176269\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.155449\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.274576\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.198062\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.384422\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.152453\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.037802\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.225124\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.115552\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.221857\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.228443\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.156024\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.198955\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.068494\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.043719\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.179609\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.335173\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.168000\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.199224\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.105378\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.140199\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.084311\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.179303\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.269614\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.313901\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.192933\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.194595\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.094968\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.166143\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.086010\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.245066\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.253073\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.148517\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.212320\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.085866\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.130669\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.197019\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.244779\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.209872\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.226254\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.080128\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.083574\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.181790\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.103834\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.372419\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.111401\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.258236\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.080992\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.145454\n",
      "\n",
      "Test set: Avg. loss: 0.0616, Accuracy: 9794/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.065979\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.065541\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.144098\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.260547\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.140615\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.173717\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.118437\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.159670\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.072010\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.195943\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.091353\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.271468\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.113387\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.268001\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.058767\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.079435\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.065650\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.117181\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.232857\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.095385\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.152165\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.056765\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.141396\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.106021\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.034685\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.095037\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.060369\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.224189\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.026003\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.075423\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.264563\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.103104\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.123012\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.193152\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.068799\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.251091\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.156354\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.032852\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.122945\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.150184\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.080349\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.141568\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.187810\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.253123\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.212254\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.090035\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.213838\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.206091\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.099450\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.194975\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.151781\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.074805\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.202028\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.021833\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.109911\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.297938\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.078894\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.087521\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.139354\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.133652\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.090486\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.126045\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.058004\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.152313\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.045579\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.139856\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.137787\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.134079\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.364610\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.044907\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.072487\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.100737\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.054676\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.256913\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.321576\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.234826\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.104475\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.088780\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.356877\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.209787\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.151416\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.215372\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.133927\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.074263\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.133255\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.598783\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.041246\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.196130\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.162063\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.137502\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.140638\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.100875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.355349\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.142604\n",
      "\n",
      "Test set: Avg. loss: 0.0548, Accuracy: 9816/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.180897\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.145571\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.110002\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.200543\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.070035\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.122384\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.130428\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.116895\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.261097\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.044600\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.322890\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.134576\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.183788\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.143282\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.251352\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.147351\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.169182\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.112782\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.121219\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.103687\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.054102\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.296658\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.323050\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.064130\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.066696\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.105078\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.024018\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.150885\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.187238\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.070873\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.113169\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.163975\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.222608\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.262392\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.294466\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.147432\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.170930\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.277714\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.063146\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.128004\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.141426\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.180511\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.288497\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.132421\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.203281\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.142563\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.085769\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.114293\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.100549\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.069877\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.047186\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.098498\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.368697\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.074885\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.169938\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.146004\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.122365\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.267758\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.104632\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.156691\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.064149\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.296381\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.143002\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.138555\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.106523\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.125369\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.208544\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.127539\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.126785\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.131348\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.084110\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.141282\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.063675\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.323660\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.135820\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.091707\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.115181\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.216416\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.125370\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.147412\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.121539\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.175995\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.181353\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.293193\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.095159\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.069371\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.218824\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.239165\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.212230\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.118504\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.041654\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.203279\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.047041\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.017618\n",
      "\n",
      "Test set: Avg. loss: 0.0505, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.187108\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.125337\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.128048\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.060149\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.209189\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.246746\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.152608\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.145046\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.113958\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.045681\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.061448\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.048516\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.018875\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.173067\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.096038\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.038696\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.154322\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.089375\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.149595\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.112069\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.147411\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.093643\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.073996\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.155883\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.054148\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.210848\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.179299\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.095025\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.050721\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.165297\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.125213\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.183725\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.071859\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.145517\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.108061\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.295551\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.032037\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.073237\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.278625\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.036648\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.140369\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.029489\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.215886\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.039430\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.204814\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.124988\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.227841\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.096467\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.159006\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.377949\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.178709\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.053348\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.307841\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.056264\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.052181\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.125374\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.122742\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.196298\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.124268\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.050685\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.216248\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.177049\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.232448\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.131400\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.156701\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.254224\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.065545\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.210642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.202216\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.132746\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.026898\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.169453\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.062813\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.172081\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.061824\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.076804\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.079331\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.210631\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.272324\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.082527\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.134004\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.303418\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.263496\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.276479\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.217985\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.075055\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.149603\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.197337\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.108593\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.127134\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.131723\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.160803\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.183179\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.186272\n",
      "\n",
      "Test set: Avg. loss: 0.0486, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.196507\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.107099\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.109600\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.091113\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.095558\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.067502\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.106971\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.119843\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.268273\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.120204\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.083696\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.164477\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.106628\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.106191\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.137071\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.113498\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.098168\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.092670\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.179690\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.228036\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.151130\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.165983\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.135680\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.077538\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.145524\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.147709\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.076788\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.026759\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.207293\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.040573\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.096800\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.143378\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.367429\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.099214\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.123246\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.074780\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.095917\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.125101\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.144202\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.128289\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.126386\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.151758\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.217391\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.110123\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.048660\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.253804\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.236451\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.131928\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.076387\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.267570\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.104347\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.066666\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.151793\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.123996\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.136182\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.050652\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.148421\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.121306\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.099430\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.070108\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.233411\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.132381\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.063762\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.038431\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.037873\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.087237\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.066626\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.167992\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.224697\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.106675\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.388288\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.066496\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.097025\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.134619\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.105142\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.066374\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.130813\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.196506\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.350736\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.040093\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.154051\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.170698\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.037101\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.145317\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.093465\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.070514\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.063253\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.144636\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.054651\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.126861\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.082149\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.059705\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.045258\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.031973\n",
      "\n",
      "Test set: Avg. loss: 0.0478, Accuracy: 9848/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net2, test_loader10)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net2, train_loader10, epoch)\n",
    "    test(net2, test_loader10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00338078, 0.        , 0.00338078, 0.        , 0.00338078,\n",
       "        0.02028468, 0.00676156, 0.01352312, 0.0169039 , 0.0169039 ,\n",
       "        0.0338078 , 0.02366546, 0.05071171, 0.05071171, 0.05747327,\n",
       "        0.05071171, 0.08451951, 0.08113873, 0.11156575, 0.07437717,\n",
       "        0.14537356, 0.138612  , 0.1724198 , 0.16227746, 0.12508887,\n",
       "        0.1893237 , 0.17918136, 0.18594292, 0.21636995, 0.14537356,\n",
       "        0.20960838, 0.20284682, 0.18594292, 0.16227746, 0.19270448,\n",
       "        0.16903902, 0.1724198 , 0.16227746, 0.1893237 , 0.20960838,\n",
       "        0.12846966, 0.16565824, 0.19946604, 0.11494653, 0.13523122,\n",
       "        0.12170809, 0.138612  , 0.10480419, 0.07775795, 0.09128107,\n",
       "        0.10818497, 0.08113873, 0.10818497, 0.08790029, 0.07775795,\n",
       "        0.07099639, 0.04733093, 0.06085405, 0.05409249, 0.03718858,\n",
       "        0.03718858, 0.04395015, 0.05409249, 0.03718858, 0.04395015,\n",
       "        0.02366546, 0.04395015, 0.02028468, 0.02704624, 0.02366546,\n",
       "        0.02028468, 0.02028468, 0.02028468, 0.0169039 , 0.00676156,\n",
       "        0.01352312, 0.00676156, 0.00338078, 0.00338078, 0.0169039 ,\n",
       "        0.00338078, 0.00338078, 0.00676156, 0.00338078, 0.00338078,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00676156,\n",
       "        0.00338078, 0.        , 0.00338078, 0.        , 0.        ,\n",
       "        0.        , 0.00338078, 0.        , 0.00338078, 0.00676156]),\n",
       " array([ 6.65051484,  6.79840968,  6.94630453,  7.09419938,  7.24209422,\n",
       "         7.38998907,  7.53788392,  7.68577876,  7.83367361,  7.98156846,\n",
       "         8.12946331,  8.27735815,  8.425253  ,  8.57314785,  8.72104269,\n",
       "         8.86893754,  9.01683239,  9.16472723,  9.31262208,  9.46051693,\n",
       "         9.60841177,  9.75630662,  9.90420147, 10.05209632, 10.19999116,\n",
       "        10.34788601, 10.49578086, 10.6436757 , 10.79157055, 10.9394654 ,\n",
       "        11.08736024, 11.23525509, 11.38314994, 11.53104479, 11.67893963,\n",
       "        11.82683448, 11.97472933, 12.12262417, 12.27051902, 12.41841387,\n",
       "        12.56630871, 12.71420356, 12.86209841, 13.00999326, 13.1578881 ,\n",
       "        13.30578295, 13.4536778 , 13.60157264, 13.74946749, 13.89736234,\n",
       "        14.04525718, 14.19315203, 14.34104688, 14.48894173, 14.63683657,\n",
       "        14.78473142, 14.93262627, 15.08052111, 15.22841596, 15.37631081,\n",
       "        15.52420565, 15.6721005 , 15.81999535, 15.9678902 , 16.11578504,\n",
       "        16.26367989, 16.41157474, 16.55946958, 16.70736443, 16.85525928,\n",
       "        17.00315412, 17.15104897, 17.29894382, 17.44683867, 17.59473351,\n",
       "        17.74262836, 17.89052321, 18.03841805, 18.1863129 , 18.33420775,\n",
       "        18.48210259, 18.62999744, 18.77789229, 18.92578714, 19.07368198,\n",
       "        19.22157683, 19.36947168, 19.51736652, 19.66526137, 19.81315622,\n",
       "        19.96105106, 20.10894591, 20.25684076, 20.4047356 , 20.55263045,\n",
       "        20.7005253 , 20.84842015, 20.99631499, 21.14420984, 21.29210469,\n",
       "        21.43999953]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = net2(noise.cuda())\n",
    "ll = net2.last\n",
    "print(ll.shape)\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net2_c10 = LID(ll, ll, k=50)\n",
    "plt.hist(lid_net2_c10, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_c8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_c8, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.0851, Accuracy: 953/8017 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/48200 (0%)]\tLoss: 2.080665\n",
      "Train Epoch: 1 [640/48200 (1%)]\tLoss: 2.077751\n",
      "Train Epoch: 1 [1280/48200 (3%)]\tLoss: 2.054353\n",
      "Train Epoch: 1 [1920/48200 (4%)]\tLoss: 2.033965\n",
      "Train Epoch: 1 [2560/48200 (5%)]\tLoss: 1.990703\n",
      "Train Epoch: 1 [3200/48200 (7%)]\tLoss: 1.951077\n",
      "Train Epoch: 1 [3840/48200 (8%)]\tLoss: 1.842593\n",
      "Train Epoch: 1 [4480/48200 (9%)]\tLoss: 1.821124\n",
      "Train Epoch: 1 [5120/48200 (11%)]\tLoss: 1.542811\n",
      "Train Epoch: 1 [5760/48200 (12%)]\tLoss: 1.499018\n",
      "Train Epoch: 1 [6400/48200 (13%)]\tLoss: 1.317794\n",
      "Train Epoch: 1 [7040/48200 (15%)]\tLoss: 1.324623\n",
      "Train Epoch: 1 [7680/48200 (16%)]\tLoss: 1.246471\n",
      "Train Epoch: 1 [8320/48200 (17%)]\tLoss: 0.994980\n",
      "Train Epoch: 1 [8960/48200 (19%)]\tLoss: 0.791617\n",
      "Train Epoch: 1 [9600/48200 (20%)]\tLoss: 0.807380\n",
      "Train Epoch: 1 [10240/48200 (21%)]\tLoss: 0.614277\n",
      "Train Epoch: 1 [10880/48200 (23%)]\tLoss: 0.647308\n",
      "Train Epoch: 1 [11520/48200 (24%)]\tLoss: 0.749157\n",
      "Train Epoch: 1 [12160/48200 (25%)]\tLoss: 0.598286\n",
      "Train Epoch: 1 [12800/48200 (27%)]\tLoss: 0.710374\n",
      "Train Epoch: 1 [13440/48200 (28%)]\tLoss: 0.649362\n",
      "Train Epoch: 1 [14080/48200 (29%)]\tLoss: 0.523132\n",
      "Train Epoch: 1 [14720/48200 (31%)]\tLoss: 0.824831\n",
      "Train Epoch: 1 [15360/48200 (32%)]\tLoss: 0.616160\n",
      "Train Epoch: 1 [16000/48200 (33%)]\tLoss: 0.520115\n",
      "Train Epoch: 1 [16640/48200 (34%)]\tLoss: 0.514463\n",
      "Train Epoch: 1 [17280/48200 (36%)]\tLoss: 0.575170\n",
      "Train Epoch: 1 [17920/48200 (37%)]\tLoss: 0.569719\n",
      "Train Epoch: 1 [18560/48200 (38%)]\tLoss: 0.738421\n",
      "Train Epoch: 1 [19200/48200 (40%)]\tLoss: 0.591270\n",
      "Train Epoch: 1 [19840/48200 (41%)]\tLoss: 0.603958\n",
      "Train Epoch: 1 [20480/48200 (42%)]\tLoss: 0.432337\n",
      "Train Epoch: 1 [21120/48200 (44%)]\tLoss: 0.499276\n",
      "Train Epoch: 1 [21760/48200 (45%)]\tLoss: 0.574944\n",
      "Train Epoch: 1 [22400/48200 (46%)]\tLoss: 0.585039\n",
      "Train Epoch: 1 [23040/48200 (48%)]\tLoss: 0.510873\n",
      "Train Epoch: 1 [23680/48200 (49%)]\tLoss: 0.355442\n",
      "Train Epoch: 1 [24320/48200 (50%)]\tLoss: 0.604939\n",
      "Train Epoch: 1 [24960/48200 (52%)]\tLoss: 0.544235\n",
      "Train Epoch: 1 [25600/48200 (53%)]\tLoss: 0.466225\n",
      "Train Epoch: 1 [26240/48200 (54%)]\tLoss: 0.614204\n",
      "Train Epoch: 1 [26880/48200 (56%)]\tLoss: 0.506875\n",
      "Train Epoch: 1 [27520/48200 (57%)]\tLoss: 0.401381\n",
      "Train Epoch: 1 [28160/48200 (58%)]\tLoss: 0.428894\n",
      "Train Epoch: 1 [28800/48200 (60%)]\tLoss: 0.424197\n",
      "Train Epoch: 1 [29440/48200 (61%)]\tLoss: 0.545836\n",
      "Train Epoch: 1 [30080/48200 (62%)]\tLoss: 0.444747\n",
      "Train Epoch: 1 [30720/48200 (64%)]\tLoss: 0.755102\n",
      "Train Epoch: 1 [31360/48200 (65%)]\tLoss: 0.493412\n",
      "Train Epoch: 1 [32000/48200 (66%)]\tLoss: 0.507261\n",
      "Train Epoch: 1 [32640/48200 (68%)]\tLoss: 0.272132\n",
      "Train Epoch: 1 [33280/48200 (69%)]\tLoss: 0.384716\n",
      "Train Epoch: 1 [33920/48200 (70%)]\tLoss: 0.568271\n",
      "Train Epoch: 1 [34560/48200 (72%)]\tLoss: 0.297456\n",
      "Train Epoch: 1 [35200/48200 (73%)]\tLoss: 0.559548\n",
      "Train Epoch: 1 [35840/48200 (74%)]\tLoss: 0.439964\n",
      "Train Epoch: 1 [36480/48200 (76%)]\tLoss: 0.360048\n",
      "Train Epoch: 1 [37120/48200 (77%)]\tLoss: 0.339736\n",
      "Train Epoch: 1 [37760/48200 (78%)]\tLoss: 0.435746\n",
      "Train Epoch: 1 [38400/48200 (80%)]\tLoss: 0.228631\n",
      "Train Epoch: 1 [39040/48200 (81%)]\tLoss: 0.457109\n",
      "Train Epoch: 1 [39680/48200 (82%)]\tLoss: 0.377885\n",
      "Train Epoch: 1 [40320/48200 (84%)]\tLoss: 0.371244\n",
      "Train Epoch: 1 [40960/48200 (85%)]\tLoss: 0.232714\n",
      "Train Epoch: 1 [41600/48200 (86%)]\tLoss: 0.248536\n",
      "Train Epoch: 1 [42240/48200 (88%)]\tLoss: 0.302662\n",
      "Train Epoch: 1 [42880/48200 (89%)]\tLoss: 0.216697\n",
      "Train Epoch: 1 [43520/48200 (90%)]\tLoss: 0.330641\n",
      "Train Epoch: 1 [44160/48200 (92%)]\tLoss: 0.301485\n",
      "Train Epoch: 1 [44800/48200 (93%)]\tLoss: 0.222462\n",
      "Train Epoch: 1 [45440/48200 (94%)]\tLoss: 0.410987\n",
      "Train Epoch: 1 [46080/48200 (95%)]\tLoss: 0.351986\n",
      "Train Epoch: 1 [46720/48200 (97%)]\tLoss: 0.253272\n",
      "Train Epoch: 1 [47360/48200 (98%)]\tLoss: 0.338484\n",
      "Train Epoch: 1 [48000/48200 (99%)]\tLoss: 0.447061\n",
      "\n",
      "Test set: Avg. loss: 0.1489, Accuracy: 7641/8017 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/48200 (0%)]\tLoss: 0.323174\n",
      "Train Epoch: 2 [640/48200 (1%)]\tLoss: 0.354278\n",
      "Train Epoch: 2 [1280/48200 (3%)]\tLoss: 0.248883\n",
      "Train Epoch: 2 [1920/48200 (4%)]\tLoss: 0.166388\n",
      "Train Epoch: 2 [2560/48200 (5%)]\tLoss: 0.397040\n",
      "Train Epoch: 2 [3200/48200 (7%)]\tLoss: 0.218510\n",
      "Train Epoch: 2 [3840/48200 (8%)]\tLoss: 0.291416\n",
      "Train Epoch: 2 [4480/48200 (9%)]\tLoss: 0.398899\n",
      "Train Epoch: 2 [5120/48200 (11%)]\tLoss: 0.317256\n",
      "Train Epoch: 2 [5760/48200 (12%)]\tLoss: 0.236407\n",
      "Train Epoch: 2 [6400/48200 (13%)]\tLoss: 0.210772\n",
      "Train Epoch: 2 [7040/48200 (15%)]\tLoss: 0.453019\n",
      "Train Epoch: 2 [7680/48200 (16%)]\tLoss: 0.385828\n",
      "Train Epoch: 2 [8320/48200 (17%)]\tLoss: 0.132379\n",
      "Train Epoch: 2 [8960/48200 (19%)]\tLoss: 0.339033\n",
      "Train Epoch: 2 [9600/48200 (20%)]\tLoss: 0.320277\n",
      "Train Epoch: 2 [10240/48200 (21%)]\tLoss: 0.300362\n",
      "Train Epoch: 2 [10880/48200 (23%)]\tLoss: 0.436732\n",
      "Train Epoch: 2 [11520/48200 (24%)]\tLoss: 0.154764\n",
      "Train Epoch: 2 [12160/48200 (25%)]\tLoss: 0.415711\n",
      "Train Epoch: 2 [12800/48200 (27%)]\tLoss: 0.322257\n",
      "Train Epoch: 2 [13440/48200 (28%)]\tLoss: 0.134885\n",
      "Train Epoch: 2 [14080/48200 (29%)]\tLoss: 0.168188\n",
      "Train Epoch: 2 [14720/48200 (31%)]\tLoss: 0.390150\n",
      "Train Epoch: 2 [15360/48200 (32%)]\tLoss: 0.218124\n",
      "Train Epoch: 2 [16000/48200 (33%)]\tLoss: 0.366782\n",
      "Train Epoch: 2 [16640/48200 (34%)]\tLoss: 0.294357\n",
      "Train Epoch: 2 [17280/48200 (36%)]\tLoss: 0.350128\n",
      "Train Epoch: 2 [17920/48200 (37%)]\tLoss: 0.195998\n",
      "Train Epoch: 2 [18560/48200 (38%)]\tLoss: 0.256879\n",
      "Train Epoch: 2 [19200/48200 (40%)]\tLoss: 0.355263\n",
      "Train Epoch: 2 [19840/48200 (41%)]\tLoss: 0.345637\n",
      "Train Epoch: 2 [20480/48200 (42%)]\tLoss: 0.546193\n",
      "Train Epoch: 2 [21120/48200 (44%)]\tLoss: 0.317940\n",
      "Train Epoch: 2 [21760/48200 (45%)]\tLoss: 0.203955\n",
      "Train Epoch: 2 [22400/48200 (46%)]\tLoss: 0.427803\n",
      "Train Epoch: 2 [23040/48200 (48%)]\tLoss: 0.355619\n",
      "Train Epoch: 2 [23680/48200 (49%)]\tLoss: 0.182983\n",
      "Train Epoch: 2 [24320/48200 (50%)]\tLoss: 0.247618\n",
      "Train Epoch: 2 [24960/48200 (52%)]\tLoss: 0.484696\n",
      "Train Epoch: 2 [25600/48200 (53%)]\tLoss: 0.455800\n",
      "Train Epoch: 2 [26240/48200 (54%)]\tLoss: 0.234724\n",
      "Train Epoch: 2 [26880/48200 (56%)]\tLoss: 0.353174\n",
      "Train Epoch: 2 [27520/48200 (57%)]\tLoss: 0.147362\n",
      "Train Epoch: 2 [28160/48200 (58%)]\tLoss: 0.385863\n",
      "Train Epoch: 2 [28800/48200 (60%)]\tLoss: 0.215982\n",
      "Train Epoch: 2 [29440/48200 (61%)]\tLoss: 0.174910\n",
      "Train Epoch: 2 [30080/48200 (62%)]\tLoss: 0.187421\n",
      "Train Epoch: 2 [30720/48200 (64%)]\tLoss: 0.353949\n",
      "Train Epoch: 2 [31360/48200 (65%)]\tLoss: 0.216616\n",
      "Train Epoch: 2 [32000/48200 (66%)]\tLoss: 0.200897\n",
      "Train Epoch: 2 [32640/48200 (68%)]\tLoss: 0.162755\n",
      "Train Epoch: 2 [33280/48200 (69%)]\tLoss: 0.254369\n",
      "Train Epoch: 2 [33920/48200 (70%)]\tLoss: 0.403007\n",
      "Train Epoch: 2 [34560/48200 (72%)]\tLoss: 0.269047\n",
      "Train Epoch: 2 [35200/48200 (73%)]\tLoss: 0.221838\n",
      "Train Epoch: 2 [35840/48200 (74%)]\tLoss: 0.409778\n",
      "Train Epoch: 2 [36480/48200 (76%)]\tLoss: 0.407832\n",
      "Train Epoch: 2 [37120/48200 (77%)]\tLoss: 0.100093\n",
      "Train Epoch: 2 [37760/48200 (78%)]\tLoss: 0.233083\n",
      "Train Epoch: 2 [38400/48200 (80%)]\tLoss: 0.361730\n",
      "Train Epoch: 2 [39040/48200 (81%)]\tLoss: 0.200932\n",
      "Train Epoch: 2 [39680/48200 (82%)]\tLoss: 0.326824\n",
      "Train Epoch: 2 [40320/48200 (84%)]\tLoss: 0.236133\n",
      "Train Epoch: 2 [40960/48200 (85%)]\tLoss: 0.258823\n",
      "Train Epoch: 2 [41600/48200 (86%)]\tLoss: 0.212682\n",
      "Train Epoch: 2 [42240/48200 (88%)]\tLoss: 0.149424\n",
      "Train Epoch: 2 [42880/48200 (89%)]\tLoss: 0.272535\n",
      "Train Epoch: 2 [43520/48200 (90%)]\tLoss: 0.323660\n",
      "Train Epoch: 2 [44160/48200 (92%)]\tLoss: 0.340315\n",
      "Train Epoch: 2 [44800/48200 (93%)]\tLoss: 0.429923\n",
      "Train Epoch: 2 [45440/48200 (94%)]\tLoss: 0.121006\n",
      "Train Epoch: 2 [46080/48200 (95%)]\tLoss: 0.303956\n",
      "Train Epoch: 2 [46720/48200 (97%)]\tLoss: 0.163855\n",
      "Train Epoch: 2 [47360/48200 (98%)]\tLoss: 0.253763\n",
      "Train Epoch: 2 [48000/48200 (99%)]\tLoss: 0.205139\n",
      "\n",
      "Test set: Avg. loss: 0.0981, Accuracy: 7778/8017 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/48200 (0%)]\tLoss: 0.399992\n",
      "Train Epoch: 3 [640/48200 (1%)]\tLoss: 0.272651\n",
      "Train Epoch: 3 [1280/48200 (3%)]\tLoss: 0.229360\n",
      "Train Epoch: 3 [1920/48200 (4%)]\tLoss: 0.306168\n",
      "Train Epoch: 3 [2560/48200 (5%)]\tLoss: 0.129741\n",
      "Train Epoch: 3 [3200/48200 (7%)]\tLoss: 0.206076\n",
      "Train Epoch: 3 [3840/48200 (8%)]\tLoss: 0.415719\n",
      "Train Epoch: 3 [4480/48200 (9%)]\tLoss: 0.420944\n",
      "Train Epoch: 3 [5120/48200 (11%)]\tLoss: 0.177933\n",
      "Train Epoch: 3 [5760/48200 (12%)]\tLoss: 0.305710\n",
      "Train Epoch: 3 [6400/48200 (13%)]\tLoss: 0.272305\n",
      "Train Epoch: 3 [7040/48200 (15%)]\tLoss: 0.237585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [7680/48200 (16%)]\tLoss: 0.238202\n",
      "Train Epoch: 3 [8320/48200 (17%)]\tLoss: 0.204273\n",
      "Train Epoch: 3 [8960/48200 (19%)]\tLoss: 0.112339\n",
      "Train Epoch: 3 [9600/48200 (20%)]\tLoss: 0.372577\n",
      "Train Epoch: 3 [10240/48200 (21%)]\tLoss: 0.226432\n",
      "Train Epoch: 3 [10880/48200 (23%)]\tLoss: 0.115228\n",
      "Train Epoch: 3 [11520/48200 (24%)]\tLoss: 0.150101\n",
      "Train Epoch: 3 [12160/48200 (25%)]\tLoss: 0.263199\n",
      "Train Epoch: 3 [12800/48200 (27%)]\tLoss: 0.168046\n",
      "Train Epoch: 3 [13440/48200 (28%)]\tLoss: 0.157311\n",
      "Train Epoch: 3 [14080/48200 (29%)]\tLoss: 0.290823\n",
      "Train Epoch: 3 [14720/48200 (31%)]\tLoss: 0.270473\n",
      "Train Epoch: 3 [15360/48200 (32%)]\tLoss: 0.340872\n",
      "Train Epoch: 3 [16000/48200 (33%)]\tLoss: 0.186803\n",
      "Train Epoch: 3 [16640/48200 (34%)]\tLoss: 0.129556\n",
      "Train Epoch: 3 [17280/48200 (36%)]\tLoss: 0.213797\n",
      "Train Epoch: 3 [17920/48200 (37%)]\tLoss: 0.264308\n",
      "Train Epoch: 3 [18560/48200 (38%)]\tLoss: 0.169477\n",
      "Train Epoch: 3 [19200/48200 (40%)]\tLoss: 0.143088\n",
      "Train Epoch: 3 [19840/48200 (41%)]\tLoss: 0.320433\n",
      "Train Epoch: 3 [20480/48200 (42%)]\tLoss: 0.273388\n",
      "Train Epoch: 3 [21120/48200 (44%)]\tLoss: 0.147539\n",
      "Train Epoch: 3 [21760/48200 (45%)]\tLoss: 0.195806\n",
      "Train Epoch: 3 [22400/48200 (46%)]\tLoss: 0.133376\n",
      "Train Epoch: 3 [23040/48200 (48%)]\tLoss: 0.175974\n",
      "Train Epoch: 3 [23680/48200 (49%)]\tLoss: 0.112603\n",
      "Train Epoch: 3 [24320/48200 (50%)]\tLoss: 0.128946\n",
      "Train Epoch: 3 [24960/48200 (52%)]\tLoss: 0.235991\n",
      "Train Epoch: 3 [25600/48200 (53%)]\tLoss: 0.202287\n",
      "Train Epoch: 3 [26240/48200 (54%)]\tLoss: 0.134250\n",
      "Train Epoch: 3 [26880/48200 (56%)]\tLoss: 0.288794\n",
      "Train Epoch: 3 [27520/48200 (57%)]\tLoss: 0.359154\n",
      "Train Epoch: 3 [28160/48200 (58%)]\tLoss: 0.121038\n",
      "Train Epoch: 3 [28800/48200 (60%)]\tLoss: 0.633391\n",
      "Train Epoch: 3 [29440/48200 (61%)]\tLoss: 0.440531\n",
      "Train Epoch: 3 [30080/48200 (62%)]\tLoss: 0.247978\n",
      "Train Epoch: 3 [30720/48200 (64%)]\tLoss: 0.369785\n",
      "Train Epoch: 3 [31360/48200 (65%)]\tLoss: 0.092017\n",
      "Train Epoch: 3 [32000/48200 (66%)]\tLoss: 0.060308\n",
      "Train Epoch: 3 [32640/48200 (68%)]\tLoss: 0.216089\n",
      "Train Epoch: 3 [33280/48200 (69%)]\tLoss: 0.130905\n",
      "Train Epoch: 3 [33920/48200 (70%)]\tLoss: 0.157219\n",
      "Train Epoch: 3 [34560/48200 (72%)]\tLoss: 0.176096\n",
      "Train Epoch: 3 [35200/48200 (73%)]\tLoss: 0.247343\n",
      "Train Epoch: 3 [35840/48200 (74%)]\tLoss: 0.402680\n",
      "Train Epoch: 3 [36480/48200 (76%)]\tLoss: 0.117362\n",
      "Train Epoch: 3 [37120/48200 (77%)]\tLoss: 0.116862\n",
      "Train Epoch: 3 [37760/48200 (78%)]\tLoss: 0.210143\n",
      "Train Epoch: 3 [38400/48200 (80%)]\tLoss: 0.378541\n",
      "Train Epoch: 3 [39040/48200 (81%)]\tLoss: 0.256883\n",
      "Train Epoch: 3 [39680/48200 (82%)]\tLoss: 0.291593\n",
      "Train Epoch: 3 [40320/48200 (84%)]\tLoss: 0.344430\n",
      "Train Epoch: 3 [40960/48200 (85%)]\tLoss: 0.138233\n",
      "Train Epoch: 3 [41600/48200 (86%)]\tLoss: 0.141287\n",
      "Train Epoch: 3 [42240/48200 (88%)]\tLoss: 0.244725\n",
      "Train Epoch: 3 [42880/48200 (89%)]\tLoss: 0.073449\n",
      "Train Epoch: 3 [43520/48200 (90%)]\tLoss: 0.206679\n",
      "Train Epoch: 3 [44160/48200 (92%)]\tLoss: 0.144227\n",
      "Train Epoch: 3 [44800/48200 (93%)]\tLoss: 0.310460\n",
      "Train Epoch: 3 [45440/48200 (94%)]\tLoss: 0.366151\n",
      "Train Epoch: 3 [46080/48200 (95%)]\tLoss: 0.333815\n",
      "Train Epoch: 3 [46720/48200 (97%)]\tLoss: 0.138183\n",
      "Train Epoch: 3 [47360/48200 (98%)]\tLoss: 0.108869\n",
      "Train Epoch: 3 [48000/48200 (99%)]\tLoss: 0.132182\n",
      "\n",
      "Test set: Avg. loss: 0.0805, Accuracy: 7807/8017 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/48200 (0%)]\tLoss: 0.118352\n",
      "Train Epoch: 4 [640/48200 (1%)]\tLoss: 0.190738\n",
      "Train Epoch: 4 [1280/48200 (3%)]\tLoss: 0.191097\n",
      "Train Epoch: 4 [1920/48200 (4%)]\tLoss: 0.161166\n",
      "Train Epoch: 4 [2560/48200 (5%)]\tLoss: 0.314735\n",
      "Train Epoch: 4 [3200/48200 (7%)]\tLoss: 0.126862\n",
      "Train Epoch: 4 [3840/48200 (8%)]\tLoss: 0.171968\n",
      "Train Epoch: 4 [4480/48200 (9%)]\tLoss: 0.171187\n",
      "Train Epoch: 4 [5120/48200 (11%)]\tLoss: 0.157195\n",
      "Train Epoch: 4 [5760/48200 (12%)]\tLoss: 0.280166\n",
      "Train Epoch: 4 [6400/48200 (13%)]\tLoss: 0.150335\n",
      "Train Epoch: 4 [7040/48200 (15%)]\tLoss: 0.270069\n",
      "Train Epoch: 4 [7680/48200 (16%)]\tLoss: 0.471340\n",
      "Train Epoch: 4 [8320/48200 (17%)]\tLoss: 0.208607\n",
      "Train Epoch: 4 [8960/48200 (19%)]\tLoss: 0.179477\n",
      "Train Epoch: 4 [9600/48200 (20%)]\tLoss: 0.211719\n",
      "Train Epoch: 4 [10240/48200 (21%)]\tLoss: 0.094355\n",
      "Train Epoch: 4 [10880/48200 (23%)]\tLoss: 0.156873\n",
      "Train Epoch: 4 [11520/48200 (24%)]\tLoss: 0.153832\n",
      "Train Epoch: 4 [12160/48200 (25%)]\tLoss: 0.356248\n",
      "Train Epoch: 4 [12800/48200 (27%)]\tLoss: 0.162367\n",
      "Train Epoch: 4 [13440/48200 (28%)]\tLoss: 0.426901\n",
      "Train Epoch: 4 [14080/48200 (29%)]\tLoss: 0.209070\n",
      "Train Epoch: 4 [14720/48200 (31%)]\tLoss: 0.128152\n",
      "Train Epoch: 4 [15360/48200 (32%)]\tLoss: 0.240304\n",
      "Train Epoch: 4 [16000/48200 (33%)]\tLoss: 0.367592\n",
      "Train Epoch: 4 [16640/48200 (34%)]\tLoss: 0.195254\n",
      "Train Epoch: 4 [17280/48200 (36%)]\tLoss: 0.135404\n",
      "Train Epoch: 4 [17920/48200 (37%)]\tLoss: 0.257271\n",
      "Train Epoch: 4 [18560/48200 (38%)]\tLoss: 0.149297\n",
      "Train Epoch: 4 [19200/48200 (40%)]\tLoss: 0.137495\n",
      "Train Epoch: 4 [19840/48200 (41%)]\tLoss: 0.143699\n",
      "Train Epoch: 4 [20480/48200 (42%)]\tLoss: 0.097852\n",
      "Train Epoch: 4 [21120/48200 (44%)]\tLoss: 0.168934\n",
      "Train Epoch: 4 [21760/48200 (45%)]\tLoss: 0.200492\n",
      "Train Epoch: 4 [22400/48200 (46%)]\tLoss: 0.197109\n",
      "Train Epoch: 4 [23040/48200 (48%)]\tLoss: 0.273618\n",
      "Train Epoch: 4 [23680/48200 (49%)]\tLoss: 0.185830\n",
      "Train Epoch: 4 [24320/48200 (50%)]\tLoss: 0.177898\n",
      "Train Epoch: 4 [24960/48200 (52%)]\tLoss: 0.496138\n",
      "Train Epoch: 4 [25600/48200 (53%)]\tLoss: 0.210451\n",
      "Train Epoch: 4 [26240/48200 (54%)]\tLoss: 0.218814\n",
      "Train Epoch: 4 [26880/48200 (56%)]\tLoss: 0.612282\n",
      "Train Epoch: 4 [27520/48200 (57%)]\tLoss: 0.312825\n",
      "Train Epoch: 4 [28160/48200 (58%)]\tLoss: 0.190481\n",
      "Train Epoch: 4 [28800/48200 (60%)]\tLoss: 0.087406\n",
      "Train Epoch: 4 [29440/48200 (61%)]\tLoss: 0.184749\n",
      "Train Epoch: 4 [30080/48200 (62%)]\tLoss: 0.218152\n",
      "Train Epoch: 4 [30720/48200 (64%)]\tLoss: 0.249685\n",
      "Train Epoch: 4 [31360/48200 (65%)]\tLoss: 0.108382\n",
      "Train Epoch: 4 [32000/48200 (66%)]\tLoss: 0.251458\n",
      "Train Epoch: 4 [32640/48200 (68%)]\tLoss: 0.212876\n",
      "Train Epoch: 4 [33280/48200 (69%)]\tLoss: 0.162245\n",
      "Train Epoch: 4 [33920/48200 (70%)]\tLoss: 0.081375\n",
      "Train Epoch: 4 [34560/48200 (72%)]\tLoss: 0.131055\n",
      "Train Epoch: 4 [35200/48200 (73%)]\tLoss: 0.144670\n",
      "Train Epoch: 4 [35840/48200 (74%)]\tLoss: 0.058652\n",
      "Train Epoch: 4 [36480/48200 (76%)]\tLoss: 0.304656\n",
      "Train Epoch: 4 [37120/48200 (77%)]\tLoss: 0.140161\n",
      "Train Epoch: 4 [37760/48200 (78%)]\tLoss: 0.121390\n",
      "Train Epoch: 4 [38400/48200 (80%)]\tLoss: 0.062813\n",
      "Train Epoch: 4 [39040/48200 (81%)]\tLoss: 0.147723\n",
      "Train Epoch: 4 [39680/48200 (82%)]\tLoss: 0.187001\n",
      "Train Epoch: 4 [40320/48200 (84%)]\tLoss: 0.167115\n",
      "Train Epoch: 4 [40960/48200 (85%)]\tLoss: 0.128485\n",
      "Train Epoch: 4 [41600/48200 (86%)]\tLoss: 0.419909\n",
      "Train Epoch: 4 [42240/48200 (88%)]\tLoss: 0.217412\n",
      "Train Epoch: 4 [42880/48200 (89%)]\tLoss: 0.162152\n",
      "Train Epoch: 4 [43520/48200 (90%)]\tLoss: 0.206680\n",
      "Train Epoch: 4 [44160/48200 (92%)]\tLoss: 0.069479\n",
      "Train Epoch: 4 [44800/48200 (93%)]\tLoss: 0.165302\n",
      "Train Epoch: 4 [45440/48200 (94%)]\tLoss: 0.204444\n",
      "Train Epoch: 4 [46080/48200 (95%)]\tLoss: 0.143699\n",
      "Train Epoch: 4 [46720/48200 (97%)]\tLoss: 0.317344\n",
      "Train Epoch: 4 [47360/48200 (98%)]\tLoss: 0.147596\n",
      "Train Epoch: 4 [48000/48200 (99%)]\tLoss: 0.437624\n",
      "\n",
      "Test set: Avg. loss: 0.0661, Accuracy: 7835/8017 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/48200 (0%)]\tLoss: 0.161614\n",
      "Train Epoch: 5 [640/48200 (1%)]\tLoss: 0.149059\n",
      "Train Epoch: 5 [1280/48200 (3%)]\tLoss: 0.298157\n",
      "Train Epoch: 5 [1920/48200 (4%)]\tLoss: 0.145931\n",
      "Train Epoch: 5 [2560/48200 (5%)]\tLoss: 0.152272\n",
      "Train Epoch: 5 [3200/48200 (7%)]\tLoss: 0.370804\n",
      "Train Epoch: 5 [3840/48200 (8%)]\tLoss: 0.481439\n",
      "Train Epoch: 5 [4480/48200 (9%)]\tLoss: 0.150875\n",
      "Train Epoch: 5 [5120/48200 (11%)]\tLoss: 0.175330\n",
      "Train Epoch: 5 [5760/48200 (12%)]\tLoss: 0.134188\n",
      "Train Epoch: 5 [6400/48200 (13%)]\tLoss: 0.074730\n",
      "Train Epoch: 5 [7040/48200 (15%)]\tLoss: 0.103769\n",
      "Train Epoch: 5 [7680/48200 (16%)]\tLoss: 0.120175\n",
      "Train Epoch: 5 [8320/48200 (17%)]\tLoss: 0.505460\n",
      "Train Epoch: 5 [8960/48200 (19%)]\tLoss: 0.270367\n",
      "Train Epoch: 5 [9600/48200 (20%)]\tLoss: 0.107330\n",
      "Train Epoch: 5 [10240/48200 (21%)]\tLoss: 0.115815\n",
      "Train Epoch: 5 [10880/48200 (23%)]\tLoss: 0.141303\n",
      "Train Epoch: 5 [11520/48200 (24%)]\tLoss: 0.119370\n",
      "Train Epoch: 5 [12160/48200 (25%)]\tLoss: 0.300576\n",
      "Train Epoch: 5 [12800/48200 (27%)]\tLoss: 0.239046\n",
      "Train Epoch: 5 [13440/48200 (28%)]\tLoss: 0.185791\n",
      "Train Epoch: 5 [14080/48200 (29%)]\tLoss: 0.172847\n",
      "Train Epoch: 5 [14720/48200 (31%)]\tLoss: 0.239624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [15360/48200 (32%)]\tLoss: 0.130724\n",
      "Train Epoch: 5 [16000/48200 (33%)]\tLoss: 0.279688\n",
      "Train Epoch: 5 [16640/48200 (34%)]\tLoss: 0.179391\n",
      "Train Epoch: 5 [17280/48200 (36%)]\tLoss: 0.171943\n",
      "Train Epoch: 5 [17920/48200 (37%)]\tLoss: 0.193679\n",
      "Train Epoch: 5 [18560/48200 (38%)]\tLoss: 0.211494\n",
      "Train Epoch: 5 [19200/48200 (40%)]\tLoss: 0.176691\n",
      "Train Epoch: 5 [19840/48200 (41%)]\tLoss: 0.144760\n",
      "Train Epoch: 5 [20480/48200 (42%)]\tLoss: 0.235052\n",
      "Train Epoch: 5 [21120/48200 (44%)]\tLoss: 0.251301\n",
      "Train Epoch: 5 [21760/48200 (45%)]\tLoss: 0.065417\n",
      "Train Epoch: 5 [22400/48200 (46%)]\tLoss: 0.150386\n",
      "Train Epoch: 5 [23040/48200 (48%)]\tLoss: 0.189008\n",
      "Train Epoch: 5 [23680/48200 (49%)]\tLoss: 0.109398\n",
      "Train Epoch: 5 [24320/48200 (50%)]\tLoss: 0.247290\n",
      "Train Epoch: 5 [24960/48200 (52%)]\tLoss: 0.209570\n",
      "Train Epoch: 5 [25600/48200 (53%)]\tLoss: 0.096663\n",
      "Train Epoch: 5 [26240/48200 (54%)]\tLoss: 0.224310\n",
      "Train Epoch: 5 [26880/48200 (56%)]\tLoss: 0.101614\n",
      "Train Epoch: 5 [27520/48200 (57%)]\tLoss: 0.118140\n",
      "Train Epoch: 5 [28160/48200 (58%)]\tLoss: 0.104433\n",
      "Train Epoch: 5 [28800/48200 (60%)]\tLoss: 0.289248\n",
      "Train Epoch: 5 [29440/48200 (61%)]\tLoss: 0.296044\n",
      "Train Epoch: 5 [30080/48200 (62%)]\tLoss: 0.241915\n",
      "Train Epoch: 5 [30720/48200 (64%)]\tLoss: 0.423619\n",
      "Train Epoch: 5 [31360/48200 (65%)]\tLoss: 0.259227\n",
      "Train Epoch: 5 [32000/48200 (66%)]\tLoss: 0.058679\n",
      "Train Epoch: 5 [32640/48200 (68%)]\tLoss: 0.142529\n",
      "Train Epoch: 5 [33280/48200 (69%)]\tLoss: 0.149555\n",
      "Train Epoch: 5 [33920/48200 (70%)]\tLoss: 0.177661\n",
      "Train Epoch: 5 [34560/48200 (72%)]\tLoss: 0.310531\n",
      "Train Epoch: 5 [35200/48200 (73%)]\tLoss: 0.071262\n",
      "Train Epoch: 5 [35840/48200 (74%)]\tLoss: 0.136907\n",
      "Train Epoch: 5 [36480/48200 (76%)]\tLoss: 0.152330\n",
      "Train Epoch: 5 [37120/48200 (77%)]\tLoss: 0.091268\n",
      "Train Epoch: 5 [37760/48200 (78%)]\tLoss: 0.228161\n",
      "Train Epoch: 5 [38400/48200 (80%)]\tLoss: 0.239100\n",
      "Train Epoch: 5 [39040/48200 (81%)]\tLoss: 0.224595\n",
      "Train Epoch: 5 [39680/48200 (82%)]\tLoss: 0.126563\n",
      "Train Epoch: 5 [40320/48200 (84%)]\tLoss: 0.293960\n",
      "Train Epoch: 5 [40960/48200 (85%)]\tLoss: 0.122304\n",
      "Train Epoch: 5 [41600/48200 (86%)]\tLoss: 0.148056\n",
      "Train Epoch: 5 [42240/48200 (88%)]\tLoss: 0.194970\n",
      "Train Epoch: 5 [42880/48200 (89%)]\tLoss: 0.163118\n",
      "Train Epoch: 5 [43520/48200 (90%)]\tLoss: 0.146238\n",
      "Train Epoch: 5 [44160/48200 (92%)]\tLoss: 0.441091\n",
      "Train Epoch: 5 [44800/48200 (93%)]\tLoss: 0.070483\n",
      "Train Epoch: 5 [45440/48200 (94%)]\tLoss: 0.085692\n",
      "Train Epoch: 5 [46080/48200 (95%)]\tLoss: 0.274414\n",
      "Train Epoch: 5 [46720/48200 (97%)]\tLoss: 0.101319\n",
      "Train Epoch: 5 [47360/48200 (98%)]\tLoss: 0.191572\n",
      "Train Epoch: 5 [48000/48200 (99%)]\tLoss: 0.240339\n",
      "\n",
      "Test set: Avg. loss: 0.0601, Accuracy: 7859/8017 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/48200 (0%)]\tLoss: 0.045432\n",
      "Train Epoch: 6 [640/48200 (1%)]\tLoss: 0.173006\n",
      "Train Epoch: 6 [1280/48200 (3%)]\tLoss: 0.188601\n",
      "Train Epoch: 6 [1920/48200 (4%)]\tLoss: 0.267546\n",
      "Train Epoch: 6 [2560/48200 (5%)]\tLoss: 0.260779\n",
      "Train Epoch: 6 [3200/48200 (7%)]\tLoss: 0.115071\n",
      "Train Epoch: 6 [3840/48200 (8%)]\tLoss: 0.125421\n",
      "Train Epoch: 6 [4480/48200 (9%)]\tLoss: 0.102285\n",
      "Train Epoch: 6 [5120/48200 (11%)]\tLoss: 0.091904\n",
      "Train Epoch: 6 [5760/48200 (12%)]\tLoss: 0.231138\n",
      "Train Epoch: 6 [6400/48200 (13%)]\tLoss: 0.163605\n",
      "Train Epoch: 6 [7040/48200 (15%)]\tLoss: 0.081967\n",
      "Train Epoch: 6 [7680/48200 (16%)]\tLoss: 0.075602\n",
      "Train Epoch: 6 [8320/48200 (17%)]\tLoss: 0.265837\n",
      "Train Epoch: 6 [8960/48200 (19%)]\tLoss: 0.184473\n",
      "Train Epoch: 6 [9600/48200 (20%)]\tLoss: 0.108854\n",
      "Train Epoch: 6 [10240/48200 (21%)]\tLoss: 0.093712\n",
      "Train Epoch: 6 [10880/48200 (23%)]\tLoss: 0.081324\n",
      "Train Epoch: 6 [11520/48200 (24%)]\tLoss: 0.249854\n",
      "Train Epoch: 6 [12160/48200 (25%)]\tLoss: 0.100561\n",
      "Train Epoch: 6 [12800/48200 (27%)]\tLoss: 0.169328\n",
      "Train Epoch: 6 [13440/48200 (28%)]\tLoss: 0.206953\n",
      "Train Epoch: 6 [14080/48200 (29%)]\tLoss: 0.099078\n",
      "Train Epoch: 6 [14720/48200 (31%)]\tLoss: 0.097455\n",
      "Train Epoch: 6 [15360/48200 (32%)]\tLoss: 0.277362\n",
      "Train Epoch: 6 [16000/48200 (33%)]\tLoss: 0.142702\n",
      "Train Epoch: 6 [16640/48200 (34%)]\tLoss: 0.273207\n",
      "Train Epoch: 6 [17280/48200 (36%)]\tLoss: 0.195240\n",
      "Train Epoch: 6 [17920/48200 (37%)]\tLoss: 0.201494\n",
      "Train Epoch: 6 [18560/48200 (38%)]\tLoss: 0.066876\n",
      "Train Epoch: 6 [19200/48200 (40%)]\tLoss: 0.164911\n",
      "Train Epoch: 6 [19840/48200 (41%)]\tLoss: 0.200599\n",
      "Train Epoch: 6 [20480/48200 (42%)]\tLoss: 0.132437\n",
      "Train Epoch: 6 [21120/48200 (44%)]\tLoss: 0.062237\n",
      "Train Epoch: 6 [21760/48200 (45%)]\tLoss: 0.226228\n",
      "Train Epoch: 6 [22400/48200 (46%)]\tLoss: 0.173204\n",
      "Train Epoch: 6 [23040/48200 (48%)]\tLoss: 0.089752\n",
      "Train Epoch: 6 [23680/48200 (49%)]\tLoss: 0.103038\n",
      "Train Epoch: 6 [24320/48200 (50%)]\tLoss: 0.204897\n",
      "Train Epoch: 6 [24960/48200 (52%)]\tLoss: 0.046894\n",
      "Train Epoch: 6 [25600/48200 (53%)]\tLoss: 0.151488\n",
      "Train Epoch: 6 [26240/48200 (54%)]\tLoss: 0.176735\n",
      "Train Epoch: 6 [26880/48200 (56%)]\tLoss: 0.051804\n",
      "Train Epoch: 6 [27520/48200 (57%)]\tLoss: 0.063404\n",
      "Train Epoch: 6 [28160/48200 (58%)]\tLoss: 0.261634\n",
      "Train Epoch: 6 [28800/48200 (60%)]\tLoss: 0.091264\n",
      "Train Epoch: 6 [29440/48200 (61%)]\tLoss: 0.139442\n",
      "Train Epoch: 6 [30080/48200 (62%)]\tLoss: 0.198085\n",
      "Train Epoch: 6 [30720/48200 (64%)]\tLoss: 0.043056\n",
      "Train Epoch: 6 [31360/48200 (65%)]\tLoss: 0.174546\n",
      "Train Epoch: 6 [32000/48200 (66%)]\tLoss: 0.050334\n",
      "Train Epoch: 6 [32640/48200 (68%)]\tLoss: 0.106554\n",
      "Train Epoch: 6 [33280/48200 (69%)]\tLoss: 0.058265\n",
      "Train Epoch: 6 [33920/48200 (70%)]\tLoss: 0.145727\n",
      "Train Epoch: 6 [34560/48200 (72%)]\tLoss: 0.140916\n",
      "Train Epoch: 6 [35200/48200 (73%)]\tLoss: 0.064469\n",
      "Train Epoch: 6 [35840/48200 (74%)]\tLoss: 0.242116\n",
      "Train Epoch: 6 [36480/48200 (76%)]\tLoss: 0.216709\n",
      "Train Epoch: 6 [37120/48200 (77%)]\tLoss: 0.216465\n",
      "Train Epoch: 6 [37760/48200 (78%)]\tLoss: 0.204660\n",
      "Train Epoch: 6 [38400/48200 (80%)]\tLoss: 0.219785\n",
      "Train Epoch: 6 [39040/48200 (81%)]\tLoss: 0.495064\n",
      "Train Epoch: 6 [39680/48200 (82%)]\tLoss: 0.079773\n",
      "Train Epoch: 6 [40320/48200 (84%)]\tLoss: 0.148731\n",
      "Train Epoch: 6 [40960/48200 (85%)]\tLoss: 0.240375\n",
      "Train Epoch: 6 [41600/48200 (86%)]\tLoss: 0.185146\n",
      "Train Epoch: 6 [42240/48200 (88%)]\tLoss: 0.160939\n",
      "Train Epoch: 6 [42880/48200 (89%)]\tLoss: 0.061481\n",
      "Train Epoch: 6 [43520/48200 (90%)]\tLoss: 0.159520\n",
      "Train Epoch: 6 [44160/48200 (92%)]\tLoss: 0.146491\n",
      "Train Epoch: 6 [44800/48200 (93%)]\tLoss: 0.166413\n",
      "Train Epoch: 6 [45440/48200 (94%)]\tLoss: 0.322764\n",
      "Train Epoch: 6 [46080/48200 (95%)]\tLoss: 0.421789\n",
      "Train Epoch: 6 [46720/48200 (97%)]\tLoss: 0.219724\n",
      "Train Epoch: 6 [47360/48200 (98%)]\tLoss: 0.161654\n",
      "Train Epoch: 6 [48000/48200 (99%)]\tLoss: 0.140478\n",
      "\n",
      "Test set: Avg. loss: 0.0547, Accuracy: 7875/8017 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/48200 (0%)]\tLoss: 0.041839\n",
      "Train Epoch: 7 [640/48200 (1%)]\tLoss: 0.158753\n",
      "Train Epoch: 7 [1280/48200 (3%)]\tLoss: 0.166194\n",
      "Train Epoch: 7 [1920/48200 (4%)]\tLoss: 0.101463\n",
      "Train Epoch: 7 [2560/48200 (5%)]\tLoss: 0.092977\n",
      "Train Epoch: 7 [3200/48200 (7%)]\tLoss: 0.158628\n",
      "Train Epoch: 7 [3840/48200 (8%)]\tLoss: 0.217883\n",
      "Train Epoch: 7 [4480/48200 (9%)]\tLoss: 0.111355\n",
      "Train Epoch: 7 [5120/48200 (11%)]\tLoss: 0.191137\n",
      "Train Epoch: 7 [5760/48200 (12%)]\tLoss: 0.221944\n",
      "Train Epoch: 7 [6400/48200 (13%)]\tLoss: 0.375989\n",
      "Train Epoch: 7 [7040/48200 (15%)]\tLoss: 0.055798\n",
      "Train Epoch: 7 [7680/48200 (16%)]\tLoss: 0.031789\n",
      "Train Epoch: 7 [8320/48200 (17%)]\tLoss: 0.263036\n",
      "Train Epoch: 7 [8960/48200 (19%)]\tLoss: 0.150406\n",
      "Train Epoch: 7 [9600/48200 (20%)]\tLoss: 0.157336\n",
      "Train Epoch: 7 [10240/48200 (21%)]\tLoss: 0.201112\n",
      "Train Epoch: 7 [10880/48200 (23%)]\tLoss: 0.027742\n",
      "Train Epoch: 7 [11520/48200 (24%)]\tLoss: 0.077591\n",
      "Train Epoch: 7 [12160/48200 (25%)]\tLoss: 0.126951\n",
      "Train Epoch: 7 [12800/48200 (27%)]\tLoss: 0.280003\n",
      "Train Epoch: 7 [13440/48200 (28%)]\tLoss: 0.242744\n",
      "Train Epoch: 7 [14080/48200 (29%)]\tLoss: 0.168359\n",
      "Train Epoch: 7 [14720/48200 (31%)]\tLoss: 0.227230\n",
      "Train Epoch: 7 [15360/48200 (32%)]\tLoss: 0.326746\n",
      "Train Epoch: 7 [16000/48200 (33%)]\tLoss: 0.115852\n",
      "Train Epoch: 7 [16640/48200 (34%)]\tLoss: 0.298790\n",
      "Train Epoch: 7 [17280/48200 (36%)]\tLoss: 0.287936\n",
      "Train Epoch: 7 [17920/48200 (37%)]\tLoss: 0.112122\n",
      "Train Epoch: 7 [18560/48200 (38%)]\tLoss: 0.127850\n",
      "Train Epoch: 7 [19200/48200 (40%)]\tLoss: 0.203548\n",
      "Train Epoch: 7 [19840/48200 (41%)]\tLoss: 0.149229\n",
      "Train Epoch: 7 [20480/48200 (42%)]\tLoss: 0.557801\n",
      "Train Epoch: 7 [21120/48200 (44%)]\tLoss: 0.115822\n",
      "Train Epoch: 7 [21760/48200 (45%)]\tLoss: 0.050280\n",
      "Train Epoch: 7 [22400/48200 (46%)]\tLoss: 0.182672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [23040/48200 (48%)]\tLoss: 0.189784\n",
      "Train Epoch: 7 [23680/48200 (49%)]\tLoss: 0.285413\n",
      "Train Epoch: 7 [24320/48200 (50%)]\tLoss: 0.151739\n",
      "Train Epoch: 7 [24960/48200 (52%)]\tLoss: 0.093503\n",
      "Train Epoch: 7 [25600/48200 (53%)]\tLoss: 0.283423\n",
      "Train Epoch: 7 [26240/48200 (54%)]\tLoss: 0.151320\n",
      "Train Epoch: 7 [26880/48200 (56%)]\tLoss: 0.104477\n",
      "Train Epoch: 7 [27520/48200 (57%)]\tLoss: 0.118996\n",
      "Train Epoch: 7 [28160/48200 (58%)]\tLoss: 0.216587\n",
      "Train Epoch: 7 [28800/48200 (60%)]\tLoss: 0.110020\n",
      "Train Epoch: 7 [29440/48200 (61%)]\tLoss: 0.096755\n",
      "Train Epoch: 7 [30080/48200 (62%)]\tLoss: 0.170507\n",
      "Train Epoch: 7 [30720/48200 (64%)]\tLoss: 0.098796\n",
      "Train Epoch: 7 [31360/48200 (65%)]\tLoss: 0.112937\n",
      "Train Epoch: 7 [32000/48200 (66%)]\tLoss: 0.211110\n",
      "Train Epoch: 7 [32640/48200 (68%)]\tLoss: 0.178929\n",
      "Train Epoch: 7 [33280/48200 (69%)]\tLoss: 0.415125\n",
      "Train Epoch: 7 [33920/48200 (70%)]\tLoss: 0.129206\n",
      "Train Epoch: 7 [34560/48200 (72%)]\tLoss: 0.113458\n",
      "Train Epoch: 7 [35200/48200 (73%)]\tLoss: 0.105352\n",
      "Train Epoch: 7 [35840/48200 (74%)]\tLoss: 0.131477\n",
      "Train Epoch: 7 [36480/48200 (76%)]\tLoss: 0.167981\n",
      "Train Epoch: 7 [37120/48200 (77%)]\tLoss: 0.142083\n",
      "Train Epoch: 7 [37760/48200 (78%)]\tLoss: 0.061652\n",
      "Train Epoch: 7 [38400/48200 (80%)]\tLoss: 0.143534\n",
      "Train Epoch: 7 [39040/48200 (81%)]\tLoss: 0.145656\n",
      "Train Epoch: 7 [39680/48200 (82%)]\tLoss: 0.045793\n",
      "Train Epoch: 7 [40320/48200 (84%)]\tLoss: 0.178142\n",
      "Train Epoch: 7 [40960/48200 (85%)]\tLoss: 0.093971\n",
      "Train Epoch: 7 [41600/48200 (86%)]\tLoss: 0.147170\n",
      "Train Epoch: 7 [42240/48200 (88%)]\tLoss: 0.156735\n",
      "Train Epoch: 7 [42880/48200 (89%)]\tLoss: 0.297336\n",
      "Train Epoch: 7 [43520/48200 (90%)]\tLoss: 0.183085\n",
      "Train Epoch: 7 [44160/48200 (92%)]\tLoss: 0.072125\n",
      "Train Epoch: 7 [44800/48200 (93%)]\tLoss: 0.271674\n",
      "Train Epoch: 7 [45440/48200 (94%)]\tLoss: 0.093008\n",
      "Train Epoch: 7 [46080/48200 (95%)]\tLoss: 0.073395\n",
      "Train Epoch: 7 [46720/48200 (97%)]\tLoss: 0.102944\n",
      "Train Epoch: 7 [47360/48200 (98%)]\tLoss: 0.125981\n",
      "Train Epoch: 7 [48000/48200 (99%)]\tLoss: 0.125934\n",
      "\n",
      "Test set: Avg. loss: 0.0488, Accuracy: 7889/8017 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/48200 (0%)]\tLoss: 0.263384\n",
      "Train Epoch: 8 [640/48200 (1%)]\tLoss: 0.143792\n",
      "Train Epoch: 8 [1280/48200 (3%)]\tLoss: 0.044900\n",
      "Train Epoch: 8 [1920/48200 (4%)]\tLoss: 0.114223\n",
      "Train Epoch: 8 [2560/48200 (5%)]\tLoss: 0.103471\n",
      "Train Epoch: 8 [3200/48200 (7%)]\tLoss: 0.152213\n",
      "Train Epoch: 8 [3840/48200 (8%)]\tLoss: 0.074526\n",
      "Train Epoch: 8 [4480/48200 (9%)]\tLoss: 0.149352\n",
      "Train Epoch: 8 [5120/48200 (11%)]\tLoss: 0.345875\n",
      "Train Epoch: 8 [5760/48200 (12%)]\tLoss: 0.130299\n",
      "Train Epoch: 8 [6400/48200 (13%)]\tLoss: 0.121658\n",
      "Train Epoch: 8 [7040/48200 (15%)]\tLoss: 0.118288\n",
      "Train Epoch: 8 [7680/48200 (16%)]\tLoss: 0.097875\n",
      "Train Epoch: 8 [8320/48200 (17%)]\tLoss: 0.050516\n",
      "Train Epoch: 8 [8960/48200 (19%)]\tLoss: 0.194438\n",
      "Train Epoch: 8 [9600/48200 (20%)]\tLoss: 0.086100\n",
      "Train Epoch: 8 [10240/48200 (21%)]\tLoss: 0.100639\n",
      "Train Epoch: 8 [10880/48200 (23%)]\tLoss: 0.151115\n",
      "Train Epoch: 8 [11520/48200 (24%)]\tLoss: 0.144435\n",
      "Train Epoch: 8 [12160/48200 (25%)]\tLoss: 0.127333\n",
      "Train Epoch: 8 [12800/48200 (27%)]\tLoss: 0.174273\n",
      "Train Epoch: 8 [13440/48200 (28%)]\tLoss: 0.086231\n",
      "Train Epoch: 8 [14080/48200 (29%)]\tLoss: 0.167111\n",
      "Train Epoch: 8 [14720/48200 (31%)]\tLoss: 0.118231\n",
      "Train Epoch: 8 [15360/48200 (32%)]\tLoss: 0.111653\n",
      "Train Epoch: 8 [16000/48200 (33%)]\tLoss: 0.477348\n",
      "Train Epoch: 8 [16640/48200 (34%)]\tLoss: 0.084855\n",
      "Train Epoch: 8 [17280/48200 (36%)]\tLoss: 0.233669\n",
      "Train Epoch: 8 [17920/48200 (37%)]\tLoss: 0.235438\n",
      "Train Epoch: 8 [18560/48200 (38%)]\tLoss: 0.078005\n",
      "Train Epoch: 8 [19200/48200 (40%)]\tLoss: 0.179995\n",
      "Train Epoch: 8 [19840/48200 (41%)]\tLoss: 0.144593\n",
      "Train Epoch: 8 [20480/48200 (42%)]\tLoss: 0.245488\n",
      "Train Epoch: 8 [21120/48200 (44%)]\tLoss: 0.148878\n",
      "Train Epoch: 8 [21760/48200 (45%)]\tLoss: 0.150398\n",
      "Train Epoch: 8 [22400/48200 (46%)]\tLoss: 0.220386\n",
      "Train Epoch: 8 [23040/48200 (48%)]\tLoss: 0.096802\n",
      "Train Epoch: 8 [23680/48200 (49%)]\tLoss: 0.201011\n",
      "Train Epoch: 8 [24320/48200 (50%)]\tLoss: 0.156519\n",
      "Train Epoch: 8 [24960/48200 (52%)]\tLoss: 0.093583\n",
      "Train Epoch: 8 [25600/48200 (53%)]\tLoss: 0.065848\n",
      "Train Epoch: 8 [26240/48200 (54%)]\tLoss: 0.130861\n",
      "Train Epoch: 8 [26880/48200 (56%)]\tLoss: 0.215656\n",
      "Train Epoch: 8 [27520/48200 (57%)]\tLoss: 0.058210\n",
      "Train Epoch: 8 [28160/48200 (58%)]\tLoss: 0.134147\n",
      "Train Epoch: 8 [28800/48200 (60%)]\tLoss: 0.207924\n",
      "Train Epoch: 8 [29440/48200 (61%)]\tLoss: 0.139224\n",
      "Train Epoch: 8 [30080/48200 (62%)]\tLoss: 0.123215\n",
      "Train Epoch: 8 [30720/48200 (64%)]\tLoss: 0.127994\n",
      "Train Epoch: 8 [31360/48200 (65%)]\tLoss: 0.126330\n",
      "Train Epoch: 8 [32000/48200 (66%)]\tLoss: 0.093767\n",
      "Train Epoch: 8 [32640/48200 (68%)]\tLoss: 0.199658\n",
      "Train Epoch: 8 [33280/48200 (69%)]\tLoss: 0.062292\n",
      "Train Epoch: 8 [33920/48200 (70%)]\tLoss: 0.067371\n",
      "Train Epoch: 8 [34560/48200 (72%)]\tLoss: 0.075821\n",
      "Train Epoch: 8 [35200/48200 (73%)]\tLoss: 0.086992\n",
      "Train Epoch: 8 [35840/48200 (74%)]\tLoss: 0.199298\n",
      "Train Epoch: 8 [36480/48200 (76%)]\tLoss: 0.072128\n",
      "Train Epoch: 8 [37120/48200 (77%)]\tLoss: 0.116832\n",
      "Train Epoch: 8 [37760/48200 (78%)]\tLoss: 0.127776\n",
      "Train Epoch: 8 [38400/48200 (80%)]\tLoss: 0.149542\n",
      "Train Epoch: 8 [39040/48200 (81%)]\tLoss: 0.049944\n",
      "Train Epoch: 8 [39680/48200 (82%)]\tLoss: 0.122182\n",
      "Train Epoch: 8 [40320/48200 (84%)]\tLoss: 0.176117\n",
      "Train Epoch: 8 [40960/48200 (85%)]\tLoss: 0.194658\n",
      "Train Epoch: 8 [41600/48200 (86%)]\tLoss: 0.087268\n",
      "Train Epoch: 8 [42240/48200 (88%)]\tLoss: 0.245347\n",
      "Train Epoch: 8 [42880/48200 (89%)]\tLoss: 0.189454\n",
      "Train Epoch: 8 [43520/48200 (90%)]\tLoss: 0.094248\n",
      "Train Epoch: 8 [44160/48200 (92%)]\tLoss: 0.064910\n",
      "Train Epoch: 8 [44800/48200 (93%)]\tLoss: 0.306987\n",
      "Train Epoch: 8 [45440/48200 (94%)]\tLoss: 0.108627\n",
      "Train Epoch: 8 [46080/48200 (95%)]\tLoss: 0.075387\n",
      "Train Epoch: 8 [46720/48200 (97%)]\tLoss: 0.144678\n",
      "Train Epoch: 8 [47360/48200 (98%)]\tLoss: 0.101150\n",
      "Train Epoch: 8 [48000/48200 (99%)]\tLoss: 0.026396\n",
      "\n",
      "Test set: Avg. loss: 0.0475, Accuracy: 7902/8017 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/48200 (0%)]\tLoss: 0.121283\n",
      "Train Epoch: 9 [640/48200 (1%)]\tLoss: 0.154893\n",
      "Train Epoch: 9 [1280/48200 (3%)]\tLoss: 0.153727\n",
      "Train Epoch: 9 [1920/48200 (4%)]\tLoss: 0.109356\n",
      "Train Epoch: 9 [2560/48200 (5%)]\tLoss: 0.080958\n",
      "Train Epoch: 9 [3200/48200 (7%)]\tLoss: 0.115717\n",
      "Train Epoch: 9 [3840/48200 (8%)]\tLoss: 0.043683\n",
      "Train Epoch: 9 [4480/48200 (9%)]\tLoss: 0.068365\n",
      "Train Epoch: 9 [5120/48200 (11%)]\tLoss: 0.019906\n",
      "Train Epoch: 9 [5760/48200 (12%)]\tLoss: 0.186582\n",
      "Train Epoch: 9 [6400/48200 (13%)]\tLoss: 0.167679\n",
      "Train Epoch: 9 [7040/48200 (15%)]\tLoss: 0.033079\n",
      "Train Epoch: 9 [7680/48200 (16%)]\tLoss: 0.057972\n",
      "Train Epoch: 9 [8320/48200 (17%)]\tLoss: 0.251730\n",
      "Train Epoch: 9 [8960/48200 (19%)]\tLoss: 0.083830\n",
      "Train Epoch: 9 [9600/48200 (20%)]\tLoss: 0.166611\n",
      "Train Epoch: 9 [10240/48200 (21%)]\tLoss: 0.118204\n",
      "Train Epoch: 9 [10880/48200 (23%)]\tLoss: 0.044250\n",
      "Train Epoch: 9 [11520/48200 (24%)]\tLoss: 0.362694\n",
      "Train Epoch: 9 [12160/48200 (25%)]\tLoss: 0.247644\n",
      "Train Epoch: 9 [12800/48200 (27%)]\tLoss: 0.309233\n",
      "Train Epoch: 9 [13440/48200 (28%)]\tLoss: 0.095092\n",
      "Train Epoch: 9 [14080/48200 (29%)]\tLoss: 0.130964\n",
      "Train Epoch: 9 [14720/48200 (31%)]\tLoss: 0.137179\n",
      "Train Epoch: 9 [15360/48200 (32%)]\tLoss: 0.209255\n",
      "Train Epoch: 9 [16000/48200 (33%)]\tLoss: 0.095217\n",
      "Train Epoch: 9 [16640/48200 (34%)]\tLoss: 0.195468\n",
      "Train Epoch: 9 [17280/48200 (36%)]\tLoss: 0.133416\n",
      "Train Epoch: 9 [17920/48200 (37%)]\tLoss: 0.059929\n",
      "Train Epoch: 9 [18560/48200 (38%)]\tLoss: 0.272553\n",
      "Train Epoch: 9 [19200/48200 (40%)]\tLoss: 0.085575\n",
      "Train Epoch: 9 [19840/48200 (41%)]\tLoss: 0.202050\n",
      "Train Epoch: 9 [20480/48200 (42%)]\tLoss: 0.120396\n",
      "Train Epoch: 9 [21120/48200 (44%)]\tLoss: 0.040328\n",
      "Train Epoch: 9 [21760/48200 (45%)]\tLoss: 0.120288\n",
      "Train Epoch: 9 [22400/48200 (46%)]\tLoss: 0.048371\n",
      "Train Epoch: 9 [23040/48200 (48%)]\tLoss: 0.057922\n",
      "Train Epoch: 9 [23680/48200 (49%)]\tLoss: 0.134118\n",
      "Train Epoch: 9 [24320/48200 (50%)]\tLoss: 0.085292\n",
      "Train Epoch: 9 [24960/48200 (52%)]\tLoss: 0.148130\n",
      "Train Epoch: 9 [25600/48200 (53%)]\tLoss: 0.186601\n",
      "Train Epoch: 9 [26240/48200 (54%)]\tLoss: 0.086885\n",
      "Train Epoch: 9 [26880/48200 (56%)]\tLoss: 0.161303\n",
      "Train Epoch: 9 [27520/48200 (57%)]\tLoss: 0.189675\n",
      "Train Epoch: 9 [28160/48200 (58%)]\tLoss: 0.342631\n",
      "Train Epoch: 9 [28800/48200 (60%)]\tLoss: 0.083417\n",
      "Train Epoch: 9 [29440/48200 (61%)]\tLoss: 0.123517\n",
      "Train Epoch: 9 [30080/48200 (62%)]\tLoss: 0.133558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [30720/48200 (64%)]\tLoss: 0.111690\n",
      "Train Epoch: 9 [31360/48200 (65%)]\tLoss: 0.044955\n",
      "Train Epoch: 9 [32000/48200 (66%)]\tLoss: 0.263454\n",
      "Train Epoch: 9 [32640/48200 (68%)]\tLoss: 0.073768\n",
      "Train Epoch: 9 [33280/48200 (69%)]\tLoss: 0.128747\n",
      "Train Epoch: 9 [33920/48200 (70%)]\tLoss: 0.089640\n",
      "Train Epoch: 9 [34560/48200 (72%)]\tLoss: 0.579141\n",
      "Train Epoch: 9 [35200/48200 (73%)]\tLoss: 0.162319\n",
      "Train Epoch: 9 [35840/48200 (74%)]\tLoss: 0.213115\n",
      "Train Epoch: 9 [36480/48200 (76%)]\tLoss: 0.061674\n",
      "Train Epoch: 9 [37120/48200 (77%)]\tLoss: 0.081147\n",
      "Train Epoch: 9 [37760/48200 (78%)]\tLoss: 0.044464\n",
      "Train Epoch: 9 [38400/48200 (80%)]\tLoss: 0.104212\n",
      "Train Epoch: 9 [39040/48200 (81%)]\tLoss: 0.129581\n",
      "Train Epoch: 9 [39680/48200 (82%)]\tLoss: 0.106596\n",
      "Train Epoch: 9 [40320/48200 (84%)]\tLoss: 0.047931\n",
      "Train Epoch: 9 [40960/48200 (85%)]\tLoss: 0.074869\n",
      "Train Epoch: 9 [41600/48200 (86%)]\tLoss: 0.035494\n",
      "Train Epoch: 9 [42240/48200 (88%)]\tLoss: 0.052306\n",
      "Train Epoch: 9 [42880/48200 (89%)]\tLoss: 0.124216\n",
      "Train Epoch: 9 [43520/48200 (90%)]\tLoss: 0.060908\n",
      "Train Epoch: 9 [44160/48200 (92%)]\tLoss: 0.117909\n",
      "Train Epoch: 9 [44800/48200 (93%)]\tLoss: 0.174113\n",
      "Train Epoch: 9 [45440/48200 (94%)]\tLoss: 0.058604\n",
      "Train Epoch: 9 [46080/48200 (95%)]\tLoss: 0.203883\n",
      "Train Epoch: 9 [46720/48200 (97%)]\tLoss: 0.074199\n",
      "Train Epoch: 9 [47360/48200 (98%)]\tLoss: 0.149097\n",
      "Train Epoch: 9 [48000/48200 (99%)]\tLoss: 0.075623\n",
      "\n",
      "Test set: Avg. loss: 0.0439, Accuracy: 7906/8017 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/48200 (0%)]\tLoss: 0.111935\n",
      "Train Epoch: 10 [640/48200 (1%)]\tLoss: 0.180461\n",
      "Train Epoch: 10 [1280/48200 (3%)]\tLoss: 0.187565\n",
      "Train Epoch: 10 [1920/48200 (4%)]\tLoss: 0.203701\n",
      "Train Epoch: 10 [2560/48200 (5%)]\tLoss: 0.084508\n",
      "Train Epoch: 10 [3200/48200 (7%)]\tLoss: 0.126757\n",
      "Train Epoch: 10 [3840/48200 (8%)]\tLoss: 0.069765\n",
      "Train Epoch: 10 [4480/48200 (9%)]\tLoss: 0.080528\n",
      "Train Epoch: 10 [5120/48200 (11%)]\tLoss: 0.058373\n",
      "Train Epoch: 10 [5760/48200 (12%)]\tLoss: 0.040314\n",
      "Train Epoch: 10 [6400/48200 (13%)]\tLoss: 0.158507\n",
      "Train Epoch: 10 [7040/48200 (15%)]\tLoss: 0.080071\n",
      "Train Epoch: 10 [7680/48200 (16%)]\tLoss: 0.055616\n",
      "Train Epoch: 10 [8320/48200 (17%)]\tLoss: 0.181940\n",
      "Train Epoch: 10 [8960/48200 (19%)]\tLoss: 0.062371\n",
      "Train Epoch: 10 [9600/48200 (20%)]\tLoss: 0.156104\n",
      "Train Epoch: 10 [10240/48200 (21%)]\tLoss: 0.099517\n",
      "Train Epoch: 10 [10880/48200 (23%)]\tLoss: 0.042272\n",
      "Train Epoch: 10 [11520/48200 (24%)]\tLoss: 0.116458\n",
      "Train Epoch: 10 [12160/48200 (25%)]\tLoss: 0.137423\n",
      "Train Epoch: 10 [12800/48200 (27%)]\tLoss: 0.038759\n",
      "Train Epoch: 10 [13440/48200 (28%)]\tLoss: 0.096938\n",
      "Train Epoch: 10 [14080/48200 (29%)]\tLoss: 0.226721\n",
      "Train Epoch: 10 [14720/48200 (31%)]\tLoss: 0.265814\n",
      "Train Epoch: 10 [15360/48200 (32%)]\tLoss: 0.040305\n",
      "Train Epoch: 10 [16000/48200 (33%)]\tLoss: 0.342428\n",
      "Train Epoch: 10 [16640/48200 (34%)]\tLoss: 0.260709\n",
      "Train Epoch: 10 [17280/48200 (36%)]\tLoss: 0.113911\n",
      "Train Epoch: 10 [17920/48200 (37%)]\tLoss: 0.046669\n",
      "Train Epoch: 10 [18560/48200 (38%)]\tLoss: 0.046771\n",
      "Train Epoch: 10 [19200/48200 (40%)]\tLoss: 0.120545\n",
      "Train Epoch: 10 [19840/48200 (41%)]\tLoss: 0.057522\n",
      "Train Epoch: 10 [20480/48200 (42%)]\tLoss: 0.086169\n",
      "Train Epoch: 10 [21120/48200 (44%)]\tLoss: 0.084615\n",
      "Train Epoch: 10 [21760/48200 (45%)]\tLoss: 0.175391\n",
      "Train Epoch: 10 [22400/48200 (46%)]\tLoss: 0.100355\n",
      "Train Epoch: 10 [23040/48200 (48%)]\tLoss: 0.096386\n",
      "Train Epoch: 10 [23680/48200 (49%)]\tLoss: 0.030552\n",
      "Train Epoch: 10 [24320/48200 (50%)]\tLoss: 0.188395\n",
      "Train Epoch: 10 [24960/48200 (52%)]\tLoss: 0.104771\n",
      "Train Epoch: 10 [25600/48200 (53%)]\tLoss: 0.051044\n",
      "Train Epoch: 10 [26240/48200 (54%)]\tLoss: 0.093244\n",
      "Train Epoch: 10 [26880/48200 (56%)]\tLoss: 0.198946\n",
      "Train Epoch: 10 [27520/48200 (57%)]\tLoss: 0.099015\n",
      "Train Epoch: 10 [28160/48200 (58%)]\tLoss: 0.052080\n",
      "Train Epoch: 10 [28800/48200 (60%)]\tLoss: 0.064058\n",
      "Train Epoch: 10 [29440/48200 (61%)]\tLoss: 0.045097\n",
      "Train Epoch: 10 [30080/48200 (62%)]\tLoss: 0.246440\n",
      "Train Epoch: 10 [30720/48200 (64%)]\tLoss: 0.232736\n",
      "Train Epoch: 10 [31360/48200 (65%)]\tLoss: 0.088140\n",
      "Train Epoch: 10 [32000/48200 (66%)]\tLoss: 0.295989\n",
      "Train Epoch: 10 [32640/48200 (68%)]\tLoss: 0.074365\n",
      "Train Epoch: 10 [33280/48200 (69%)]\tLoss: 0.140727\n",
      "Train Epoch: 10 [33920/48200 (70%)]\tLoss: 0.060969\n",
      "Train Epoch: 10 [34560/48200 (72%)]\tLoss: 0.118065\n",
      "Train Epoch: 10 [35200/48200 (73%)]\tLoss: 0.022774\n",
      "Train Epoch: 10 [35840/48200 (74%)]\tLoss: 0.035563\n",
      "Train Epoch: 10 [36480/48200 (76%)]\tLoss: 0.199828\n",
      "Train Epoch: 10 [37120/48200 (77%)]\tLoss: 0.133822\n",
      "Train Epoch: 10 [37760/48200 (78%)]\tLoss: 0.132255\n",
      "Train Epoch: 10 [38400/48200 (80%)]\tLoss: 0.082939\n",
      "Train Epoch: 10 [39040/48200 (81%)]\tLoss: 0.050354\n",
      "Train Epoch: 10 [39680/48200 (82%)]\tLoss: 0.061130\n",
      "Train Epoch: 10 [40320/48200 (84%)]\tLoss: 0.053676\n",
      "Train Epoch: 10 [40960/48200 (85%)]\tLoss: 0.216496\n",
      "Train Epoch: 10 [41600/48200 (86%)]\tLoss: 0.086198\n",
      "Train Epoch: 10 [42240/48200 (88%)]\tLoss: 0.174028\n",
      "Train Epoch: 10 [42880/48200 (89%)]\tLoss: 0.162355\n",
      "Train Epoch: 10 [43520/48200 (90%)]\tLoss: 0.114042\n",
      "Train Epoch: 10 [44160/48200 (92%)]\tLoss: 0.124129\n",
      "Train Epoch: 10 [44800/48200 (93%)]\tLoss: 0.053903\n",
      "Train Epoch: 10 [45440/48200 (94%)]\tLoss: 0.135826\n",
      "Train Epoch: 10 [46080/48200 (95%)]\tLoss: 0.119422\n",
      "Train Epoch: 10 [46720/48200 (97%)]\tLoss: 0.088617\n",
      "Train Epoch: 10 [47360/48200 (98%)]\tLoss: 0.117675\n",
      "Train Epoch: 10 [48000/48200 (99%)]\tLoss: 0.074009\n",
      "\n",
      "Test set: Avg. loss: 0.0422, Accuracy: 7911/8017 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net_c8 = Net_c8().cuda()\n",
    "n_epochs = 10\n",
    "optimizer = optim.SGD(net_c8.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader8.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "test(net_c8, test_loader8)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net_c8, train_loader8, epoch)\n",
    "    test(net_c8, test_loader8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00349753, 0.00349753, 0.        , 0.00349753, 0.0139901 ,\n",
       "        0.00699505, 0.03147773, 0.02448268, 0.01049258, 0.03847278,\n",
       "        0.07344804, 0.04197031, 0.08743815, 0.09093567, 0.06645299,\n",
       "        0.11192083, 0.11541835, 0.06995052, 0.15039361, 0.11541835,\n",
       "        0.13640351, 0.13640351, 0.18187134, 0.22733918, 0.19236392,\n",
       "        0.17487629, 0.22733918, 0.18187134, 0.18187134, 0.19236392,\n",
       "        0.17137877, 0.21334908, 0.25182186, 0.21334908, 0.20635403,\n",
       "        0.19935897, 0.21334908, 0.16788124, 0.19586145, 0.13290598,\n",
       "        0.16438372, 0.12940846, 0.15738866, 0.12591093, 0.13640351,\n",
       "        0.11891588, 0.11541835, 0.09093567, 0.08743815, 0.09093567,\n",
       "        0.08743815, 0.06295547, 0.08394062, 0.06995052, 0.05246289,\n",
       "        0.06295547, 0.04546784, 0.03497526, 0.02798021, 0.03147773,\n",
       "        0.04546784, 0.02448268, 0.02798021, 0.00699505, 0.02798021,\n",
       "        0.0139901 , 0.01049258, 0.01748763, 0.01748763, 0.0139901 ,\n",
       "        0.02448268, 0.01049258, 0.01748763, 0.0139901 , 0.0139901 ,\n",
       "        0.00349753, 0.00349753, 0.00699505, 0.00699505, 0.        ,\n",
       "        0.        , 0.00699505, 0.        , 0.00349753, 0.        ,\n",
       "        0.00699505, 0.01049258, 0.00349753, 0.00349753, 0.        ,\n",
       "        0.00349753, 0.        , 0.00349753, 0.        , 0.00349753,\n",
       "        0.        , 0.        , 0.        , 0.00349753, 0.00349753]),\n",
       " array([ 5.44577961,  5.58873781,  5.73169601,  5.8746542 ,  6.0176124 ,\n",
       "         6.1605706 ,  6.3035288 ,  6.446487  ,  6.5894452 ,  6.7324034 ,\n",
       "         6.8753616 ,  7.0183198 ,  7.161278  ,  7.3042362 ,  7.4471944 ,\n",
       "         7.5901526 ,  7.7331108 ,  7.876069  ,  8.0190272 ,  8.1619854 ,\n",
       "         8.3049436 ,  8.4479018 ,  8.59086   ,  8.7338182 ,  8.8767764 ,\n",
       "         9.0197346 ,  9.1626928 ,  9.305651  ,  9.4486092 ,  9.5915674 ,\n",
       "         9.7345256 ,  9.8774838 , 10.020442  , 10.1634002 , 10.3063584 ,\n",
       "        10.4493166 , 10.5922748 , 10.735233  , 10.8781912 , 11.0211494 ,\n",
       "        11.1641076 , 11.3070658 , 11.450024  , 11.5929822 , 11.7359404 ,\n",
       "        11.8788986 , 12.0218568 , 12.164815  , 12.3077732 , 12.4507314 ,\n",
       "        12.5936896 , 12.7366478 , 12.879606  , 13.0225642 , 13.1655224 ,\n",
       "        13.3084806 , 13.4514388 , 13.594397  , 13.7373552 , 13.8803134 ,\n",
       "        14.0232716 , 14.1662298 , 14.309188  , 14.4521462 , 14.5951044 ,\n",
       "        14.7380626 , 14.8810208 , 15.023979  , 15.1669372 , 15.3098954 ,\n",
       "        15.4528536 , 15.5958118 , 15.73876999, 15.88172819, 16.02468639,\n",
       "        16.16764459, 16.31060279, 16.45356099, 16.59651919, 16.73947739,\n",
       "        16.88243559, 17.02539379, 17.16835199, 17.31131019, 17.45426839,\n",
       "        17.59722659, 17.74018479, 17.88314299, 18.02610119, 18.16905939,\n",
       "        18.31201759, 18.45497579, 18.59793399, 18.74089219, 18.88385039,\n",
       "        19.02680859, 19.16976679, 19.31272499, 19.45568319, 19.59864139,\n",
       "        19.74159959]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = net_c8(noise.cuda())\n",
    "ll = net_c8.last\n",
    "print(ll.shape)\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net1_c8 = LID(ll, ll, k=50)\n",
    "plt.hist(lid_net1_c8, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2_c8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2_c8, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 100)\n",
    "        self.fc2 = nn.Linear(100, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.0767, Accuracy: 1093/8017 (13%)\n",
      "\n",
      "Train Epoch: 1 [0/48200 (0%)]\tLoss: 2.124532\n",
      "Train Epoch: 1 [640/48200 (1%)]\tLoss: 2.080121\n",
      "Train Epoch: 1 [1280/48200 (3%)]\tLoss: 2.001012\n",
      "Train Epoch: 1 [1920/48200 (4%)]\tLoss: 2.000285\n",
      "Train Epoch: 1 [2560/48200 (5%)]\tLoss: 1.937588\n",
      "Train Epoch: 1 [3200/48200 (7%)]\tLoss: 1.935493\n",
      "Train Epoch: 1 [3840/48200 (8%)]\tLoss: 1.729519\n",
      "Train Epoch: 1 [4480/48200 (9%)]\tLoss: 1.619585\n",
      "Train Epoch: 1 [5120/48200 (11%)]\tLoss: 1.392503\n",
      "Train Epoch: 1 [5760/48200 (12%)]\tLoss: 1.315869\n",
      "Train Epoch: 1 [6400/48200 (13%)]\tLoss: 1.125140\n",
      "Train Epoch: 1 [7040/48200 (15%)]\tLoss: 1.302177\n",
      "Train Epoch: 1 [7680/48200 (16%)]\tLoss: 0.987594\n",
      "Train Epoch: 1 [8320/48200 (17%)]\tLoss: 0.975525\n",
      "Train Epoch: 1 [8960/48200 (19%)]\tLoss: 0.838939\n",
      "Train Epoch: 1 [9600/48200 (20%)]\tLoss: 0.667607\n",
      "Train Epoch: 1 [10240/48200 (21%)]\tLoss: 0.614115\n",
      "Train Epoch: 1 [10880/48200 (23%)]\tLoss: 0.755726\n",
      "Train Epoch: 1 [11520/48200 (24%)]\tLoss: 0.767577\n",
      "Train Epoch: 1 [12160/48200 (25%)]\tLoss: 0.550053\n",
      "Train Epoch: 1 [12800/48200 (27%)]\tLoss: 0.647598\n",
      "Train Epoch: 1 [13440/48200 (28%)]\tLoss: 0.349948\n",
      "Train Epoch: 1 [14080/48200 (29%)]\tLoss: 0.656696\n",
      "Train Epoch: 1 [14720/48200 (31%)]\tLoss: 0.630770\n",
      "Train Epoch: 1 [15360/48200 (32%)]\tLoss: 0.842787\n",
      "Train Epoch: 1 [16000/48200 (33%)]\tLoss: 0.674240\n",
      "Train Epoch: 1 [16640/48200 (34%)]\tLoss: 0.492652\n",
      "Train Epoch: 1 [17280/48200 (36%)]\tLoss: 0.445517\n",
      "Train Epoch: 1 [17920/48200 (37%)]\tLoss: 0.402180\n",
      "Train Epoch: 1 [18560/48200 (38%)]\tLoss: 0.594522\n",
      "Train Epoch: 1 [19200/48200 (40%)]\tLoss: 0.462573\n",
      "Train Epoch: 1 [19840/48200 (41%)]\tLoss: 0.487662\n",
      "Train Epoch: 1 [20480/48200 (42%)]\tLoss: 0.367314\n",
      "Train Epoch: 1 [21120/48200 (44%)]\tLoss: 0.695602\n",
      "Train Epoch: 1 [21760/48200 (45%)]\tLoss: 0.311472\n",
      "Train Epoch: 1 [22400/48200 (46%)]\tLoss: 0.378950\n",
      "Train Epoch: 1 [23040/48200 (48%)]\tLoss: 0.394401\n",
      "Train Epoch: 1 [23680/48200 (49%)]\tLoss: 0.429446\n",
      "Train Epoch: 1 [24320/48200 (50%)]\tLoss: 0.364957\n",
      "Train Epoch: 1 [24960/48200 (52%)]\tLoss: 0.291565\n",
      "Train Epoch: 1 [25600/48200 (53%)]\tLoss: 0.257606\n",
      "Train Epoch: 1 [26240/48200 (54%)]\tLoss: 0.544920\n",
      "Train Epoch: 1 [26880/48200 (56%)]\tLoss: 0.296871\n",
      "Train Epoch: 1 [27520/48200 (57%)]\tLoss: 0.391908\n",
      "Train Epoch: 1 [28160/48200 (58%)]\tLoss: 0.331755\n",
      "Train Epoch: 1 [28800/48200 (60%)]\tLoss: 0.356028\n",
      "Train Epoch: 1 [29440/48200 (61%)]\tLoss: 0.421067\n",
      "Train Epoch: 1 [30080/48200 (62%)]\tLoss: 0.272145\n",
      "Train Epoch: 1 [30720/48200 (64%)]\tLoss: 0.288383\n",
      "Train Epoch: 1 [31360/48200 (65%)]\tLoss: 0.369477\n",
      "Train Epoch: 1 [32000/48200 (66%)]\tLoss: 0.470187\n",
      "Train Epoch: 1 [32640/48200 (68%)]\tLoss: 0.540029\n",
      "Train Epoch: 1 [33280/48200 (69%)]\tLoss: 0.279893\n",
      "Train Epoch: 1 [33920/48200 (70%)]\tLoss: 0.442606\n",
      "Train Epoch: 1 [34560/48200 (72%)]\tLoss: 0.330463\n",
      "Train Epoch: 1 [35200/48200 (73%)]\tLoss: 0.368529\n",
      "Train Epoch: 1 [35840/48200 (74%)]\tLoss: 0.156131\n",
      "Train Epoch: 1 [36480/48200 (76%)]\tLoss: 0.352231\n",
      "Train Epoch: 1 [37120/48200 (77%)]\tLoss: 0.326367\n",
      "Train Epoch: 1 [37760/48200 (78%)]\tLoss: 0.331793\n",
      "Train Epoch: 1 [38400/48200 (80%)]\tLoss: 0.332641\n",
      "Train Epoch: 1 [39040/48200 (81%)]\tLoss: 0.432590\n",
      "Train Epoch: 1 [39680/48200 (82%)]\tLoss: 0.286784\n",
      "Train Epoch: 1 [40320/48200 (84%)]\tLoss: 0.180888\n",
      "Train Epoch: 1 [40960/48200 (85%)]\tLoss: 0.401534\n",
      "Train Epoch: 1 [41600/48200 (86%)]\tLoss: 0.298622\n",
      "Train Epoch: 1 [42240/48200 (88%)]\tLoss: 0.411037\n",
      "Train Epoch: 1 [42880/48200 (89%)]\tLoss: 0.371138\n",
      "Train Epoch: 1 [43520/48200 (90%)]\tLoss: 0.184646\n",
      "Train Epoch: 1 [44160/48200 (92%)]\tLoss: 0.341204\n",
      "Train Epoch: 1 [44800/48200 (93%)]\tLoss: 0.306605\n",
      "Train Epoch: 1 [45440/48200 (94%)]\tLoss: 0.189648\n",
      "Train Epoch: 1 [46080/48200 (95%)]\tLoss: 0.296901\n",
      "Train Epoch: 1 [46720/48200 (97%)]\tLoss: 0.190077\n",
      "Train Epoch: 1 [47360/48200 (98%)]\tLoss: 0.273539\n",
      "Train Epoch: 1 [48000/48200 (99%)]\tLoss: 0.241510\n",
      "\n",
      "Test set: Avg. loss: 0.1218, Accuracy: 7716/8017 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/48200 (0%)]\tLoss: 0.399077\n",
      "Train Epoch: 2 [640/48200 (1%)]\tLoss: 0.261044\n",
      "Train Epoch: 2 [1280/48200 (3%)]\tLoss: 0.559918\n",
      "Train Epoch: 2 [1920/48200 (4%)]\tLoss: 0.162571\n",
      "Train Epoch: 2 [2560/48200 (5%)]\tLoss: 0.382858\n",
      "Train Epoch: 2 [3200/48200 (7%)]\tLoss: 0.347829\n",
      "Train Epoch: 2 [3840/48200 (8%)]\tLoss: 0.158901\n",
      "Train Epoch: 2 [4480/48200 (9%)]\tLoss: 0.242240\n",
      "Train Epoch: 2 [5120/48200 (11%)]\tLoss: 0.549883\n",
      "Train Epoch: 2 [5760/48200 (12%)]\tLoss: 0.291869\n",
      "Train Epoch: 2 [6400/48200 (13%)]\tLoss: 0.190454\n",
      "Train Epoch: 2 [7040/48200 (15%)]\tLoss: 0.207747\n",
      "Train Epoch: 2 [7680/48200 (16%)]\tLoss: 0.119367\n",
      "Train Epoch: 2 [8320/48200 (17%)]\tLoss: 0.163328\n",
      "Train Epoch: 2 [8960/48200 (19%)]\tLoss: 0.090984\n",
      "Train Epoch: 2 [9600/48200 (20%)]\tLoss: 0.148798\n",
      "Train Epoch: 2 [10240/48200 (21%)]\tLoss: 0.139144\n",
      "Train Epoch: 2 [10880/48200 (23%)]\tLoss: 0.244685\n",
      "Train Epoch: 2 [11520/48200 (24%)]\tLoss: 0.335252\n",
      "Train Epoch: 2 [12160/48200 (25%)]\tLoss: 0.215910\n",
      "Train Epoch: 2 [12800/48200 (27%)]\tLoss: 0.104801\n",
      "Train Epoch: 2 [13440/48200 (28%)]\tLoss: 0.351539\n",
      "Train Epoch: 2 [14080/48200 (29%)]\tLoss: 0.315677\n",
      "Train Epoch: 2 [14720/48200 (31%)]\tLoss: 0.173974\n",
      "Train Epoch: 2 [15360/48200 (32%)]\tLoss: 0.236859\n",
      "Train Epoch: 2 [16000/48200 (33%)]\tLoss: 0.328457\n",
      "Train Epoch: 2 [16640/48200 (34%)]\tLoss: 0.140235\n",
      "Train Epoch: 2 [17280/48200 (36%)]\tLoss: 0.443850\n",
      "Train Epoch: 2 [17920/48200 (37%)]\tLoss: 0.207801\n",
      "Train Epoch: 2 [18560/48200 (38%)]\tLoss: 0.142057\n",
      "Train Epoch: 2 [19200/48200 (40%)]\tLoss: 0.172684\n",
      "Train Epoch: 2 [19840/48200 (41%)]\tLoss: 0.247571\n",
      "Train Epoch: 2 [20480/48200 (42%)]\tLoss: 0.232745\n",
      "Train Epoch: 2 [21120/48200 (44%)]\tLoss: 0.337171\n",
      "Train Epoch: 2 [21760/48200 (45%)]\tLoss: 0.186813\n",
      "Train Epoch: 2 [22400/48200 (46%)]\tLoss: 0.153906\n",
      "Train Epoch: 2 [23040/48200 (48%)]\tLoss: 0.135990\n",
      "Train Epoch: 2 [23680/48200 (49%)]\tLoss: 0.176966\n",
      "Train Epoch: 2 [24320/48200 (50%)]\tLoss: 0.171495\n",
      "Train Epoch: 2 [24960/48200 (52%)]\tLoss: 0.348241\n",
      "Train Epoch: 2 [25600/48200 (53%)]\tLoss: 0.075650\n",
      "Train Epoch: 2 [26240/48200 (54%)]\tLoss: 0.113921\n",
      "Train Epoch: 2 [26880/48200 (56%)]\tLoss: 0.240038\n",
      "Train Epoch: 2 [27520/48200 (57%)]\tLoss: 0.142230\n",
      "Train Epoch: 2 [28160/48200 (58%)]\tLoss: 0.167907\n",
      "Train Epoch: 2 [28800/48200 (60%)]\tLoss: 0.182548\n",
      "Train Epoch: 2 [29440/48200 (61%)]\tLoss: 0.187350\n",
      "Train Epoch: 2 [30080/48200 (62%)]\tLoss: 0.276264\n",
      "Train Epoch: 2 [30720/48200 (64%)]\tLoss: 0.222055\n",
      "Train Epoch: 2 [31360/48200 (65%)]\tLoss: 0.268878\n",
      "Train Epoch: 2 [32000/48200 (66%)]\tLoss: 0.272270\n",
      "Train Epoch: 2 [32640/48200 (68%)]\tLoss: 0.177273\n",
      "Train Epoch: 2 [33280/48200 (69%)]\tLoss: 0.119907\n",
      "Train Epoch: 2 [33920/48200 (70%)]\tLoss: 0.126845\n",
      "Train Epoch: 2 [34560/48200 (72%)]\tLoss: 0.096615\n",
      "Train Epoch: 2 [35200/48200 (73%)]\tLoss: 0.200391\n",
      "Train Epoch: 2 [35840/48200 (74%)]\tLoss: 0.228527\n",
      "Train Epoch: 2 [36480/48200 (76%)]\tLoss: 0.412660\n",
      "Train Epoch: 2 [37120/48200 (77%)]\tLoss: 0.353553\n",
      "Train Epoch: 2 [37760/48200 (78%)]\tLoss: 0.209105\n",
      "Train Epoch: 2 [38400/48200 (80%)]\tLoss: 0.133392\n",
      "Train Epoch: 2 [39040/48200 (81%)]\tLoss: 0.134824\n",
      "Train Epoch: 2 [39680/48200 (82%)]\tLoss: 0.233396\n",
      "Train Epoch: 2 [40320/48200 (84%)]\tLoss: 0.069083\n",
      "Train Epoch: 2 [40960/48200 (85%)]\tLoss: 0.096448\n",
      "Train Epoch: 2 [41600/48200 (86%)]\tLoss: 0.165116\n",
      "Train Epoch: 2 [42240/48200 (88%)]\tLoss: 0.187566\n",
      "Train Epoch: 2 [42880/48200 (89%)]\tLoss: 0.374261\n",
      "Train Epoch: 2 [43520/48200 (90%)]\tLoss: 0.332986\n",
      "Train Epoch: 2 [44160/48200 (92%)]\tLoss: 0.196882\n",
      "Train Epoch: 2 [44800/48200 (93%)]\tLoss: 0.396504\n",
      "Train Epoch: 2 [45440/48200 (94%)]\tLoss: 0.128694\n",
      "Train Epoch: 2 [46080/48200 (95%)]\tLoss: 0.281307\n",
      "Train Epoch: 2 [46720/48200 (97%)]\tLoss: 0.227474\n",
      "Train Epoch: 2 [47360/48200 (98%)]\tLoss: 0.311865\n",
      "Train Epoch: 2 [48000/48200 (99%)]\tLoss: 0.233466\n",
      "\n",
      "Test set: Avg. loss: 0.0832, Accuracy: 7806/8017 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/48200 (0%)]\tLoss: 0.196420\n",
      "Train Epoch: 3 [640/48200 (1%)]\tLoss: 0.161852\n",
      "Train Epoch: 3 [1280/48200 (3%)]\tLoss: 0.109256\n",
      "Train Epoch: 3 [1920/48200 (4%)]\tLoss: 0.179663\n",
      "Train Epoch: 3 [2560/48200 (5%)]\tLoss: 0.080832\n",
      "Train Epoch: 3 [3200/48200 (7%)]\tLoss: 0.236131\n",
      "Train Epoch: 3 [3840/48200 (8%)]\tLoss: 0.180887\n",
      "Train Epoch: 3 [4480/48200 (9%)]\tLoss: 0.290682\n",
      "Train Epoch: 3 [5120/48200 (11%)]\tLoss: 0.125125\n",
      "Train Epoch: 3 [5760/48200 (12%)]\tLoss: 0.157114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [6400/48200 (13%)]\tLoss: 0.146493\n",
      "Train Epoch: 3 [7040/48200 (15%)]\tLoss: 0.307869\n",
      "Train Epoch: 3 [7680/48200 (16%)]\tLoss: 0.094759\n",
      "Train Epoch: 3 [8320/48200 (17%)]\tLoss: 0.119808\n",
      "Train Epoch: 3 [8960/48200 (19%)]\tLoss: 0.499658\n",
      "Train Epoch: 3 [9600/48200 (20%)]\tLoss: 0.067145\n",
      "Train Epoch: 3 [10240/48200 (21%)]\tLoss: 0.214824\n",
      "Train Epoch: 3 [10880/48200 (23%)]\tLoss: 0.225647\n",
      "Train Epoch: 3 [11520/48200 (24%)]\tLoss: 0.101158\n",
      "Train Epoch: 3 [12160/48200 (25%)]\tLoss: 0.095540\n",
      "Train Epoch: 3 [12800/48200 (27%)]\tLoss: 0.165291\n",
      "Train Epoch: 3 [13440/48200 (28%)]\tLoss: 0.147344\n",
      "Train Epoch: 3 [14080/48200 (29%)]\tLoss: 0.183161\n",
      "Train Epoch: 3 [14720/48200 (31%)]\tLoss: 0.220958\n",
      "Train Epoch: 3 [15360/48200 (32%)]\tLoss: 0.221444\n",
      "Train Epoch: 3 [16000/48200 (33%)]\tLoss: 0.114379\n",
      "Train Epoch: 3 [16640/48200 (34%)]\tLoss: 0.153379\n",
      "Train Epoch: 3 [17280/48200 (36%)]\tLoss: 0.154812\n",
      "Train Epoch: 3 [17920/48200 (37%)]\tLoss: 0.258330\n",
      "Train Epoch: 3 [18560/48200 (38%)]\tLoss: 0.137543\n",
      "Train Epoch: 3 [19200/48200 (40%)]\tLoss: 0.115088\n",
      "Train Epoch: 3 [19840/48200 (41%)]\tLoss: 0.241098\n",
      "Train Epoch: 3 [20480/48200 (42%)]\tLoss: 0.046877\n",
      "Train Epoch: 3 [21120/48200 (44%)]\tLoss: 0.099643\n",
      "Train Epoch: 3 [21760/48200 (45%)]\tLoss: 0.360091\n",
      "Train Epoch: 3 [22400/48200 (46%)]\tLoss: 0.325892\n",
      "Train Epoch: 3 [23040/48200 (48%)]\tLoss: 0.287075\n",
      "Train Epoch: 3 [23680/48200 (49%)]\tLoss: 0.118573\n",
      "Train Epoch: 3 [24320/48200 (50%)]\tLoss: 0.148256\n",
      "Train Epoch: 3 [24960/48200 (52%)]\tLoss: 0.042875\n",
      "Train Epoch: 3 [25600/48200 (53%)]\tLoss: 0.102381\n",
      "Train Epoch: 3 [26240/48200 (54%)]\tLoss: 0.106614\n",
      "Train Epoch: 3 [26880/48200 (56%)]\tLoss: 0.233472\n",
      "Train Epoch: 3 [27520/48200 (57%)]\tLoss: 0.155415\n",
      "Train Epoch: 3 [28160/48200 (58%)]\tLoss: 0.369631\n",
      "Train Epoch: 3 [28800/48200 (60%)]\tLoss: 0.146601\n",
      "Train Epoch: 3 [29440/48200 (61%)]\tLoss: 0.136178\n",
      "Train Epoch: 3 [30080/48200 (62%)]\tLoss: 0.171025\n",
      "Train Epoch: 3 [30720/48200 (64%)]\tLoss: 0.269703\n",
      "Train Epoch: 3 [31360/48200 (65%)]\tLoss: 0.187813\n",
      "Train Epoch: 3 [32000/48200 (66%)]\tLoss: 0.125615\n",
      "Train Epoch: 3 [32640/48200 (68%)]\tLoss: 0.315289\n",
      "Train Epoch: 3 [33280/48200 (69%)]\tLoss: 0.194789\n",
      "Train Epoch: 3 [33920/48200 (70%)]\tLoss: 0.112768\n",
      "Train Epoch: 3 [34560/48200 (72%)]\tLoss: 0.112576\n",
      "Train Epoch: 3 [35200/48200 (73%)]\tLoss: 0.199371\n",
      "Train Epoch: 3 [35840/48200 (74%)]\tLoss: 0.120138\n",
      "Train Epoch: 3 [36480/48200 (76%)]\tLoss: 0.101837\n",
      "Train Epoch: 3 [37120/48200 (77%)]\tLoss: 0.214589\n",
      "Train Epoch: 3 [37760/48200 (78%)]\tLoss: 0.147476\n",
      "Train Epoch: 3 [38400/48200 (80%)]\tLoss: 0.126072\n",
      "Train Epoch: 3 [39040/48200 (81%)]\tLoss: 0.190840\n",
      "Train Epoch: 3 [39680/48200 (82%)]\tLoss: 0.240115\n",
      "Train Epoch: 3 [40320/48200 (84%)]\tLoss: 0.277864\n",
      "Train Epoch: 3 [40960/48200 (85%)]\tLoss: 0.182847\n",
      "Train Epoch: 3 [41600/48200 (86%)]\tLoss: 0.129669\n",
      "Train Epoch: 3 [42240/48200 (88%)]\tLoss: 0.142374\n",
      "Train Epoch: 3 [42880/48200 (89%)]\tLoss: 0.162726\n",
      "Train Epoch: 3 [43520/48200 (90%)]\tLoss: 0.132770\n",
      "Train Epoch: 3 [44160/48200 (92%)]\tLoss: 0.089056\n",
      "Train Epoch: 3 [44800/48200 (93%)]\tLoss: 0.167974\n",
      "Train Epoch: 3 [45440/48200 (94%)]\tLoss: 0.155120\n",
      "Train Epoch: 3 [46080/48200 (95%)]\tLoss: 0.113583\n",
      "Train Epoch: 3 [46720/48200 (97%)]\tLoss: 0.219874\n",
      "Train Epoch: 3 [47360/48200 (98%)]\tLoss: 0.128839\n",
      "Train Epoch: 3 [48000/48200 (99%)]\tLoss: 0.122021\n",
      "\n",
      "Test set: Avg. loss: 0.0656, Accuracy: 7834/8017 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/48200 (0%)]\tLoss: 0.213751\n",
      "Train Epoch: 4 [640/48200 (1%)]\tLoss: 0.151665\n",
      "Train Epoch: 4 [1280/48200 (3%)]\tLoss: 0.098121\n",
      "Train Epoch: 4 [1920/48200 (4%)]\tLoss: 0.107778\n",
      "Train Epoch: 4 [2560/48200 (5%)]\tLoss: 0.130981\n",
      "Train Epoch: 4 [3200/48200 (7%)]\tLoss: 0.264359\n",
      "Train Epoch: 4 [3840/48200 (8%)]\tLoss: 0.106865\n",
      "Train Epoch: 4 [4480/48200 (9%)]\tLoss: 0.090706\n",
      "Train Epoch: 4 [5120/48200 (11%)]\tLoss: 0.271452\n",
      "Train Epoch: 4 [5760/48200 (12%)]\tLoss: 0.059753\n",
      "Train Epoch: 4 [6400/48200 (13%)]\tLoss: 0.057052\n",
      "Train Epoch: 4 [7040/48200 (15%)]\tLoss: 0.118804\n",
      "Train Epoch: 4 [7680/48200 (16%)]\tLoss: 0.188162\n",
      "Train Epoch: 4 [8320/48200 (17%)]\tLoss: 0.165188\n",
      "Train Epoch: 4 [8960/48200 (19%)]\tLoss: 0.091425\n",
      "Train Epoch: 4 [9600/48200 (20%)]\tLoss: 0.119657\n",
      "Train Epoch: 4 [10240/48200 (21%)]\tLoss: 0.066947\n",
      "Train Epoch: 4 [10880/48200 (23%)]\tLoss: 0.191707\n",
      "Train Epoch: 4 [11520/48200 (24%)]\tLoss: 0.154094\n",
      "Train Epoch: 4 [12160/48200 (25%)]\tLoss: 0.068558\n",
      "Train Epoch: 4 [12800/48200 (27%)]\tLoss: 0.134658\n",
      "Train Epoch: 4 [13440/48200 (28%)]\tLoss: 0.145197\n",
      "Train Epoch: 4 [14080/48200 (29%)]\tLoss: 0.191575\n",
      "Train Epoch: 4 [14720/48200 (31%)]\tLoss: 0.254158\n",
      "Train Epoch: 4 [15360/48200 (32%)]\tLoss: 0.144413\n",
      "Train Epoch: 4 [16000/48200 (33%)]\tLoss: 0.164424\n",
      "Train Epoch: 4 [16640/48200 (34%)]\tLoss: 0.265968\n",
      "Train Epoch: 4 [17280/48200 (36%)]\tLoss: 0.090887\n",
      "Train Epoch: 4 [17920/48200 (37%)]\tLoss: 0.041984\n",
      "Train Epoch: 4 [18560/48200 (38%)]\tLoss: 0.127190\n",
      "Train Epoch: 4 [19200/48200 (40%)]\tLoss: 0.072368\n",
      "Train Epoch: 4 [19840/48200 (41%)]\tLoss: 0.193153\n",
      "Train Epoch: 4 [20480/48200 (42%)]\tLoss: 0.231739\n",
      "Train Epoch: 4 [21120/48200 (44%)]\tLoss: 0.094589\n",
      "Train Epoch: 4 [21760/48200 (45%)]\tLoss: 0.224909\n",
      "Train Epoch: 4 [22400/48200 (46%)]\tLoss: 0.092335\n",
      "Train Epoch: 4 [23040/48200 (48%)]\tLoss: 0.182017\n",
      "Train Epoch: 4 [23680/48200 (49%)]\tLoss: 0.026821\n",
      "Train Epoch: 4 [24320/48200 (50%)]\tLoss: 0.150895\n",
      "Train Epoch: 4 [24960/48200 (52%)]\tLoss: 0.078721\n",
      "Train Epoch: 4 [25600/48200 (53%)]\tLoss: 0.038501\n",
      "Train Epoch: 4 [26240/48200 (54%)]\tLoss: 0.148735\n",
      "Train Epoch: 4 [26880/48200 (56%)]\tLoss: 0.421487\n",
      "Train Epoch: 4 [27520/48200 (57%)]\tLoss: 0.085066\n",
      "Train Epoch: 4 [28160/48200 (58%)]\tLoss: 0.234967\n",
      "Train Epoch: 4 [28800/48200 (60%)]\tLoss: 0.146603\n",
      "Train Epoch: 4 [29440/48200 (61%)]\tLoss: 0.194177\n",
      "Train Epoch: 4 [30080/48200 (62%)]\tLoss: 0.077077\n",
      "Train Epoch: 4 [30720/48200 (64%)]\tLoss: 0.200937\n",
      "Train Epoch: 4 [31360/48200 (65%)]\tLoss: 0.138489\n",
      "Train Epoch: 4 [32000/48200 (66%)]\tLoss: 0.086407\n",
      "Train Epoch: 4 [32640/48200 (68%)]\tLoss: 0.090856\n",
      "Train Epoch: 4 [33280/48200 (69%)]\tLoss: 0.118144\n",
      "Train Epoch: 4 [33920/48200 (70%)]\tLoss: 0.075374\n",
      "Train Epoch: 4 [34560/48200 (72%)]\tLoss: 0.077110\n",
      "Train Epoch: 4 [35200/48200 (73%)]\tLoss: 0.145302\n",
      "Train Epoch: 4 [35840/48200 (74%)]\tLoss: 0.089530\n",
      "Train Epoch: 4 [36480/48200 (76%)]\tLoss: 0.061934\n",
      "Train Epoch: 4 [37120/48200 (77%)]\tLoss: 0.126490\n",
      "Train Epoch: 4 [37760/48200 (78%)]\tLoss: 0.138794\n",
      "Train Epoch: 4 [38400/48200 (80%)]\tLoss: 0.050762\n",
      "Train Epoch: 4 [39040/48200 (81%)]\tLoss: 0.128491\n",
      "Train Epoch: 4 [39680/48200 (82%)]\tLoss: 0.161814\n",
      "Train Epoch: 4 [40320/48200 (84%)]\tLoss: 0.129727\n",
      "Train Epoch: 4 [40960/48200 (85%)]\tLoss: 0.133237\n",
      "Train Epoch: 4 [41600/48200 (86%)]\tLoss: 0.279297\n",
      "Train Epoch: 4 [42240/48200 (88%)]\tLoss: 0.079243\n",
      "Train Epoch: 4 [42880/48200 (89%)]\tLoss: 0.055287\n",
      "Train Epoch: 4 [43520/48200 (90%)]\tLoss: 0.036936\n",
      "Train Epoch: 4 [44160/48200 (92%)]\tLoss: 0.348603\n",
      "Train Epoch: 4 [44800/48200 (93%)]\tLoss: 0.159235\n",
      "Train Epoch: 4 [45440/48200 (94%)]\tLoss: 0.158091\n",
      "Train Epoch: 4 [46080/48200 (95%)]\tLoss: 0.098350\n",
      "Train Epoch: 4 [46720/48200 (97%)]\tLoss: 0.115936\n",
      "Train Epoch: 4 [47360/48200 (98%)]\tLoss: 0.059576\n",
      "Train Epoch: 4 [48000/48200 (99%)]\tLoss: 0.314466\n",
      "\n",
      "Test set: Avg. loss: 0.0557, Accuracy: 7865/8017 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/48200 (0%)]\tLoss: 0.166389\n",
      "Train Epoch: 5 [640/48200 (1%)]\tLoss: 0.148249\n",
      "Train Epoch: 5 [1280/48200 (3%)]\tLoss: 0.048412\n",
      "Train Epoch: 5 [1920/48200 (4%)]\tLoss: 0.171488\n",
      "Train Epoch: 5 [2560/48200 (5%)]\tLoss: 0.188752\n",
      "Train Epoch: 5 [3200/48200 (7%)]\tLoss: 0.149270\n",
      "Train Epoch: 5 [3840/48200 (8%)]\tLoss: 0.180401\n",
      "Train Epoch: 5 [4480/48200 (9%)]\tLoss: 0.057559\n",
      "Train Epoch: 5 [5120/48200 (11%)]\tLoss: 0.127262\n",
      "Train Epoch: 5 [5760/48200 (12%)]\tLoss: 0.272595\n",
      "Train Epoch: 5 [6400/48200 (13%)]\tLoss: 0.086447\n",
      "Train Epoch: 5 [7040/48200 (15%)]\tLoss: 0.101287\n",
      "Train Epoch: 5 [7680/48200 (16%)]\tLoss: 0.060646\n",
      "Train Epoch: 5 [8320/48200 (17%)]\tLoss: 0.142190\n",
      "Train Epoch: 5 [8960/48200 (19%)]\tLoss: 0.139090\n",
      "Train Epoch: 5 [9600/48200 (20%)]\tLoss: 0.160824\n",
      "Train Epoch: 5 [10240/48200 (21%)]\tLoss: 0.033129\n",
      "Train Epoch: 5 [10880/48200 (23%)]\tLoss: 0.056823\n",
      "Train Epoch: 5 [11520/48200 (24%)]\tLoss: 0.071291\n",
      "Train Epoch: 5 [12160/48200 (25%)]\tLoss: 0.073229\n",
      "Train Epoch: 5 [12800/48200 (27%)]\tLoss: 0.115824\n",
      "Train Epoch: 5 [13440/48200 (28%)]\tLoss: 0.051851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [14080/48200 (29%)]\tLoss: 0.085986\n",
      "Train Epoch: 5 [14720/48200 (31%)]\tLoss: 0.091218\n",
      "Train Epoch: 5 [15360/48200 (32%)]\tLoss: 0.259002\n",
      "Train Epoch: 5 [16000/48200 (33%)]\tLoss: 0.095736\n",
      "Train Epoch: 5 [16640/48200 (34%)]\tLoss: 0.118999\n",
      "Train Epoch: 5 [17280/48200 (36%)]\tLoss: 0.290808\n",
      "Train Epoch: 5 [17920/48200 (37%)]\tLoss: 0.075848\n",
      "Train Epoch: 5 [18560/48200 (38%)]\tLoss: 0.084447\n",
      "Train Epoch: 5 [19200/48200 (40%)]\tLoss: 0.181716\n",
      "Train Epoch: 5 [19840/48200 (41%)]\tLoss: 0.174951\n",
      "Train Epoch: 5 [20480/48200 (42%)]\tLoss: 0.129419\n",
      "Train Epoch: 5 [21120/48200 (44%)]\tLoss: 0.119647\n",
      "Train Epoch: 5 [21760/48200 (45%)]\tLoss: 0.116237\n",
      "Train Epoch: 5 [22400/48200 (46%)]\tLoss: 0.203935\n",
      "Train Epoch: 5 [23040/48200 (48%)]\tLoss: 0.073762\n",
      "Train Epoch: 5 [23680/48200 (49%)]\tLoss: 0.112127\n",
      "Train Epoch: 5 [24320/48200 (50%)]\tLoss: 0.150749\n",
      "Train Epoch: 5 [24960/48200 (52%)]\tLoss: 0.226141\n",
      "Train Epoch: 5 [25600/48200 (53%)]\tLoss: 0.275428\n",
      "Train Epoch: 5 [26240/48200 (54%)]\tLoss: 0.086640\n",
      "Train Epoch: 5 [26880/48200 (56%)]\tLoss: 0.066375\n",
      "Train Epoch: 5 [27520/48200 (57%)]\tLoss: 0.114296\n",
      "Train Epoch: 5 [28160/48200 (58%)]\tLoss: 0.081979\n",
      "Train Epoch: 5 [28800/48200 (60%)]\tLoss: 0.190440\n",
      "Train Epoch: 5 [29440/48200 (61%)]\tLoss: 0.256135\n",
      "Train Epoch: 5 [30080/48200 (62%)]\tLoss: 0.103179\n",
      "Train Epoch: 5 [30720/48200 (64%)]\tLoss: 0.163113\n",
      "Train Epoch: 5 [31360/48200 (65%)]\tLoss: 0.219387\n",
      "Train Epoch: 5 [32000/48200 (66%)]\tLoss: 0.123214\n",
      "Train Epoch: 5 [32640/48200 (68%)]\tLoss: 0.135218\n",
      "Train Epoch: 5 [33280/48200 (69%)]\tLoss: 0.066550\n",
      "Train Epoch: 5 [33920/48200 (70%)]\tLoss: 0.097472\n",
      "Train Epoch: 5 [34560/48200 (72%)]\tLoss: 0.052983\n",
      "Train Epoch: 5 [35200/48200 (73%)]\tLoss: 0.063723\n",
      "Train Epoch: 5 [35840/48200 (74%)]\tLoss: 0.222012\n",
      "Train Epoch: 5 [36480/48200 (76%)]\tLoss: 0.101051\n",
      "Train Epoch: 5 [37120/48200 (77%)]\tLoss: 0.155135\n",
      "Train Epoch: 5 [37760/48200 (78%)]\tLoss: 0.104636\n",
      "Train Epoch: 5 [38400/48200 (80%)]\tLoss: 0.085663\n",
      "Train Epoch: 5 [39040/48200 (81%)]\tLoss: 0.095035\n",
      "Train Epoch: 5 [39680/48200 (82%)]\tLoss: 0.121684\n",
      "Train Epoch: 5 [40320/48200 (84%)]\tLoss: 0.085528\n",
      "Train Epoch: 5 [40960/48200 (85%)]\tLoss: 0.129409\n",
      "Train Epoch: 5 [41600/48200 (86%)]\tLoss: 0.140938\n",
      "Train Epoch: 5 [42240/48200 (88%)]\tLoss: 0.085085\n",
      "Train Epoch: 5 [42880/48200 (89%)]\tLoss: 0.058794\n",
      "Train Epoch: 5 [43520/48200 (90%)]\tLoss: 0.145117\n",
      "Train Epoch: 5 [44160/48200 (92%)]\tLoss: 0.092687\n",
      "Train Epoch: 5 [44800/48200 (93%)]\tLoss: 0.078925\n",
      "Train Epoch: 5 [45440/48200 (94%)]\tLoss: 0.077602\n",
      "Train Epoch: 5 [46080/48200 (95%)]\tLoss: 0.093567\n",
      "Train Epoch: 5 [46720/48200 (97%)]\tLoss: 0.135804\n",
      "Train Epoch: 5 [47360/48200 (98%)]\tLoss: 0.115493\n",
      "Train Epoch: 5 [48000/48200 (99%)]\tLoss: 0.038463\n",
      "\n",
      "Test set: Avg. loss: 0.0503, Accuracy: 7884/8017 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/48200 (0%)]\tLoss: 0.072531\n",
      "Train Epoch: 6 [640/48200 (1%)]\tLoss: 0.079611\n",
      "Train Epoch: 6 [1280/48200 (3%)]\tLoss: 0.066919\n",
      "Train Epoch: 6 [1920/48200 (4%)]\tLoss: 0.438293\n",
      "Train Epoch: 6 [2560/48200 (5%)]\tLoss: 0.254521\n",
      "Train Epoch: 6 [3200/48200 (7%)]\tLoss: 0.303287\n",
      "Train Epoch: 6 [3840/48200 (8%)]\tLoss: 0.095510\n",
      "Train Epoch: 6 [4480/48200 (9%)]\tLoss: 0.084266\n",
      "Train Epoch: 6 [5120/48200 (11%)]\tLoss: 0.073060\n",
      "Train Epoch: 6 [5760/48200 (12%)]\tLoss: 0.095042\n",
      "Train Epoch: 6 [6400/48200 (13%)]\tLoss: 0.076840\n",
      "Train Epoch: 6 [7040/48200 (15%)]\tLoss: 0.048458\n",
      "Train Epoch: 6 [7680/48200 (16%)]\tLoss: 0.207605\n",
      "Train Epoch: 6 [8320/48200 (17%)]\tLoss: 0.042356\n",
      "Train Epoch: 6 [8960/48200 (19%)]\tLoss: 0.299426\n",
      "Train Epoch: 6 [9600/48200 (20%)]\tLoss: 0.048644\n",
      "Train Epoch: 6 [10240/48200 (21%)]\tLoss: 0.093856\n",
      "Train Epoch: 6 [10880/48200 (23%)]\tLoss: 0.180615\n",
      "Train Epoch: 6 [11520/48200 (24%)]\tLoss: 0.075804\n",
      "Train Epoch: 6 [12160/48200 (25%)]\tLoss: 0.278215\n",
      "Train Epoch: 6 [12800/48200 (27%)]\tLoss: 0.161735\n",
      "Train Epoch: 6 [13440/48200 (28%)]\tLoss: 0.111587\n",
      "Train Epoch: 6 [14080/48200 (29%)]\tLoss: 0.045813\n",
      "Train Epoch: 6 [14720/48200 (31%)]\tLoss: 0.044696\n",
      "Train Epoch: 6 [15360/48200 (32%)]\tLoss: 0.234554\n",
      "Train Epoch: 6 [16000/48200 (33%)]\tLoss: 0.137051\n",
      "Train Epoch: 6 [16640/48200 (34%)]\tLoss: 0.129006\n",
      "Train Epoch: 6 [17280/48200 (36%)]\tLoss: 0.095483\n",
      "Train Epoch: 6 [17920/48200 (37%)]\tLoss: 0.219532\n",
      "Train Epoch: 6 [18560/48200 (38%)]\tLoss: 0.033832\n",
      "Train Epoch: 6 [19200/48200 (40%)]\tLoss: 0.184288\n",
      "Train Epoch: 6 [19840/48200 (41%)]\tLoss: 0.114938\n",
      "Train Epoch: 6 [20480/48200 (42%)]\tLoss: 0.074557\n",
      "Train Epoch: 6 [21120/48200 (44%)]\tLoss: 0.258564\n",
      "Train Epoch: 6 [21760/48200 (45%)]\tLoss: 0.105313\n",
      "Train Epoch: 6 [22400/48200 (46%)]\tLoss: 0.057079\n",
      "Train Epoch: 6 [23040/48200 (48%)]\tLoss: 0.193390\n",
      "Train Epoch: 6 [23680/48200 (49%)]\tLoss: 0.155550\n",
      "Train Epoch: 6 [24320/48200 (50%)]\tLoss: 0.196639\n",
      "Train Epoch: 6 [24960/48200 (52%)]\tLoss: 0.038999\n",
      "Train Epoch: 6 [25600/48200 (53%)]\tLoss: 0.066865\n",
      "Train Epoch: 6 [26240/48200 (54%)]\tLoss: 0.085281\n",
      "Train Epoch: 6 [26880/48200 (56%)]\tLoss: 0.120179\n",
      "Train Epoch: 6 [27520/48200 (57%)]\tLoss: 0.250839\n",
      "Train Epoch: 6 [28160/48200 (58%)]\tLoss: 0.106481\n",
      "Train Epoch: 6 [28800/48200 (60%)]\tLoss: 0.146617\n",
      "Train Epoch: 6 [29440/48200 (61%)]\tLoss: 0.030972\n",
      "Train Epoch: 6 [30080/48200 (62%)]\tLoss: 0.064268\n",
      "Train Epoch: 6 [30720/48200 (64%)]\tLoss: 0.423769\n",
      "Train Epoch: 6 [31360/48200 (65%)]\tLoss: 0.056067\n",
      "Train Epoch: 6 [32000/48200 (66%)]\tLoss: 0.040109\n",
      "Train Epoch: 6 [32640/48200 (68%)]\tLoss: 0.113417\n",
      "Train Epoch: 6 [33280/48200 (69%)]\tLoss: 0.126897\n",
      "Train Epoch: 6 [33920/48200 (70%)]\tLoss: 0.064971\n",
      "Train Epoch: 6 [34560/48200 (72%)]\tLoss: 0.191614\n",
      "Train Epoch: 6 [35200/48200 (73%)]\tLoss: 0.134237\n",
      "Train Epoch: 6 [35840/48200 (74%)]\tLoss: 0.104649\n",
      "Train Epoch: 6 [36480/48200 (76%)]\tLoss: 0.151631\n",
      "Train Epoch: 6 [37120/48200 (77%)]\tLoss: 0.058908\n",
      "Train Epoch: 6 [37760/48200 (78%)]\tLoss: 0.052465\n",
      "Train Epoch: 6 [38400/48200 (80%)]\tLoss: 0.028897\n",
      "Train Epoch: 6 [39040/48200 (81%)]\tLoss: 0.044731\n",
      "Train Epoch: 6 [39680/48200 (82%)]\tLoss: 0.106675\n",
      "Train Epoch: 6 [40320/48200 (84%)]\tLoss: 0.120300\n",
      "Train Epoch: 6 [40960/48200 (85%)]\tLoss: 0.073687\n",
      "Train Epoch: 6 [41600/48200 (86%)]\tLoss: 0.016684\n",
      "Train Epoch: 6 [42240/48200 (88%)]\tLoss: 0.114053\n",
      "Train Epoch: 6 [42880/48200 (89%)]\tLoss: 0.098331\n",
      "Train Epoch: 6 [43520/48200 (90%)]\tLoss: 0.078357\n",
      "Train Epoch: 6 [44160/48200 (92%)]\tLoss: 0.058236\n",
      "Train Epoch: 6 [44800/48200 (93%)]\tLoss: 0.089974\n",
      "Train Epoch: 6 [45440/48200 (94%)]\tLoss: 0.127706\n",
      "Train Epoch: 6 [46080/48200 (95%)]\tLoss: 0.082768\n",
      "Train Epoch: 6 [46720/48200 (97%)]\tLoss: 0.057763\n",
      "Train Epoch: 6 [47360/48200 (98%)]\tLoss: 0.159233\n",
      "Train Epoch: 6 [48000/48200 (99%)]\tLoss: 0.106668\n",
      "\n",
      "Test set: Avg. loss: 0.0435, Accuracy: 7909/8017 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/48200 (0%)]\tLoss: 0.188314\n",
      "Train Epoch: 7 [640/48200 (1%)]\tLoss: 0.126101\n",
      "Train Epoch: 7 [1280/48200 (3%)]\tLoss: 0.052753\n",
      "Train Epoch: 7 [1920/48200 (4%)]\tLoss: 0.299506\n",
      "Train Epoch: 7 [2560/48200 (5%)]\tLoss: 0.150627\n",
      "Train Epoch: 7 [3200/48200 (7%)]\tLoss: 0.144279\n",
      "Train Epoch: 7 [3840/48200 (8%)]\tLoss: 0.045606\n",
      "Train Epoch: 7 [4480/48200 (9%)]\tLoss: 0.149145\n",
      "Train Epoch: 7 [5120/48200 (11%)]\tLoss: 0.078998\n",
      "Train Epoch: 7 [5760/48200 (12%)]\tLoss: 0.070430\n",
      "Train Epoch: 7 [6400/48200 (13%)]\tLoss: 0.076293\n",
      "Train Epoch: 7 [7040/48200 (15%)]\tLoss: 0.116578\n",
      "Train Epoch: 7 [7680/48200 (16%)]\tLoss: 0.126962\n",
      "Train Epoch: 7 [8320/48200 (17%)]\tLoss: 0.043952\n",
      "Train Epoch: 7 [8960/48200 (19%)]\tLoss: 0.083119\n",
      "Train Epoch: 7 [9600/48200 (20%)]\tLoss: 0.070314\n",
      "Train Epoch: 7 [10240/48200 (21%)]\tLoss: 0.042338\n",
      "Train Epoch: 7 [10880/48200 (23%)]\tLoss: 0.094988\n",
      "Train Epoch: 7 [11520/48200 (24%)]\tLoss: 0.029344\n",
      "Train Epoch: 7 [12160/48200 (25%)]\tLoss: 0.055048\n",
      "Train Epoch: 7 [12800/48200 (27%)]\tLoss: 0.142428\n",
      "Train Epoch: 7 [13440/48200 (28%)]\tLoss: 0.101472\n",
      "Train Epoch: 7 [14080/48200 (29%)]\tLoss: 0.097700\n",
      "Train Epoch: 7 [14720/48200 (31%)]\tLoss: 0.144238\n",
      "Train Epoch: 7 [15360/48200 (32%)]\tLoss: 0.069676\n",
      "Train Epoch: 7 [16000/48200 (33%)]\tLoss: 0.051182\n",
      "Train Epoch: 7 [16640/48200 (34%)]\tLoss: 0.124255\n",
      "Train Epoch: 7 [17280/48200 (36%)]\tLoss: 0.052865\n",
      "Train Epoch: 7 [17920/48200 (37%)]\tLoss: 0.091200\n",
      "Train Epoch: 7 [18560/48200 (38%)]\tLoss: 0.094417\n",
      "Train Epoch: 7 [19200/48200 (40%)]\tLoss: 0.022186\n",
      "Train Epoch: 7 [19840/48200 (41%)]\tLoss: 0.180385\n",
      "Train Epoch: 7 [20480/48200 (42%)]\tLoss: 0.020810\n",
      "Train Epoch: 7 [21120/48200 (44%)]\tLoss: 0.040024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [21760/48200 (45%)]\tLoss: 0.197354\n",
      "Train Epoch: 7 [22400/48200 (46%)]\tLoss: 0.047364\n",
      "Train Epoch: 7 [23040/48200 (48%)]\tLoss: 0.032852\n",
      "Train Epoch: 7 [23680/48200 (49%)]\tLoss: 0.137532\n",
      "Train Epoch: 7 [24320/48200 (50%)]\tLoss: 0.207822\n",
      "Train Epoch: 7 [24960/48200 (52%)]\tLoss: 0.027329\n",
      "Train Epoch: 7 [25600/48200 (53%)]\tLoss: 0.139072\n",
      "Train Epoch: 7 [26240/48200 (54%)]\tLoss: 0.066644\n",
      "Train Epoch: 7 [26880/48200 (56%)]\tLoss: 0.038952\n",
      "Train Epoch: 7 [27520/48200 (57%)]\tLoss: 0.109432\n",
      "Train Epoch: 7 [28160/48200 (58%)]\tLoss: 0.093271\n",
      "Train Epoch: 7 [28800/48200 (60%)]\tLoss: 0.045407\n",
      "Train Epoch: 7 [29440/48200 (61%)]\tLoss: 0.084699\n",
      "Train Epoch: 7 [30080/48200 (62%)]\tLoss: 0.141938\n",
      "Train Epoch: 7 [30720/48200 (64%)]\tLoss: 0.083401\n",
      "Train Epoch: 7 [31360/48200 (65%)]\tLoss: 0.030332\n",
      "Train Epoch: 7 [32000/48200 (66%)]\tLoss: 0.080836\n",
      "Train Epoch: 7 [32640/48200 (68%)]\tLoss: 0.016513\n",
      "Train Epoch: 7 [33280/48200 (69%)]\tLoss: 0.037777\n",
      "Train Epoch: 7 [33920/48200 (70%)]\tLoss: 0.081834\n",
      "Train Epoch: 7 [34560/48200 (72%)]\tLoss: 0.063227\n",
      "Train Epoch: 7 [35200/48200 (73%)]\tLoss: 0.130207\n",
      "Train Epoch: 7 [35840/48200 (74%)]\tLoss: 0.155149\n",
      "Train Epoch: 7 [36480/48200 (76%)]\tLoss: 0.052672\n",
      "Train Epoch: 7 [37120/48200 (77%)]\tLoss: 0.166787\n",
      "Train Epoch: 7 [37760/48200 (78%)]\tLoss: 0.127096\n",
      "Train Epoch: 7 [38400/48200 (80%)]\tLoss: 0.222251\n",
      "Train Epoch: 7 [39040/48200 (81%)]\tLoss: 0.076272\n",
      "Train Epoch: 7 [39680/48200 (82%)]\tLoss: 0.255763\n",
      "Train Epoch: 7 [40320/48200 (84%)]\tLoss: 0.113714\n",
      "Train Epoch: 7 [40960/48200 (85%)]\tLoss: 0.144947\n",
      "Train Epoch: 7 [41600/48200 (86%)]\tLoss: 0.086660\n",
      "Train Epoch: 7 [42240/48200 (88%)]\tLoss: 0.179914\n",
      "Train Epoch: 7 [42880/48200 (89%)]\tLoss: 0.090166\n",
      "Train Epoch: 7 [43520/48200 (90%)]\tLoss: 0.118695\n",
      "Train Epoch: 7 [44160/48200 (92%)]\tLoss: 0.115286\n",
      "Train Epoch: 7 [44800/48200 (93%)]\tLoss: 0.167979\n",
      "Train Epoch: 7 [45440/48200 (94%)]\tLoss: 0.127269\n",
      "Train Epoch: 7 [46080/48200 (95%)]\tLoss: 0.069729\n",
      "Train Epoch: 7 [46720/48200 (97%)]\tLoss: 0.102317\n",
      "Train Epoch: 7 [47360/48200 (98%)]\tLoss: 0.191068\n",
      "Train Epoch: 7 [48000/48200 (99%)]\tLoss: 0.070392\n",
      "\n",
      "Test set: Avg. loss: 0.0398, Accuracy: 7912/8017 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/48200 (0%)]\tLoss: 0.165749\n",
      "Train Epoch: 8 [640/48200 (1%)]\tLoss: 0.164374\n",
      "Train Epoch: 8 [1280/48200 (3%)]\tLoss: 0.106285\n",
      "Train Epoch: 8 [1920/48200 (4%)]\tLoss: 0.067718\n",
      "Train Epoch: 8 [2560/48200 (5%)]\tLoss: 0.062619\n",
      "Train Epoch: 8 [3200/48200 (7%)]\tLoss: 0.105703\n",
      "Train Epoch: 8 [3840/48200 (8%)]\tLoss: 0.072849\n",
      "Train Epoch: 8 [4480/48200 (9%)]\tLoss: 0.035989\n",
      "Train Epoch: 8 [5120/48200 (11%)]\tLoss: 0.045151\n",
      "Train Epoch: 8 [5760/48200 (12%)]\tLoss: 0.329873\n",
      "Train Epoch: 8 [6400/48200 (13%)]\tLoss: 0.089611\n",
      "Train Epoch: 8 [7040/48200 (15%)]\tLoss: 0.196265\n",
      "Train Epoch: 8 [7680/48200 (16%)]\tLoss: 0.062386\n",
      "Train Epoch: 8 [8320/48200 (17%)]\tLoss: 0.193779\n",
      "Train Epoch: 8 [8960/48200 (19%)]\tLoss: 0.065219\n",
      "Train Epoch: 8 [9600/48200 (20%)]\tLoss: 0.151034\n",
      "Train Epoch: 8 [10240/48200 (21%)]\tLoss: 0.024665\n",
      "Train Epoch: 8 [10880/48200 (23%)]\tLoss: 0.038073\n",
      "Train Epoch: 8 [11520/48200 (24%)]\tLoss: 0.103913\n",
      "Train Epoch: 8 [12160/48200 (25%)]\tLoss: 0.080172\n",
      "Train Epoch: 8 [12800/48200 (27%)]\tLoss: 0.016111\n",
      "Train Epoch: 8 [13440/48200 (28%)]\tLoss: 0.185504\n",
      "Train Epoch: 8 [14080/48200 (29%)]\tLoss: 0.132444\n",
      "Train Epoch: 8 [14720/48200 (31%)]\tLoss: 0.156397\n",
      "Train Epoch: 8 [15360/48200 (32%)]\tLoss: 0.038307\n",
      "Train Epoch: 8 [16000/48200 (33%)]\tLoss: 0.077751\n",
      "Train Epoch: 8 [16640/48200 (34%)]\tLoss: 0.050657\n",
      "Train Epoch: 8 [17280/48200 (36%)]\tLoss: 0.049806\n",
      "Train Epoch: 8 [17920/48200 (37%)]\tLoss: 0.131329\n",
      "Train Epoch: 8 [18560/48200 (38%)]\tLoss: 0.047728\n",
      "Train Epoch: 8 [19200/48200 (40%)]\tLoss: 0.046934\n",
      "Train Epoch: 8 [19840/48200 (41%)]\tLoss: 0.084180\n",
      "Train Epoch: 8 [20480/48200 (42%)]\tLoss: 0.168245\n",
      "Train Epoch: 8 [21120/48200 (44%)]\tLoss: 0.063198\n",
      "Train Epoch: 8 [21760/48200 (45%)]\tLoss: 0.096822\n",
      "Train Epoch: 8 [22400/48200 (46%)]\tLoss: 0.066050\n",
      "Train Epoch: 8 [23040/48200 (48%)]\tLoss: 0.186810\n",
      "Train Epoch: 8 [23680/48200 (49%)]\tLoss: 0.060539\n",
      "Train Epoch: 8 [24320/48200 (50%)]\tLoss: 0.025829\n",
      "Train Epoch: 8 [24960/48200 (52%)]\tLoss: 0.068021\n",
      "Train Epoch: 8 [25600/48200 (53%)]\tLoss: 0.141153\n",
      "Train Epoch: 8 [26240/48200 (54%)]\tLoss: 0.146004\n",
      "Train Epoch: 8 [26880/48200 (56%)]\tLoss: 0.074001\n",
      "Train Epoch: 8 [27520/48200 (57%)]\tLoss: 0.103053\n",
      "Train Epoch: 8 [28160/48200 (58%)]\tLoss: 0.032789\n",
      "Train Epoch: 8 [28800/48200 (60%)]\tLoss: 0.028655\n",
      "Train Epoch: 8 [29440/48200 (61%)]\tLoss: 0.018393\n",
      "Train Epoch: 8 [30080/48200 (62%)]\tLoss: 0.056336\n",
      "Train Epoch: 8 [30720/48200 (64%)]\tLoss: 0.017960\n",
      "Train Epoch: 8 [31360/48200 (65%)]\tLoss: 0.020713\n",
      "Train Epoch: 8 [32000/48200 (66%)]\tLoss: 0.361488\n",
      "Train Epoch: 8 [32640/48200 (68%)]\tLoss: 0.065309\n",
      "Train Epoch: 8 [33280/48200 (69%)]\tLoss: 0.021431\n",
      "Train Epoch: 8 [33920/48200 (70%)]\tLoss: 0.202734\n",
      "Train Epoch: 8 [34560/48200 (72%)]\tLoss: 0.250356\n",
      "Train Epoch: 8 [35200/48200 (73%)]\tLoss: 0.100870\n",
      "Train Epoch: 8 [35840/48200 (74%)]\tLoss: 0.079246\n",
      "Train Epoch: 8 [36480/48200 (76%)]\tLoss: 0.155725\n",
      "Train Epoch: 8 [37120/48200 (77%)]\tLoss: 0.153725\n",
      "Train Epoch: 8 [37760/48200 (78%)]\tLoss: 0.120886\n",
      "Train Epoch: 8 [38400/48200 (80%)]\tLoss: 0.023718\n",
      "Train Epoch: 8 [39040/48200 (81%)]\tLoss: 0.187503\n",
      "Train Epoch: 8 [39680/48200 (82%)]\tLoss: 0.115435\n",
      "Train Epoch: 8 [40320/48200 (84%)]\tLoss: 0.126801\n",
      "Train Epoch: 8 [40960/48200 (85%)]\tLoss: 0.115489\n",
      "Train Epoch: 8 [41600/48200 (86%)]\tLoss: 0.034532\n",
      "Train Epoch: 8 [42240/48200 (88%)]\tLoss: 0.103683\n",
      "Train Epoch: 8 [42880/48200 (89%)]\tLoss: 0.044909\n",
      "Train Epoch: 8 [43520/48200 (90%)]\tLoss: 0.147917\n",
      "Train Epoch: 8 [44160/48200 (92%)]\tLoss: 0.053121\n",
      "Train Epoch: 8 [44800/48200 (93%)]\tLoss: 0.055269\n",
      "Train Epoch: 8 [45440/48200 (94%)]\tLoss: 0.067809\n",
      "Train Epoch: 8 [46080/48200 (95%)]\tLoss: 0.113732\n",
      "Train Epoch: 8 [46720/48200 (97%)]\tLoss: 0.082486\n",
      "Train Epoch: 8 [47360/48200 (98%)]\tLoss: 0.209967\n",
      "Train Epoch: 8 [48000/48200 (99%)]\tLoss: 0.073693\n",
      "\n",
      "Test set: Avg. loss: 0.0362, Accuracy: 7922/8017 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/48200 (0%)]\tLoss: 0.088912\n",
      "Train Epoch: 9 [640/48200 (1%)]\tLoss: 0.103999\n",
      "Train Epoch: 9 [1280/48200 (3%)]\tLoss: 0.060271\n",
      "Train Epoch: 9 [1920/48200 (4%)]\tLoss: 0.120511\n",
      "Train Epoch: 9 [2560/48200 (5%)]\tLoss: 0.041413\n",
      "Train Epoch: 9 [3200/48200 (7%)]\tLoss: 0.093639\n",
      "Train Epoch: 9 [3840/48200 (8%)]\tLoss: 0.089564\n",
      "Train Epoch: 9 [4480/48200 (9%)]\tLoss: 0.108022\n",
      "Train Epoch: 9 [5120/48200 (11%)]\tLoss: 0.083867\n",
      "Train Epoch: 9 [5760/48200 (12%)]\tLoss: 0.056180\n",
      "Train Epoch: 9 [6400/48200 (13%)]\tLoss: 0.046134\n",
      "Train Epoch: 9 [7040/48200 (15%)]\tLoss: 0.216183\n",
      "Train Epoch: 9 [7680/48200 (16%)]\tLoss: 0.048730\n",
      "Train Epoch: 9 [8320/48200 (17%)]\tLoss: 0.025250\n",
      "Train Epoch: 9 [8960/48200 (19%)]\tLoss: 0.069339\n",
      "Train Epoch: 9 [9600/48200 (20%)]\tLoss: 0.043539\n",
      "Train Epoch: 9 [10240/48200 (21%)]\tLoss: 0.106499\n",
      "Train Epoch: 9 [10880/48200 (23%)]\tLoss: 0.082160\n",
      "Train Epoch: 9 [11520/48200 (24%)]\tLoss: 0.074968\n",
      "Train Epoch: 9 [12160/48200 (25%)]\tLoss: 0.086289\n",
      "Train Epoch: 9 [12800/48200 (27%)]\tLoss: 0.094249\n",
      "Train Epoch: 9 [13440/48200 (28%)]\tLoss: 0.027550\n",
      "Train Epoch: 9 [14080/48200 (29%)]\tLoss: 0.148966\n",
      "Train Epoch: 9 [14720/48200 (31%)]\tLoss: 0.198977\n",
      "Train Epoch: 9 [15360/48200 (32%)]\tLoss: 0.248231\n",
      "Train Epoch: 9 [16000/48200 (33%)]\tLoss: 0.090716\n",
      "Train Epoch: 9 [16640/48200 (34%)]\tLoss: 0.055757\n",
      "Train Epoch: 9 [17280/48200 (36%)]\tLoss: 0.023160\n",
      "Train Epoch: 9 [17920/48200 (37%)]\tLoss: 0.069338\n",
      "Train Epoch: 9 [18560/48200 (38%)]\tLoss: 0.041337\n",
      "Train Epoch: 9 [19200/48200 (40%)]\tLoss: 0.083662\n",
      "Train Epoch: 9 [19840/48200 (41%)]\tLoss: 0.025527\n",
      "Train Epoch: 9 [20480/48200 (42%)]\tLoss: 0.054883\n",
      "Train Epoch: 9 [21120/48200 (44%)]\tLoss: 0.030347\n",
      "Train Epoch: 9 [21760/48200 (45%)]\tLoss: 0.117154\n",
      "Train Epoch: 9 [22400/48200 (46%)]\tLoss: 0.104155\n",
      "Train Epoch: 9 [23040/48200 (48%)]\tLoss: 0.106779\n",
      "Train Epoch: 9 [23680/48200 (49%)]\tLoss: 0.062997\n",
      "Train Epoch: 9 [24320/48200 (50%)]\tLoss: 0.112025\n",
      "Train Epoch: 9 [24960/48200 (52%)]\tLoss: 0.064655\n",
      "Train Epoch: 9 [25600/48200 (53%)]\tLoss: 0.041233\n",
      "Train Epoch: 9 [26240/48200 (54%)]\tLoss: 0.031038\n",
      "Train Epoch: 9 [26880/48200 (56%)]\tLoss: 0.131303\n",
      "Train Epoch: 9 [27520/48200 (57%)]\tLoss: 0.060162\n",
      "Train Epoch: 9 [28160/48200 (58%)]\tLoss: 0.080154\n",
      "Train Epoch: 9 [28800/48200 (60%)]\tLoss: 0.039678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [29440/48200 (61%)]\tLoss: 0.189876\n",
      "Train Epoch: 9 [30080/48200 (62%)]\tLoss: 0.132867\n",
      "Train Epoch: 9 [30720/48200 (64%)]\tLoss: 0.058648\n",
      "Train Epoch: 9 [31360/48200 (65%)]\tLoss: 0.236816\n",
      "Train Epoch: 9 [32000/48200 (66%)]\tLoss: 0.030990\n",
      "Train Epoch: 9 [32640/48200 (68%)]\tLoss: 0.032491\n",
      "Train Epoch: 9 [33280/48200 (69%)]\tLoss: 0.190632\n",
      "Train Epoch: 9 [33920/48200 (70%)]\tLoss: 0.072591\n",
      "Train Epoch: 9 [34560/48200 (72%)]\tLoss: 0.203781\n",
      "Train Epoch: 9 [35200/48200 (73%)]\tLoss: 0.035547\n",
      "Train Epoch: 9 [35840/48200 (74%)]\tLoss: 0.032931\n",
      "Train Epoch: 9 [36480/48200 (76%)]\tLoss: 0.233333\n",
      "Train Epoch: 9 [37120/48200 (77%)]\tLoss: 0.085153\n",
      "Train Epoch: 9 [37760/48200 (78%)]\tLoss: 0.030904\n",
      "Train Epoch: 9 [38400/48200 (80%)]\tLoss: 0.034929\n",
      "Train Epoch: 9 [39040/48200 (81%)]\tLoss: 0.096662\n",
      "Train Epoch: 9 [39680/48200 (82%)]\tLoss: 0.164802\n",
      "Train Epoch: 9 [40320/48200 (84%)]\tLoss: 0.099479\n",
      "Train Epoch: 9 [40960/48200 (85%)]\tLoss: 0.063189\n",
      "Train Epoch: 9 [41600/48200 (86%)]\tLoss: 0.013310\n",
      "Train Epoch: 9 [42240/48200 (88%)]\tLoss: 0.066646\n",
      "Train Epoch: 9 [42880/48200 (89%)]\tLoss: 0.145077\n",
      "Train Epoch: 9 [43520/48200 (90%)]\tLoss: 0.038226\n",
      "Train Epoch: 9 [44160/48200 (92%)]\tLoss: 0.121871\n",
      "Train Epoch: 9 [44800/48200 (93%)]\tLoss: 0.127237\n",
      "Train Epoch: 9 [45440/48200 (94%)]\tLoss: 0.240554\n",
      "Train Epoch: 9 [46080/48200 (95%)]\tLoss: 0.172658\n",
      "Train Epoch: 9 [46720/48200 (97%)]\tLoss: 0.046960\n",
      "Train Epoch: 9 [47360/48200 (98%)]\tLoss: 0.092241\n",
      "Train Epoch: 9 [48000/48200 (99%)]\tLoss: 0.210300\n",
      "\n",
      "Test set: Avg. loss: 0.0358, Accuracy: 7917/8017 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/48200 (0%)]\tLoss: 0.033202\n",
      "Train Epoch: 10 [640/48200 (1%)]\tLoss: 0.036244\n",
      "Train Epoch: 10 [1280/48200 (3%)]\tLoss: 0.111580\n",
      "Train Epoch: 10 [1920/48200 (4%)]\tLoss: 0.016421\n",
      "Train Epoch: 10 [2560/48200 (5%)]\tLoss: 0.096840\n",
      "Train Epoch: 10 [3200/48200 (7%)]\tLoss: 0.161580\n",
      "Train Epoch: 10 [3840/48200 (8%)]\tLoss: 0.166977\n",
      "Train Epoch: 10 [4480/48200 (9%)]\tLoss: 0.126473\n",
      "Train Epoch: 10 [5120/48200 (11%)]\tLoss: 0.182136\n",
      "Train Epoch: 10 [5760/48200 (12%)]\tLoss: 0.142870\n",
      "Train Epoch: 10 [6400/48200 (13%)]\tLoss: 0.194525\n",
      "Train Epoch: 10 [7040/48200 (15%)]\tLoss: 0.092773\n",
      "Train Epoch: 10 [7680/48200 (16%)]\tLoss: 0.014792\n",
      "Train Epoch: 10 [8320/48200 (17%)]\tLoss: 0.274553\n",
      "Train Epoch: 10 [8960/48200 (19%)]\tLoss: 0.021665\n",
      "Train Epoch: 10 [9600/48200 (20%)]\tLoss: 0.085809\n",
      "Train Epoch: 10 [10240/48200 (21%)]\tLoss: 0.079803\n",
      "Train Epoch: 10 [10880/48200 (23%)]\tLoss: 0.081674\n",
      "Train Epoch: 10 [11520/48200 (24%)]\tLoss: 0.067576\n",
      "Train Epoch: 10 [12160/48200 (25%)]\tLoss: 0.075772\n",
      "Train Epoch: 10 [12800/48200 (27%)]\tLoss: 0.051176\n",
      "Train Epoch: 10 [13440/48200 (28%)]\tLoss: 0.017329\n",
      "Train Epoch: 10 [14080/48200 (29%)]\tLoss: 0.018178\n",
      "Train Epoch: 10 [14720/48200 (31%)]\tLoss: 0.047210\n",
      "Train Epoch: 10 [15360/48200 (32%)]\tLoss: 0.112511\n",
      "Train Epoch: 10 [16000/48200 (33%)]\tLoss: 0.051284\n",
      "Train Epoch: 10 [16640/48200 (34%)]\tLoss: 0.017210\n",
      "Train Epoch: 10 [17280/48200 (36%)]\tLoss: 0.082680\n",
      "Train Epoch: 10 [17920/48200 (37%)]\tLoss: 0.094697\n",
      "Train Epoch: 10 [18560/48200 (38%)]\tLoss: 0.035932\n",
      "Train Epoch: 10 [19200/48200 (40%)]\tLoss: 0.073549\n",
      "Train Epoch: 10 [19840/48200 (41%)]\tLoss: 0.233264\n",
      "Train Epoch: 10 [20480/48200 (42%)]\tLoss: 0.044707\n",
      "Train Epoch: 10 [21120/48200 (44%)]\tLoss: 0.088090\n",
      "Train Epoch: 10 [21760/48200 (45%)]\tLoss: 0.120011\n",
      "Train Epoch: 10 [22400/48200 (46%)]\tLoss: 0.171006\n",
      "Train Epoch: 10 [23040/48200 (48%)]\tLoss: 0.133135\n",
      "Train Epoch: 10 [23680/48200 (49%)]\tLoss: 0.046202\n",
      "Train Epoch: 10 [24320/48200 (50%)]\tLoss: 0.066947\n",
      "Train Epoch: 10 [24960/48200 (52%)]\tLoss: 0.146723\n",
      "Train Epoch: 10 [25600/48200 (53%)]\tLoss: 0.031726\n",
      "Train Epoch: 10 [26240/48200 (54%)]\tLoss: 0.191726\n",
      "Train Epoch: 10 [26880/48200 (56%)]\tLoss: 0.196831\n",
      "Train Epoch: 10 [27520/48200 (57%)]\tLoss: 0.084825\n",
      "Train Epoch: 10 [28160/48200 (58%)]\tLoss: 0.013585\n",
      "Train Epoch: 10 [28800/48200 (60%)]\tLoss: 0.050167\n",
      "Train Epoch: 10 [29440/48200 (61%)]\tLoss: 0.108929\n",
      "Train Epoch: 10 [30080/48200 (62%)]\tLoss: 0.066674\n",
      "Train Epoch: 10 [30720/48200 (64%)]\tLoss: 0.028768\n",
      "Train Epoch: 10 [31360/48200 (65%)]\tLoss: 0.038414\n",
      "Train Epoch: 10 [32000/48200 (66%)]\tLoss: 0.063772\n",
      "Train Epoch: 10 [32640/48200 (68%)]\tLoss: 0.272656\n",
      "Train Epoch: 10 [33280/48200 (69%)]\tLoss: 0.042307\n",
      "Train Epoch: 10 [33920/48200 (70%)]\tLoss: 0.059630\n",
      "Train Epoch: 10 [34560/48200 (72%)]\tLoss: 0.038600\n",
      "Train Epoch: 10 [35200/48200 (73%)]\tLoss: 0.183556\n",
      "Train Epoch: 10 [35840/48200 (74%)]\tLoss: 0.070899\n",
      "Train Epoch: 10 [36480/48200 (76%)]\tLoss: 0.075144\n",
      "Train Epoch: 10 [37120/48200 (77%)]\tLoss: 0.081028\n",
      "Train Epoch: 10 [37760/48200 (78%)]\tLoss: 0.051733\n",
      "Train Epoch: 10 [38400/48200 (80%)]\tLoss: 0.017393\n",
      "Train Epoch: 10 [39040/48200 (81%)]\tLoss: 0.254735\n",
      "Train Epoch: 10 [39680/48200 (82%)]\tLoss: 0.021014\n",
      "Train Epoch: 10 [40320/48200 (84%)]\tLoss: 0.025346\n",
      "Train Epoch: 10 [40960/48200 (85%)]\tLoss: 0.034032\n",
      "Train Epoch: 10 [41600/48200 (86%)]\tLoss: 0.092987\n",
      "Train Epoch: 10 [42240/48200 (88%)]\tLoss: 0.054272\n",
      "Train Epoch: 10 [42880/48200 (89%)]\tLoss: 0.027992\n",
      "Train Epoch: 10 [43520/48200 (90%)]\tLoss: 0.075179\n",
      "Train Epoch: 10 [44160/48200 (92%)]\tLoss: 0.098713\n",
      "Train Epoch: 10 [44800/48200 (93%)]\tLoss: 0.087286\n",
      "Train Epoch: 10 [45440/48200 (94%)]\tLoss: 0.158231\n",
      "Train Epoch: 10 [46080/48200 (95%)]\tLoss: 0.068092\n",
      "Train Epoch: 10 [46720/48200 (97%)]\tLoss: 0.309926\n",
      "Train Epoch: 10 [47360/48200 (98%)]\tLoss: 0.085340\n",
      "Train Epoch: 10 [48000/48200 (99%)]\tLoss: 0.154545\n",
      "\n",
      "Test set: Avg. loss: 0.0317, Accuracy: 7924/8017 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net2_c8 = Net2_c8().cuda()\n",
    "n_epochs = 10\n",
    "optimizer = optim.SGD(net2_c8.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader8.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "test(net2_c8, test_loader8)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net2_c8, train_loader8, epoch)\n",
    "    test(net2_c8, test_loader8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00338522, 0.        , 0.        , 0.00338522, 0.        ,\n",
       "        0.        , 0.01354088, 0.01015566, 0.01354088, 0.01354088,\n",
       "        0.02031132, 0.02369655, 0.04400787, 0.03723743, 0.04062265,\n",
       "        0.06093397, 0.05754875, 0.07786008, 0.09478618, 0.12525317,\n",
       "        0.12525317, 0.14217927, 0.16587582, 0.11848273, 0.1624906 ,\n",
       "        0.16587582, 0.16926104, 0.21665413, 0.19634281, 0.1794167 ,\n",
       "        0.22342457, 0.17603148, 0.1794167 , 0.18957236, 0.18957236,\n",
       "        0.20988369, 0.18957236, 0.24035068, 0.21326891, 0.1624906 ,\n",
       "        0.15572016, 0.18618714, 0.1624906 , 0.11848273, 0.13879405,\n",
       "        0.11509751, 0.10494184, 0.10155662, 0.10155662, 0.14556449,\n",
       "        0.11848273, 0.11171229, 0.05754875, 0.08463052, 0.07786008,\n",
       "        0.09478618, 0.05754875, 0.05077831, 0.05416353, 0.04400787,\n",
       "        0.04062265, 0.03385221, 0.03046699, 0.04062265, 0.02369655,\n",
       "        0.03046699, 0.02031132, 0.01015566, 0.02708177, 0.01354088,\n",
       "        0.0169261 , 0.03046699, 0.01354088, 0.01354088, 0.01354088,\n",
       "        0.01015566, 0.        , 0.        , 0.00677044, 0.00677044,\n",
       "        0.00338522, 0.00677044, 0.00677044, 0.00677044, 0.00338522,\n",
       "        0.00338522, 0.00338522, 0.        , 0.        , 0.        ,\n",
       "        0.00338522, 0.00677044, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00338522, 0.        , 0.00338522]),\n",
       " array([ 6.71696369,  6.86466455,  7.0123654 ,  7.16006626,  7.30776711,\n",
       "         7.45546796,  7.60316882,  7.75086967,  7.89857053,  8.04627138,\n",
       "         8.19397223,  8.34167309,  8.48937394,  8.6370748 ,  8.78477565,\n",
       "         8.9324765 ,  9.08017736,  9.22787821,  9.37557907,  9.52327992,\n",
       "         9.67098078,  9.81868163,  9.96638248, 10.11408334, 10.26178419,\n",
       "        10.40948505, 10.5571859 , 10.70488675, 10.85258761, 11.00028846,\n",
       "        11.14798932, 11.29569017, 11.44339102, 11.59109188, 11.73879273,\n",
       "        11.88649359, 12.03419444, 12.18189529, 12.32959615, 12.477297  ,\n",
       "        12.62499786, 12.77269871, 12.92039956, 13.06810042, 13.21580127,\n",
       "        13.36350213, 13.51120298, 13.65890383, 13.80660469, 13.95430554,\n",
       "        14.1020064 , 14.24970725, 14.3974081 , 14.54510896, 14.69280981,\n",
       "        14.84051067, 14.98821152, 15.13591238, 15.28361323, 15.43131408,\n",
       "        15.57901494, 15.72671579, 15.87441665, 16.0221175 , 16.16981835,\n",
       "        16.31751921, 16.46522006, 16.61292092, 16.76062177, 16.90832262,\n",
       "        17.05602348, 17.20372433, 17.35142519, 17.49912604, 17.64682689,\n",
       "        17.79452775, 17.9422286 , 18.08992946, 18.23763031, 18.38533116,\n",
       "        18.53303202, 18.68073287, 18.82843373, 18.97613458, 19.12383543,\n",
       "        19.27153629, 19.41923714, 19.566938  , 19.71463885, 19.86233971,\n",
       "        20.01004056, 20.15774141, 20.30544227, 20.45314312, 20.60084398,\n",
       "        20.74854483, 20.89624568, 21.04394654, 21.19164739, 21.33934825,\n",
       "        21.4870491 ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEe1JREFUeJzt3W2MXFd9x/Hvr04TngoYYlqa2NiUUBHUKoEl0EKhPAVD25gXIIyKZNRUFqipCoi2QVRBGCElULXqi6iNRVxRSkkhPHSlGoXw1FaqAt6EEOKEEGNCspgWgymUUgKGf1/MTTpZZr1317M7sz7fj7TynXvPHf/XnvvbM2fOPZuqQpLUhp+ZdAGSpLVj6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JBeoZ9ke5I7khxKcumI429IcluSW5J8Isnjho79OMnN3dfsOIuXJC1PlrojN8kG4EvAC4F54ADwyqq6bajNc4HPVNX3k7wW+M2qekV37HtV9bC+BZ155pm1devWZX8jktSyG2+88ZtVtWmpdqf1eK4LgENVdRggyTXADuD+0K+qTw21vwF41fLK/X9bt25lbm5upadLUpOSfLVPuz7DO2cB9ww9nu/2LeZi4KNDjx+UZC7JDUleOuqEJLu7NnNHjx7tUZIkaSX69PQzYt/IMaEkrwJmgOcM7d5SVUeSPB74ZJIvVNWXH/BkVXuBvQAzMzOuACdJq6RPT38e2Dz0+GzgyMJGSV4AvBm4qKruvW9/VR3p/jwMfBo4/yTqlSSdhD6hfwA4J8m2JKcDO4EHzMJJcj5wFYPA/8bQ/o1Jzui2zwSeydBnAZKktbXk8E5VHU9yCXAdsAHYV1UHk+wB5qpqFngn8DDgA0kA7q6qi4AnAVcl+QmDHzCXD8/6kSStrSWnbK61mZmZcvaOJC1Pkhuramapdt6RK0kNMfQlqSGGviQ1pM88fWnNbL30n+/fvuvy35pgJdKpyZ6+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ1xlUyvmipjS+mNPX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIc7e0UjOzJFOTfb0Jakhhr4kNcThHU0th5ik8bOnL0kNMfQlqSEO72giHLqRJsOeviQ1xNCXpIYY+pLUEENfkhrSK/STbE9yR5JDSS4dcfwNSW5LckuSTyR53NCxXUnu7L52jbN4SdLyLBn6STYAVwIvBs4FXpnk3AXNPgfMVNWvAtcC7+jOfRTwFuDpwAXAW5JsHF/5kqTl6NPTvwA4VFWHq+qHwDXAjuEGVfWpqvp+9/AG4Oxu+0XA9VV1rKq+DVwPbB9P6ZKk5eoT+mcB9ww9nu/2LeZi4KPLOTfJ7iRzSeaOHj3aoyRJ0kr0Cf2M2FcjGyavAmaAdy7n3KraW1UzVTWzadOmHiVJklaiT+jPA5uHHp8NHFnYKMkLgDcDF1XVvcs5V5K0NvqE/gHgnCTbkpwO7ARmhxskOR+4ikHgf2Po0HXAhUk2dh/gXtjtkyRNwJJr71TV8SSXMAjrDcC+qjqYZA8wV1WzDIZzHgZ8IAnA3VV1UVUdS/I2Bj84APZU1bFV+U60alwnRzp19Fpwrar2A/sX7LtsaPsFJzh3H7BvpQVKksbHO3IlqSGGviQ1xNCXpIb4S1S0qoY/BD6ZNpLGw56+JDXE0Jekhji8o3Vt4dCQ9xFIJ2ZPX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIc7e0bJ4s5W0vtnTl6SGGPqS1BCHdzQWDulI64M9fUlqiKEvSQ0x9CWpIYa+JDXE0Jekhjh7R/dzBo506rOnL0kNMfQlqSEO75zChodrFvuNUg7pSG2xpy9JDTH0JakhDu80aD0O6fQZqlpOO6lV9vQlqSGGviQ1xNCXpIYY+pLUEENfkhri7B2tO+tx9pE0LXr19JNsT3JHkkNJLh1x/NlJbkpyPMnLFhz7cZKbu6/ZcRUuSVq+JXv6STYAVwIvBOaBA0lmq+q2oWZ3A68G3jjiKf63qs4bQ62SpJPUZ3jnAuBQVR0GSHINsAO4P/Sr6q7u2E9WoUZJ0pj0Gd45C7hn6PF8t6+vByWZS3JDkpcuqzpJ0lj16elnxL5axt+xpaqOJHk88MkkX6iqLz/gL0h2A7sBtmzZsoynliQtR5+e/jyweejx2cCRvn9BVR3p/jwMfBo4f0SbvVU1U1UzmzZt6vvUkqRl6hP6B4BzkmxLcjqwE+g1CyfJxiRndNtnAs9k6LMASdLaWnJ4p6qOJ7kEuA7YAOyrqoNJ9gBzVTWb5GnAh4GNwO8keWtVPRl4EnBV9wHvzwCXL5j1I009V+7UqaTXzVlVtR/Yv2DfZUPbBxgM+yw879+BXznJGiVJY+IyDJLUEJdhOMW4RIGkE7GnL0kNMfQlqSEO76gJzsCRBuzpS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDXHtnXXI5ZMlrZQ9fUlqiKEvSQ0x9CWpIYa+JDXE0Jekhjh7pxEtzvhZje/Z38Cl9c6eviQ1xNCXpIY4vKPmOESjltnTl6SGGPqS1BCHd6QVcphI65E9fUlqiKEvSQ0x9CWpIYa+JDXED3LVND+MVWt69fSTbE9yR5JDSS4dcfzZSW5KcjzJyxYc25Xkzu5r17gKlyQt35Khn2QDcCXwYuBc4JVJzl3Q7G7g1cA/LDj3UcBbgKcDFwBvSbLx5MuWJK1En+GdC4BDVXUYIMk1wA7gtvsaVNVd3bGfLDj3RcD1VXWsO349sB1430lXLo1ZiyuRqj19hnfOAu4Zejzf7evjZM6VJI1Zn9DPiH3V8/l7nZtkd5K5JHNHjx7t+dSSpOXqE/rzwOahx2cDR3o+f69zq2pvVc1U1cymTZt6PrUkabn6hP4B4Jwk25KcDuwEZns+/3XAhUk2dh/gXtjtkyRNwJKhX1XHgUsYhPXtwPur6mCSPUkuAkjytCTzwMuBq5Ic7M49BryNwQ+OA8Ce+z7UlSStvV43Z1XVfmD/gn2XDW0fYDB0M+rcfcC+k6hROLPkVOCNYJoGLsMgSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jaoi/OUsaM2/C0jSzpy9JDTH0Jakhhr4kNcTQl6SGGPqS1BBn70wxl1Ne//w/1LSxpy9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQV9mcAv5OVUlrxZ6+JDXE0JekhqSqJl3DA8zMzNTc3Nyky1hT/qKNtjmkp3FIcmNVzSzVzp6+JDXE0JekhvSavZNkO/BXwAbgXVV1+YLjZwB/BzwV+Bbwiqq6K8lW4Hbgjq7pDVX1mvGULp16nMml1bZk6CfZAFwJvBCYBw4kma2q24aaXQx8u6qekGQncAXwiu7Yl6vqvDHXLUlagT7DOxcAh6rqcFX9ELgG2LGgzQ7g3d32tcDzk2R8ZUqSxqHP8M5ZwD1Dj+eBpy/WpqqOJ/kO8Oju2LYknwO+C/xZVf3byZUsnVqcvaW11Cf0R/XYF87zXKzN14EtVfWtJE8FPpLkyVX13QecnOwGdgNs2bKlR0mSpJXoM7wzD2weenw2cGSxNklOAx4BHKuqe6vqWwBVdSPwZeCJC/+CqtpbVTNVNbNp06blfxeSpF76hP4B4Jwk25KcDuwEZhe0mQV2ddsvAz5ZVZVkU/dBMEkeD5wDHB5P6ZKk5VpyeKcbo78EuI7BlM19VXUwyR5grqpmgauB9yQ5BBxj8IMB4NnAniTHgR8Dr6mqY6vxjUiSltZrnn5V7Qf2L9h32dD2D4CXjzjvg8AHT7JGSdKYuLTyKvNmG62Urx2tBpdhkKSGGPqS1BCHdybEG3K0HH2GehwOUh/29CWpIYa+JDXE4Z015JCOpEmzpy9JDTH0JakhDu9I64yzdHQy7OlLUkMMfUlqiMM70jrWd0bYuIaEHFpa/+zpS1JD7OlLAuzFt8KeviQ1xNCXpIY4vLMKXG5Bk+ZrUIuxpy9JDTH0JakhDu+MiW+ntV44S6dt9vQlqSGGviQ1xOEdSSfk0OWpxZ6+JDXE0Jekhji8s4jFZjj4Vlct6PM679PG2UHTx56+JDXE0JekhqSqJl3DA8zMzNTc3Nyky3AYRxozh3pWV5Ibq2pmqXb29CWpIYa+JDXE2TuSJmqxodTlzppbreGjU22tInv6ktSQXqGfZHuSO5IcSnLpiONnJPnH7vhnkmwdOvambv8dSV40vtIlScu15PBOkg3AlcALgXngQJLZqrptqNnFwLer6glJdgJXAK9Ici6wE3gy8IvAx5M8sap+PO5v5D593oqdam/XpFPRcmfQjXMIaDVm7/W54XMt8qhPT/8C4FBVHa6qHwLXADsWtNkBvLvbvhZ4fpJ0+6+pqnur6ivAoe75JEkT0Cf0zwLuGXo83+0b2aaqjgPfAR7d81xJ0hrpM3snI/YtvKNrsTZ9ziXJbmB39/B7Sb4FfLNHbSeUK8bTZhFnMoYaV9l6qBHWR53WeJK6a22iNfa83het8STyotfzLPP5F9b5uD4n9Qn9eWDz0OOzgSOLtJlPchrwCOBYz3Opqr3A3vseJ5nrc2fZJFnj+KyHOq1xPKxxfFZaZ5/hnQPAOUm2JTmdwQezswvazAK7uu2XAZ+swfoOs8DObnbPNuAc4LPLLVKSNB5L9vSr6niSS4DrgA3Avqo6mGQPMFdVs8DVwHuSHGLQw9/ZnXswyfuB24DjwB+s5swdSdKJ9bojt6r2A/sX7LtsaPsHwMsXOfftwNuXWdfepZtMnDWOz3qo0xrHwxrHZ0V1Tt0qm5Kk1eMyDJLUkKkK/SSPTHJtki8muT3Jr026plGSvD7JwSS3JnlfkgdNQU37knwjya1D+x6V5Pokd3Z/bpzCGt/Z/X/fkuTDSR45yRq7mn6qzqFjb0xSSc6cRG1DdYysMckfdkueHEzyjknV19Uy6v/7vCQ3JLk5yVySid6smWRzkk91eXMwyR91+6fm2jlBjSu7dqpqar4Y3NX7+9326cAjJ13TiBrPAr4CPLh7/H7g1VNQ17OBpwC3Du17B3Bpt30pcMUU1nghcFq3fcWka1yszm7/ZgYTGr4KnDltNQLPBT4OnNE9fswU1vgx4MXd9kuAT0+4xscCT+m2fw74EnDuNF07J6hxRdfO1PT0kzycwYvkaoCq+mFV/ddkq1rUacCDu3sSHsKIew/WWlX9K4OZU8OGl8d4N/DSNS1qgVE1VtXHanAXN8ANDO7lmKhF/i0B/hL4E0bcYLjWFqnxtcDlVXVv1+Yba17YkEVqLODh3fYjmPC1U1Vfr6qbuu3/Bm5n0LGbmmtnsRpXeu1MTegDjweOAn+b5HNJ3pXkoZMuaqGq+hrw58DdwNeB71TVxyZb1aJ+vqq+DoMXDvCYCdezlN8DPjrpIkZJchHwtar6/KRrOYEnAr/RrXT7L0meNumCRngd8M4k9zC4jt404Xru160OfD7wGab02llQ47De1840hf5pDN4K/nVVnQ/8D4O3VVOlG9vbAWxjsHLoQ5O8arJVrX9J3szgXo73TrqWhZI8BHgzcNlSbSfsNGAj8Azgj4H3dwsfTpPXAq+vqs3A6+ne2U9akocBHwReV1XfnXQ9oyxW43KvnWkK/Xlgvqru+wl2LYMfAtPmBcBXqupoVf0I+BDw6xOuaTH/meSxAN2fE327v5gku4DfBn63ugHKKfNLDH7Ifz7JXQzeRt+U5BcmWtVPmwc+VAOfBX7CYH2WabKLwTUD8AGmYNXdJD/LIEzfW1X31TZV184iNa7o2pma0K+q/wDuSfLL3a7nM7iTd9rcDTwjyUO6XtTzGYyxTaPh5TF2Af80wVpGSrId+FPgoqr6/qTrGaWqvlBVj6mqrVW1lUG4PqV7zU6TjwDPA0jyRAaTIaZtAbYjwHO67ecBd06wFrpr+Grg9qr6i6FDU3PtLFbjiq+dSX0ivcin1OcBc8AtDF7AGydd0yJ1vhX4InAr8B662RITrul9DD5j+BGDULqYwfLWn2BwYX0CeNQU1niIwfLbN3dffzON/5YLjt/F5GfvjPq3PB34++51eRPwvCms8VnAjcDnGYxLP3XCNT6LwYfLtwy9Bl8yTdfOCWpc0bXjHbmS1JCpGd6RJK0+Q1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIb8H8yFw+l9PVd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = net2_c8(noise.cuda())\n",
    "ll = net2_c8.last\n",
    "print(ll.shape)\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net2_c8 = LID(ll, ll, k=50)\n",
    "plt.hist(lid_net2_c8, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.352073653268565\n",
      "12.127778225896543\n",
      "10.343094565354395\n",
      "12.188324013133153\n"
     ]
    }
   ],
   "source": [
    "print(lid_net1_c10.mean())\n",
    "print(lid_net2_c10.mean())\n",
    "\n",
    "print(lid_net1_c8.mean())\n",
    "print(lid_net2_c8.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network using 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_c5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_c5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.6136, Accuracy: 776/5139 (15%)\n",
      "\n",
      "Train Epoch: 1 [0/30596 (0%)]\tLoss: 1.624736\n",
      "Train Epoch: 1 [640/30596 (2%)]\tLoss: 1.574385\n",
      "Train Epoch: 1 [1280/30596 (4%)]\tLoss: 1.527636\n",
      "Train Epoch: 1 [1920/30596 (6%)]\tLoss: 1.447317\n",
      "Train Epoch: 1 [2560/30596 (8%)]\tLoss: 1.273492\n",
      "Train Epoch: 1 [3200/30596 (10%)]\tLoss: 1.208273\n",
      "Train Epoch: 1 [3840/30596 (13%)]\tLoss: 1.018849\n",
      "Train Epoch: 1 [4480/30596 (15%)]\tLoss: 0.882609\n",
      "Train Epoch: 1 [5120/30596 (17%)]\tLoss: 0.804402\n",
      "Train Epoch: 1 [5760/30596 (19%)]\tLoss: 0.896352\n",
      "Train Epoch: 1 [6400/30596 (21%)]\tLoss: 0.567690\n",
      "Train Epoch: 1 [7040/30596 (23%)]\tLoss: 0.417135\n",
      "Train Epoch: 1 [7680/30596 (25%)]\tLoss: 0.492278\n",
      "Train Epoch: 1 [8320/30596 (27%)]\tLoss: 0.576188\n",
      "Train Epoch: 1 [8960/30596 (29%)]\tLoss: 0.281412\n",
      "Train Epoch: 1 [9600/30596 (31%)]\tLoss: 0.420193\n",
      "Train Epoch: 1 [10240/30596 (33%)]\tLoss: 0.406761\n",
      "Train Epoch: 1 [10880/30596 (35%)]\tLoss: 0.440940\n",
      "Train Epoch: 1 [11520/30596 (38%)]\tLoss: 0.268332\n",
      "Train Epoch: 1 [12160/30596 (40%)]\tLoss: 0.358981\n",
      "Train Epoch: 1 [12800/30596 (42%)]\tLoss: 0.323008\n",
      "Train Epoch: 1 [13440/30596 (44%)]\tLoss: 0.307929\n",
      "Train Epoch: 1 [14080/30596 (46%)]\tLoss: 0.234625\n",
      "Train Epoch: 1 [14720/30596 (48%)]\tLoss: 0.154203\n",
      "Train Epoch: 1 [15360/30596 (50%)]\tLoss: 0.267372\n",
      "Train Epoch: 1 [16000/30596 (52%)]\tLoss: 0.242541\n",
      "Train Epoch: 1 [16640/30596 (54%)]\tLoss: 0.200308\n",
      "Train Epoch: 1 [17280/30596 (56%)]\tLoss: 0.121298\n",
      "Train Epoch: 1 [17920/30596 (58%)]\tLoss: 0.174622\n",
      "Train Epoch: 1 [18560/30596 (61%)]\tLoss: 0.163233\n",
      "Train Epoch: 1 [19200/30596 (63%)]\tLoss: 0.311072\n",
      "Train Epoch: 1 [19840/30596 (65%)]\tLoss: 0.270219\n",
      "Train Epoch: 1 [20480/30596 (67%)]\tLoss: 0.273834\n",
      "Train Epoch: 1 [21120/30596 (69%)]\tLoss: 0.193656\n",
      "Train Epoch: 1 [21760/30596 (71%)]\tLoss: 0.219028\n",
      "Train Epoch: 1 [22400/30596 (73%)]\tLoss: 0.205612\n",
      "Train Epoch: 1 [23040/30596 (75%)]\tLoss: 0.364003\n",
      "Train Epoch: 1 [23680/30596 (77%)]\tLoss: 0.298925\n",
      "Train Epoch: 1 [24320/30596 (79%)]\tLoss: 0.152416\n",
      "Train Epoch: 1 [24960/30596 (81%)]\tLoss: 0.199741\n",
      "Train Epoch: 1 [25600/30596 (84%)]\tLoss: 0.203551\n",
      "Train Epoch: 1 [26240/30596 (86%)]\tLoss: 0.105790\n",
      "Train Epoch: 1 [26880/30596 (88%)]\tLoss: 0.224142\n",
      "Train Epoch: 1 [27520/30596 (90%)]\tLoss: 0.280064\n",
      "Train Epoch: 1 [28160/30596 (92%)]\tLoss: 0.389920\n",
      "Train Epoch: 1 [28800/30596 (94%)]\tLoss: 0.182564\n",
      "Train Epoch: 1 [29440/30596 (96%)]\tLoss: 0.255095\n",
      "Train Epoch: 1 [30080/30596 (98%)]\tLoss: 0.156606\n",
      "\n",
      "Test set: Avg. loss: 0.0909, Accuracy: 4987/5139 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/30596 (0%)]\tLoss: 0.137275\n",
      "Train Epoch: 2 [640/30596 (2%)]\tLoss: 0.152972\n",
      "Train Epoch: 2 [1280/30596 (4%)]\tLoss: 0.144199\n",
      "Train Epoch: 2 [1920/30596 (6%)]\tLoss: 0.157030\n",
      "Train Epoch: 2 [2560/30596 (8%)]\tLoss: 0.348486\n",
      "Train Epoch: 2 [3200/30596 (10%)]\tLoss: 0.255165\n",
      "Train Epoch: 2 [3840/30596 (13%)]\tLoss: 0.203121\n",
      "Train Epoch: 2 [4480/30596 (15%)]\tLoss: 0.068761\n",
      "Train Epoch: 2 [5120/30596 (17%)]\tLoss: 0.093180\n",
      "Train Epoch: 2 [5760/30596 (19%)]\tLoss: 0.203261\n",
      "Train Epoch: 2 [6400/30596 (21%)]\tLoss: 0.386961\n",
      "Train Epoch: 2 [7040/30596 (23%)]\tLoss: 0.258468\n",
      "Train Epoch: 2 [7680/30596 (25%)]\tLoss: 0.170882\n",
      "Train Epoch: 2 [8320/30596 (27%)]\tLoss: 0.098310\n",
      "Train Epoch: 2 [8960/30596 (29%)]\tLoss: 0.161021\n",
      "Train Epoch: 2 [9600/30596 (31%)]\tLoss: 0.138076\n",
      "Train Epoch: 2 [10240/30596 (33%)]\tLoss: 0.214746\n",
      "Train Epoch: 2 [10880/30596 (35%)]\tLoss: 0.097835\n",
      "Train Epoch: 2 [11520/30596 (38%)]\tLoss: 0.216776\n",
      "Train Epoch: 2 [12160/30596 (40%)]\tLoss: 0.251119\n",
      "Train Epoch: 2 [12800/30596 (42%)]\tLoss: 0.198698\n",
      "Train Epoch: 2 [13440/30596 (44%)]\tLoss: 0.169587\n",
      "Train Epoch: 2 [14080/30596 (46%)]\tLoss: 0.235979\n",
      "Train Epoch: 2 [14720/30596 (48%)]\tLoss: 0.068575\n",
      "Train Epoch: 2 [15360/30596 (50%)]\tLoss: 0.182437\n",
      "Train Epoch: 2 [16000/30596 (52%)]\tLoss: 0.111788\n",
      "Train Epoch: 2 [16640/30596 (54%)]\tLoss: 0.148913\n",
      "Train Epoch: 2 [17280/30596 (56%)]\tLoss: 0.209666\n",
      "Train Epoch: 2 [17920/30596 (58%)]\tLoss: 0.093654\n",
      "Train Epoch: 2 [18560/30596 (61%)]\tLoss: 0.254856\n",
      "Train Epoch: 2 [19200/30596 (63%)]\tLoss: 0.123135\n",
      "Train Epoch: 2 [19840/30596 (65%)]\tLoss: 0.218364\n",
      "Train Epoch: 2 [20480/30596 (67%)]\tLoss: 0.115538\n",
      "Train Epoch: 2 [21120/30596 (69%)]\tLoss: 0.102910\n",
      "Train Epoch: 2 [21760/30596 (71%)]\tLoss: 0.388598\n",
      "Train Epoch: 2 [22400/30596 (73%)]\tLoss: 0.133294\n",
      "Train Epoch: 2 [23040/30596 (75%)]\tLoss: 0.136829\n",
      "Train Epoch: 2 [23680/30596 (77%)]\tLoss: 0.057187\n",
      "Train Epoch: 2 [24320/30596 (79%)]\tLoss: 0.104446\n",
      "Train Epoch: 2 [24960/30596 (81%)]\tLoss: 0.098329\n",
      "Train Epoch: 2 [25600/30596 (84%)]\tLoss: 0.175760\n",
      "Train Epoch: 2 [26240/30596 (86%)]\tLoss: 0.132970\n",
      "Train Epoch: 2 [26880/30596 (88%)]\tLoss: 0.122705\n",
      "Train Epoch: 2 [27520/30596 (90%)]\tLoss: 0.099494\n",
      "Train Epoch: 2 [28160/30596 (92%)]\tLoss: 0.132958\n",
      "Train Epoch: 2 [28800/30596 (94%)]\tLoss: 0.105343\n",
      "Train Epoch: 2 [29440/30596 (96%)]\tLoss: 0.334792\n",
      "Train Epoch: 2 [30080/30596 (98%)]\tLoss: 0.124023\n",
      "\n",
      "Test set: Avg. loss: 0.0436, Accuracy: 5064/5139 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/30596 (0%)]\tLoss: 0.091953\n",
      "Train Epoch: 3 [640/30596 (2%)]\tLoss: 0.063611\n",
      "Train Epoch: 3 [1280/30596 (4%)]\tLoss: 0.173455\n",
      "Train Epoch: 3 [1920/30596 (6%)]\tLoss: 0.126004\n",
      "Train Epoch: 3 [2560/30596 (8%)]\tLoss: 0.056758\n",
      "Train Epoch: 3 [3200/30596 (10%)]\tLoss: 0.380061\n",
      "Train Epoch: 3 [3840/30596 (13%)]\tLoss: 0.044645\n",
      "Train Epoch: 3 [4480/30596 (15%)]\tLoss: 0.134727\n",
      "Train Epoch: 3 [5120/30596 (17%)]\tLoss: 0.163265\n",
      "Train Epoch: 3 [5760/30596 (19%)]\tLoss: 0.063852\n",
      "Train Epoch: 3 [6400/30596 (21%)]\tLoss: 0.232300\n",
      "Train Epoch: 3 [7040/30596 (23%)]\tLoss: 0.152093\n",
      "Train Epoch: 3 [7680/30596 (25%)]\tLoss: 0.200223\n",
      "Train Epoch: 3 [8320/30596 (27%)]\tLoss: 0.094148\n",
      "Train Epoch: 3 [8960/30596 (29%)]\tLoss: 0.093046\n",
      "Train Epoch: 3 [9600/30596 (31%)]\tLoss: 0.127484\n",
      "Train Epoch: 3 [10240/30596 (33%)]\tLoss: 0.103578\n",
      "Train Epoch: 3 [10880/30596 (35%)]\tLoss: 0.183276\n",
      "Train Epoch: 3 [11520/30596 (38%)]\tLoss: 0.182592\n",
      "Train Epoch: 3 [12160/30596 (40%)]\tLoss: 0.157766\n",
      "Train Epoch: 3 [12800/30596 (42%)]\tLoss: 0.130195\n",
      "Train Epoch: 3 [13440/30596 (44%)]\tLoss: 0.082038\n",
      "Train Epoch: 3 [14080/30596 (46%)]\tLoss: 0.076515\n",
      "Train Epoch: 3 [14720/30596 (48%)]\tLoss: 0.220154\n",
      "Train Epoch: 3 [15360/30596 (50%)]\tLoss: 0.111114\n",
      "Train Epoch: 3 [16000/30596 (52%)]\tLoss: 0.053586\n",
      "Train Epoch: 3 [16640/30596 (54%)]\tLoss: 0.167119\n",
      "Train Epoch: 3 [17280/30596 (56%)]\tLoss: 0.210926\n",
      "Train Epoch: 3 [17920/30596 (58%)]\tLoss: 0.097422\n",
      "Train Epoch: 3 [18560/30596 (61%)]\tLoss: 0.045570\n",
      "Train Epoch: 3 [19200/30596 (63%)]\tLoss: 0.225772\n",
      "Train Epoch: 3 [19840/30596 (65%)]\tLoss: 0.170177\n",
      "Train Epoch: 3 [20480/30596 (67%)]\tLoss: 0.055881\n",
      "Train Epoch: 3 [21120/30596 (69%)]\tLoss: 0.111733\n",
      "Train Epoch: 3 [21760/30596 (71%)]\tLoss: 0.080948\n",
      "Train Epoch: 3 [22400/30596 (73%)]\tLoss: 0.207030\n",
      "Train Epoch: 3 [23040/30596 (75%)]\tLoss: 0.041917\n",
      "Train Epoch: 3 [23680/30596 (77%)]\tLoss: 0.100142\n",
      "Train Epoch: 3 [24320/30596 (79%)]\tLoss: 0.097253\n",
      "Train Epoch: 3 [24960/30596 (81%)]\tLoss: 0.088844\n",
      "Train Epoch: 3 [25600/30596 (84%)]\tLoss: 0.166068\n",
      "Train Epoch: 3 [26240/30596 (86%)]\tLoss: 0.142585\n",
      "Train Epoch: 3 [26880/30596 (88%)]\tLoss: 0.443452\n",
      "Train Epoch: 3 [27520/30596 (90%)]\tLoss: 0.063585\n",
      "Train Epoch: 3 [28160/30596 (92%)]\tLoss: 0.059206\n",
      "Train Epoch: 3 [28800/30596 (94%)]\tLoss: 0.058355\n",
      "Train Epoch: 3 [29440/30596 (96%)]\tLoss: 0.126496\n",
      "Train Epoch: 3 [30080/30596 (98%)]\tLoss: 0.033947\n",
      "\n",
      "Test set: Avg. loss: 0.0325, Accuracy: 5079/5139 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/30596 (0%)]\tLoss: 0.148190\n",
      "Train Epoch: 4 [640/30596 (2%)]\tLoss: 0.090826\n",
      "Train Epoch: 4 [1280/30596 (4%)]\tLoss: 0.041932\n",
      "Train Epoch: 4 [1920/30596 (6%)]\tLoss: 0.070079\n",
      "Train Epoch: 4 [2560/30596 (8%)]\tLoss: 0.141138\n",
      "Train Epoch: 4 [3200/30596 (10%)]\tLoss: 0.174680\n",
      "Train Epoch: 4 [3840/30596 (13%)]\tLoss: 0.078737\n",
      "Train Epoch: 4 [4480/30596 (15%)]\tLoss: 0.096725\n",
      "Train Epoch: 4 [5120/30596 (17%)]\tLoss: 0.044022\n",
      "Train Epoch: 4 [5760/30596 (19%)]\tLoss: 0.053859\n",
      "Train Epoch: 4 [6400/30596 (21%)]\tLoss: 0.116002\n",
      "Train Epoch: 4 [7040/30596 (23%)]\tLoss: 0.085566\n",
      "Train Epoch: 4 [7680/30596 (25%)]\tLoss: 0.037648\n",
      "Train Epoch: 4 [8320/30596 (27%)]\tLoss: 0.122832\n",
      "Train Epoch: 4 [8960/30596 (29%)]\tLoss: 0.083985\n",
      "Train Epoch: 4 [9600/30596 (31%)]\tLoss: 0.044732\n",
      "Train Epoch: 4 [10240/30596 (33%)]\tLoss: 0.144432\n",
      "Train Epoch: 4 [10880/30596 (35%)]\tLoss: 0.111515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [11520/30596 (38%)]\tLoss: 0.117020\n",
      "Train Epoch: 4 [12160/30596 (40%)]\tLoss: 0.153038\n",
      "Train Epoch: 4 [12800/30596 (42%)]\tLoss: 0.075280\n",
      "Train Epoch: 4 [13440/30596 (44%)]\tLoss: 0.154982\n",
      "Train Epoch: 4 [14080/30596 (46%)]\tLoss: 0.097636\n",
      "Train Epoch: 4 [14720/30596 (48%)]\tLoss: 0.156357\n",
      "Train Epoch: 4 [15360/30596 (50%)]\tLoss: 0.386735\n",
      "Train Epoch: 4 [16000/30596 (52%)]\tLoss: 0.066318\n",
      "Train Epoch: 4 [16640/30596 (54%)]\tLoss: 0.036759\n",
      "Train Epoch: 4 [17280/30596 (56%)]\tLoss: 0.059006\n",
      "Train Epoch: 4 [17920/30596 (58%)]\tLoss: 0.166732\n",
      "Train Epoch: 4 [18560/30596 (61%)]\tLoss: 0.059458\n",
      "Train Epoch: 4 [19200/30596 (63%)]\tLoss: 0.168574\n",
      "Train Epoch: 4 [19840/30596 (65%)]\tLoss: 0.178940\n",
      "Train Epoch: 4 [20480/30596 (67%)]\tLoss: 0.061106\n",
      "Train Epoch: 4 [21120/30596 (69%)]\tLoss: 0.086548\n",
      "Train Epoch: 4 [21760/30596 (71%)]\tLoss: 0.061440\n",
      "Train Epoch: 4 [22400/30596 (73%)]\tLoss: 0.145853\n",
      "Train Epoch: 4 [23040/30596 (75%)]\tLoss: 0.062898\n",
      "Train Epoch: 4 [23680/30596 (77%)]\tLoss: 0.136555\n",
      "Train Epoch: 4 [24320/30596 (79%)]\tLoss: 0.045974\n",
      "Train Epoch: 4 [24960/30596 (81%)]\tLoss: 0.069408\n",
      "Train Epoch: 4 [25600/30596 (84%)]\tLoss: 0.106820\n",
      "Train Epoch: 4 [26240/30596 (86%)]\tLoss: 0.113017\n",
      "Train Epoch: 4 [26880/30596 (88%)]\tLoss: 0.156226\n",
      "Train Epoch: 4 [27520/30596 (90%)]\tLoss: 0.037110\n",
      "Train Epoch: 4 [28160/30596 (92%)]\tLoss: 0.061544\n",
      "Train Epoch: 4 [28800/30596 (94%)]\tLoss: 0.139873\n",
      "Train Epoch: 4 [29440/30596 (96%)]\tLoss: 0.135664\n",
      "Train Epoch: 4 [30080/30596 (98%)]\tLoss: 0.179450\n",
      "\n",
      "Test set: Avg. loss: 0.0291, Accuracy: 5084/5139 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/30596 (0%)]\tLoss: 0.158403\n",
      "Train Epoch: 5 [640/30596 (2%)]\tLoss: 0.010958\n",
      "Train Epoch: 5 [1280/30596 (4%)]\tLoss: 0.103923\n",
      "Train Epoch: 5 [1920/30596 (6%)]\tLoss: 0.285814\n",
      "Train Epoch: 5 [2560/30596 (8%)]\tLoss: 0.077576\n",
      "Train Epoch: 5 [3200/30596 (10%)]\tLoss: 0.097358\n",
      "Train Epoch: 5 [3840/30596 (13%)]\tLoss: 0.060698\n",
      "Train Epoch: 5 [4480/30596 (15%)]\tLoss: 0.149457\n",
      "Train Epoch: 5 [5120/30596 (17%)]\tLoss: 0.134067\n",
      "Train Epoch: 5 [5760/30596 (19%)]\tLoss: 0.079320\n",
      "Train Epoch: 5 [6400/30596 (21%)]\tLoss: 0.080298\n",
      "Train Epoch: 5 [7040/30596 (23%)]\tLoss: 0.067678\n",
      "Train Epoch: 5 [7680/30596 (25%)]\tLoss: 0.088526\n",
      "Train Epoch: 5 [8320/30596 (27%)]\tLoss: 0.075352\n",
      "Train Epoch: 5 [8960/30596 (29%)]\tLoss: 0.104542\n",
      "Train Epoch: 5 [9600/30596 (31%)]\tLoss: 0.283680\n",
      "Train Epoch: 5 [10240/30596 (33%)]\tLoss: 0.079432\n",
      "Train Epoch: 5 [10880/30596 (35%)]\tLoss: 0.032293\n",
      "Train Epoch: 5 [11520/30596 (38%)]\tLoss: 0.151100\n",
      "Train Epoch: 5 [12160/30596 (40%)]\tLoss: 0.043365\n",
      "Train Epoch: 5 [12800/30596 (42%)]\tLoss: 0.023069\n",
      "Train Epoch: 5 [13440/30596 (44%)]\tLoss: 0.047486\n",
      "Train Epoch: 5 [14080/30596 (46%)]\tLoss: 0.191821\n",
      "Train Epoch: 5 [14720/30596 (48%)]\tLoss: 0.086004\n",
      "Train Epoch: 5 [15360/30596 (50%)]\tLoss: 0.036613\n",
      "Train Epoch: 5 [16000/30596 (52%)]\tLoss: 0.090507\n",
      "Train Epoch: 5 [16640/30596 (54%)]\tLoss: 0.051218\n",
      "Train Epoch: 5 [17280/30596 (56%)]\tLoss: 0.110946\n",
      "Train Epoch: 5 [17920/30596 (58%)]\tLoss: 0.024860\n",
      "Train Epoch: 5 [18560/30596 (61%)]\tLoss: 0.186735\n",
      "Train Epoch: 5 [19200/30596 (63%)]\tLoss: 0.016848\n",
      "Train Epoch: 5 [19840/30596 (65%)]\tLoss: 0.084729\n",
      "Train Epoch: 5 [20480/30596 (67%)]\tLoss: 0.171805\n",
      "Train Epoch: 5 [21120/30596 (69%)]\tLoss: 0.064530\n",
      "Train Epoch: 5 [21760/30596 (71%)]\tLoss: 0.063704\n",
      "Train Epoch: 5 [22400/30596 (73%)]\tLoss: 0.057115\n",
      "Train Epoch: 5 [23040/30596 (75%)]\tLoss: 0.051002\n",
      "Train Epoch: 5 [23680/30596 (77%)]\tLoss: 0.139234\n",
      "Train Epoch: 5 [24320/30596 (79%)]\tLoss: 0.145671\n",
      "Train Epoch: 5 [24960/30596 (81%)]\tLoss: 0.062495\n",
      "Train Epoch: 5 [25600/30596 (84%)]\tLoss: 0.051537\n",
      "Train Epoch: 5 [26240/30596 (86%)]\tLoss: 0.117926\n",
      "Train Epoch: 5 [26880/30596 (88%)]\tLoss: 0.134638\n",
      "Train Epoch: 5 [27520/30596 (90%)]\tLoss: 0.211271\n",
      "Train Epoch: 5 [28160/30596 (92%)]\tLoss: 0.096693\n",
      "Train Epoch: 5 [28800/30596 (94%)]\tLoss: 0.041268\n",
      "Train Epoch: 5 [29440/30596 (96%)]\tLoss: 0.050333\n",
      "Train Epoch: 5 [30080/30596 (98%)]\tLoss: 0.072064\n",
      "\n",
      "Test set: Avg. loss: 0.0228, Accuracy: 5099/5139 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/30596 (0%)]\tLoss: 0.217072\n",
      "Train Epoch: 6 [640/30596 (2%)]\tLoss: 0.162112\n",
      "Train Epoch: 6 [1280/30596 (4%)]\tLoss: 0.202571\n",
      "Train Epoch: 6 [1920/30596 (6%)]\tLoss: 0.029493\n",
      "Train Epoch: 6 [2560/30596 (8%)]\tLoss: 0.116537\n",
      "Train Epoch: 6 [3200/30596 (10%)]\tLoss: 0.146041\n",
      "Train Epoch: 6 [3840/30596 (13%)]\tLoss: 0.089712\n",
      "Train Epoch: 6 [4480/30596 (15%)]\tLoss: 0.040155\n",
      "Train Epoch: 6 [5120/30596 (17%)]\tLoss: 0.099945\n",
      "Train Epoch: 6 [5760/30596 (19%)]\tLoss: 0.039584\n",
      "Train Epoch: 6 [6400/30596 (21%)]\tLoss: 0.027806\n",
      "Train Epoch: 6 [7040/30596 (23%)]\tLoss: 0.039912\n",
      "Train Epoch: 6 [7680/30596 (25%)]\tLoss: 0.163345\n",
      "Train Epoch: 6 [8320/30596 (27%)]\tLoss: 0.129774\n",
      "Train Epoch: 6 [8960/30596 (29%)]\tLoss: 0.113695\n",
      "Train Epoch: 6 [9600/30596 (31%)]\tLoss: 0.016504\n",
      "Train Epoch: 6 [10240/30596 (33%)]\tLoss: 0.096533\n",
      "Train Epoch: 6 [10880/30596 (35%)]\tLoss: 0.047168\n",
      "Train Epoch: 6 [11520/30596 (38%)]\tLoss: 0.165296\n",
      "Train Epoch: 6 [12160/30596 (40%)]\tLoss: 0.120831\n",
      "Train Epoch: 6 [12800/30596 (42%)]\tLoss: 0.034771\n",
      "Train Epoch: 6 [13440/30596 (44%)]\tLoss: 0.097592\n",
      "Train Epoch: 6 [14080/30596 (46%)]\tLoss: 0.081350\n",
      "Train Epoch: 6 [14720/30596 (48%)]\tLoss: 0.081811\n",
      "Train Epoch: 6 [15360/30596 (50%)]\tLoss: 0.082236\n",
      "Train Epoch: 6 [16000/30596 (52%)]\tLoss: 0.080531\n",
      "Train Epoch: 6 [16640/30596 (54%)]\tLoss: 0.139053\n",
      "Train Epoch: 6 [17280/30596 (56%)]\tLoss: 0.037586\n",
      "Train Epoch: 6 [17920/30596 (58%)]\tLoss: 0.053018\n",
      "Train Epoch: 6 [18560/30596 (61%)]\tLoss: 0.060120\n",
      "Train Epoch: 6 [19200/30596 (63%)]\tLoss: 0.108746\n",
      "Train Epoch: 6 [19840/30596 (65%)]\tLoss: 0.080490\n",
      "Train Epoch: 6 [20480/30596 (67%)]\tLoss: 0.026667\n",
      "Train Epoch: 6 [21120/30596 (69%)]\tLoss: 0.053635\n",
      "Train Epoch: 6 [21760/30596 (71%)]\tLoss: 0.039187\n",
      "Train Epoch: 6 [22400/30596 (73%)]\tLoss: 0.010998\n",
      "Train Epoch: 6 [23040/30596 (75%)]\tLoss: 0.057161\n",
      "Train Epoch: 6 [23680/30596 (77%)]\tLoss: 0.034209\n",
      "Train Epoch: 6 [24320/30596 (79%)]\tLoss: 0.036853\n",
      "Train Epoch: 6 [24960/30596 (81%)]\tLoss: 0.069464\n",
      "Train Epoch: 6 [25600/30596 (84%)]\tLoss: 0.157970\n",
      "Train Epoch: 6 [26240/30596 (86%)]\tLoss: 0.072594\n",
      "Train Epoch: 6 [26880/30596 (88%)]\tLoss: 0.099767\n",
      "Train Epoch: 6 [27520/30596 (90%)]\tLoss: 0.066629\n",
      "Train Epoch: 6 [28160/30596 (92%)]\tLoss: 0.120312\n",
      "Train Epoch: 6 [28800/30596 (94%)]\tLoss: 0.036032\n",
      "Train Epoch: 6 [29440/30596 (96%)]\tLoss: 0.136227\n",
      "Train Epoch: 6 [30080/30596 (98%)]\tLoss: 0.117903\n",
      "\n",
      "Test set: Avg. loss: 0.0215, Accuracy: 5104/5139 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/30596 (0%)]\tLoss: 0.093476\n",
      "Train Epoch: 7 [640/30596 (2%)]\tLoss: 0.075910\n",
      "Train Epoch: 7 [1280/30596 (4%)]\tLoss: 0.075726\n",
      "Train Epoch: 7 [1920/30596 (6%)]\tLoss: 0.018666\n",
      "Train Epoch: 7 [2560/30596 (8%)]\tLoss: 0.230518\n",
      "Train Epoch: 7 [3200/30596 (10%)]\tLoss: 0.098756\n",
      "Train Epoch: 7 [3840/30596 (13%)]\tLoss: 0.131749\n",
      "Train Epoch: 7 [4480/30596 (15%)]\tLoss: 0.008221\n",
      "Train Epoch: 7 [5120/30596 (17%)]\tLoss: 0.127952\n",
      "Train Epoch: 7 [5760/30596 (19%)]\tLoss: 0.111388\n",
      "Train Epoch: 7 [6400/30596 (21%)]\tLoss: 0.045654\n",
      "Train Epoch: 7 [7040/30596 (23%)]\tLoss: 0.177969\n",
      "Train Epoch: 7 [7680/30596 (25%)]\tLoss: 0.047769\n",
      "Train Epoch: 7 [8320/30596 (27%)]\tLoss: 0.132889\n",
      "Train Epoch: 7 [8960/30596 (29%)]\tLoss: 0.135777\n",
      "Train Epoch: 7 [9600/30596 (31%)]\tLoss: 0.016744\n",
      "Train Epoch: 7 [10240/30596 (33%)]\tLoss: 0.028757\n",
      "Train Epoch: 7 [10880/30596 (35%)]\tLoss: 0.146573\n",
      "Train Epoch: 7 [11520/30596 (38%)]\tLoss: 0.069782\n",
      "Train Epoch: 7 [12160/30596 (40%)]\tLoss: 0.107984\n",
      "Train Epoch: 7 [12800/30596 (42%)]\tLoss: 0.171001\n",
      "Train Epoch: 7 [13440/30596 (44%)]\tLoss: 0.063728\n",
      "Train Epoch: 7 [14080/30596 (46%)]\tLoss: 0.029703\n",
      "Train Epoch: 7 [14720/30596 (48%)]\tLoss: 0.185569\n",
      "Train Epoch: 7 [15360/30596 (50%)]\tLoss: 0.076817\n",
      "Train Epoch: 7 [16000/30596 (52%)]\tLoss: 0.027372\n",
      "Train Epoch: 7 [16640/30596 (54%)]\tLoss: 0.046622\n",
      "Train Epoch: 7 [17280/30596 (56%)]\tLoss: 0.163207\n",
      "Train Epoch: 7 [17920/30596 (58%)]\tLoss: 0.057623\n",
      "Train Epoch: 7 [18560/30596 (61%)]\tLoss: 0.058212\n",
      "Train Epoch: 7 [19200/30596 (63%)]\tLoss: 0.024363\n",
      "Train Epoch: 7 [19840/30596 (65%)]\tLoss: 0.072964\n",
      "Train Epoch: 7 [20480/30596 (67%)]\tLoss: 0.112444\n",
      "Train Epoch: 7 [21120/30596 (69%)]\tLoss: 0.170665\n",
      "Train Epoch: 7 [21760/30596 (71%)]\tLoss: 0.072911\n",
      "Train Epoch: 7 [22400/30596 (73%)]\tLoss: 0.071631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [23040/30596 (75%)]\tLoss: 0.148550\n",
      "Train Epoch: 7 [23680/30596 (77%)]\tLoss: 0.030178\n",
      "Train Epoch: 7 [24320/30596 (79%)]\tLoss: 0.016463\n",
      "Train Epoch: 7 [24960/30596 (81%)]\tLoss: 0.022412\n",
      "Train Epoch: 7 [25600/30596 (84%)]\tLoss: 0.020551\n",
      "Train Epoch: 7 [26240/30596 (86%)]\tLoss: 0.109369\n",
      "Train Epoch: 7 [26880/30596 (88%)]\tLoss: 0.140623\n",
      "Train Epoch: 7 [27520/30596 (90%)]\tLoss: 0.075738\n",
      "Train Epoch: 7 [28160/30596 (92%)]\tLoss: 0.112684\n",
      "Train Epoch: 7 [28800/30596 (94%)]\tLoss: 0.071483\n",
      "Train Epoch: 7 [29440/30596 (96%)]\tLoss: 0.026024\n",
      "Train Epoch: 7 [30080/30596 (98%)]\tLoss: 0.019757\n",
      "\n",
      "Test set: Avg. loss: 0.0210, Accuracy: 5100/5139 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/30596 (0%)]\tLoss: 0.099283\n",
      "Train Epoch: 8 [640/30596 (2%)]\tLoss: 0.138834\n",
      "Train Epoch: 8 [1280/30596 (4%)]\tLoss: 0.097541\n",
      "Train Epoch: 8 [1920/30596 (6%)]\tLoss: 0.312480\n",
      "Train Epoch: 8 [2560/30596 (8%)]\tLoss: 0.119726\n",
      "Train Epoch: 8 [3200/30596 (10%)]\tLoss: 0.033646\n",
      "Train Epoch: 8 [3840/30596 (13%)]\tLoss: 0.050083\n",
      "Train Epoch: 8 [4480/30596 (15%)]\tLoss: 0.065760\n",
      "Train Epoch: 8 [5120/30596 (17%)]\tLoss: 0.031928\n",
      "Train Epoch: 8 [5760/30596 (19%)]\tLoss: 0.042529\n",
      "Train Epoch: 8 [6400/30596 (21%)]\tLoss: 0.163436\n",
      "Train Epoch: 8 [7040/30596 (23%)]\tLoss: 0.065433\n",
      "Train Epoch: 8 [7680/30596 (25%)]\tLoss: 0.049375\n",
      "Train Epoch: 8 [8320/30596 (27%)]\tLoss: 0.055558\n",
      "Train Epoch: 8 [8960/30596 (29%)]\tLoss: 0.078980\n",
      "Train Epoch: 8 [9600/30596 (31%)]\tLoss: 0.035227\n",
      "Train Epoch: 8 [10240/30596 (33%)]\tLoss: 0.064542\n",
      "Train Epoch: 8 [10880/30596 (35%)]\tLoss: 0.079235\n",
      "Train Epoch: 8 [11520/30596 (38%)]\tLoss: 0.131306\n",
      "Train Epoch: 8 [12160/30596 (40%)]\tLoss: 0.005930\n",
      "Train Epoch: 8 [12800/30596 (42%)]\tLoss: 0.213466\n",
      "Train Epoch: 8 [13440/30596 (44%)]\tLoss: 0.033089\n",
      "Train Epoch: 8 [14080/30596 (46%)]\tLoss: 0.050064\n",
      "Train Epoch: 8 [14720/30596 (48%)]\tLoss: 0.024260\n",
      "Train Epoch: 8 [15360/30596 (50%)]\tLoss: 0.017458\n",
      "Train Epoch: 8 [16000/30596 (52%)]\tLoss: 0.103816\n",
      "Train Epoch: 8 [16640/30596 (54%)]\tLoss: 0.013899\n",
      "Train Epoch: 8 [17280/30596 (56%)]\tLoss: 0.116428\n",
      "Train Epoch: 8 [17920/30596 (58%)]\tLoss: 0.054084\n",
      "Train Epoch: 8 [18560/30596 (61%)]\tLoss: 0.080126\n",
      "Train Epoch: 8 [19200/30596 (63%)]\tLoss: 0.072345\n",
      "Train Epoch: 8 [19840/30596 (65%)]\tLoss: 0.025312\n",
      "Train Epoch: 8 [20480/30596 (67%)]\tLoss: 0.020012\n",
      "Train Epoch: 8 [21120/30596 (69%)]\tLoss: 0.080209\n",
      "Train Epoch: 8 [21760/30596 (71%)]\tLoss: 0.138465\n",
      "Train Epoch: 8 [22400/30596 (73%)]\tLoss: 0.053651\n",
      "Train Epoch: 8 [23040/30596 (75%)]\tLoss: 0.051844\n",
      "Train Epoch: 8 [23680/30596 (77%)]\tLoss: 0.088959\n",
      "Train Epoch: 8 [24320/30596 (79%)]\tLoss: 0.009891\n",
      "Train Epoch: 8 [24960/30596 (81%)]\tLoss: 0.026286\n",
      "Train Epoch: 8 [25600/30596 (84%)]\tLoss: 0.011914\n",
      "Train Epoch: 8 [26240/30596 (86%)]\tLoss: 0.123345\n",
      "Train Epoch: 8 [26880/30596 (88%)]\tLoss: 0.111306\n",
      "Train Epoch: 8 [27520/30596 (90%)]\tLoss: 0.109881\n",
      "Train Epoch: 8 [28160/30596 (92%)]\tLoss: 0.031361\n",
      "Train Epoch: 8 [28800/30596 (94%)]\tLoss: 0.092497\n",
      "Train Epoch: 8 [29440/30596 (96%)]\tLoss: 0.052921\n",
      "Train Epoch: 8 [30080/30596 (98%)]\tLoss: 0.073546\n",
      "\n",
      "Test set: Avg. loss: 0.0158, Accuracy: 5108/5139 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/30596 (0%)]\tLoss: 0.012602\n",
      "Train Epoch: 9 [640/30596 (2%)]\tLoss: 0.040582\n",
      "Train Epoch: 9 [1280/30596 (4%)]\tLoss: 0.014581\n",
      "Train Epoch: 9 [1920/30596 (6%)]\tLoss: 0.013634\n",
      "Train Epoch: 9 [2560/30596 (8%)]\tLoss: 0.097113\n",
      "Train Epoch: 9 [3200/30596 (10%)]\tLoss: 0.211201\n",
      "Train Epoch: 9 [3840/30596 (13%)]\tLoss: 0.103273\n",
      "Train Epoch: 9 [4480/30596 (15%)]\tLoss: 0.104023\n",
      "Train Epoch: 9 [5120/30596 (17%)]\tLoss: 0.088987\n",
      "Train Epoch: 9 [5760/30596 (19%)]\tLoss: 0.043517\n",
      "Train Epoch: 9 [6400/30596 (21%)]\tLoss: 0.077361\n",
      "Train Epoch: 9 [7040/30596 (23%)]\tLoss: 0.032807\n",
      "Train Epoch: 9 [7680/30596 (25%)]\tLoss: 0.119796\n",
      "Train Epoch: 9 [8320/30596 (27%)]\tLoss: 0.028175\n",
      "Train Epoch: 9 [8960/30596 (29%)]\tLoss: 0.467088\n",
      "Train Epoch: 9 [9600/30596 (31%)]\tLoss: 0.025822\n",
      "Train Epoch: 9 [10240/30596 (33%)]\tLoss: 0.110505\n",
      "Train Epoch: 9 [10880/30596 (35%)]\tLoss: 0.080129\n",
      "Train Epoch: 9 [11520/30596 (38%)]\tLoss: 0.040479\n",
      "Train Epoch: 9 [12160/30596 (40%)]\tLoss: 0.036603\n",
      "Train Epoch: 9 [12800/30596 (42%)]\tLoss: 0.065096\n",
      "Train Epoch: 9 [13440/30596 (44%)]\tLoss: 0.047132\n",
      "Train Epoch: 9 [14080/30596 (46%)]\tLoss: 0.094926\n",
      "Train Epoch: 9 [14720/30596 (48%)]\tLoss: 0.042148\n",
      "Train Epoch: 9 [15360/30596 (50%)]\tLoss: 0.100076\n",
      "Train Epoch: 9 [16000/30596 (52%)]\tLoss: 0.078566\n",
      "Train Epoch: 9 [16640/30596 (54%)]\tLoss: 0.022315\n",
      "Train Epoch: 9 [17280/30596 (56%)]\tLoss: 0.063372\n",
      "Train Epoch: 9 [17920/30596 (58%)]\tLoss: 0.020307\n",
      "Train Epoch: 9 [18560/30596 (61%)]\tLoss: 0.037746\n",
      "Train Epoch: 9 [19200/30596 (63%)]\tLoss: 0.016025\n",
      "Train Epoch: 9 [19840/30596 (65%)]\tLoss: 0.044300\n",
      "Train Epoch: 9 [20480/30596 (67%)]\tLoss: 0.071687\n",
      "Train Epoch: 9 [21120/30596 (69%)]\tLoss: 0.035400\n",
      "Train Epoch: 9 [21760/30596 (71%)]\tLoss: 0.145755\n",
      "Train Epoch: 9 [22400/30596 (73%)]\tLoss: 0.018015\n",
      "Train Epoch: 9 [23040/30596 (75%)]\tLoss: 0.049086\n",
      "Train Epoch: 9 [23680/30596 (77%)]\tLoss: 0.039231\n",
      "Train Epoch: 9 [24320/30596 (79%)]\tLoss: 0.103107\n",
      "Train Epoch: 9 [24960/30596 (81%)]\tLoss: 0.017328\n",
      "Train Epoch: 9 [25600/30596 (84%)]\tLoss: 0.023750\n",
      "Train Epoch: 9 [26240/30596 (86%)]\tLoss: 0.044197\n",
      "Train Epoch: 9 [26880/30596 (88%)]\tLoss: 0.045847\n",
      "Train Epoch: 9 [27520/30596 (90%)]\tLoss: 0.089070\n",
      "Train Epoch: 9 [28160/30596 (92%)]\tLoss: 0.099173\n",
      "Train Epoch: 9 [28800/30596 (94%)]\tLoss: 0.070866\n",
      "Train Epoch: 9 [29440/30596 (96%)]\tLoss: 0.072400\n",
      "Train Epoch: 9 [30080/30596 (98%)]\tLoss: 0.025967\n",
      "\n",
      "Test set: Avg. loss: 0.0154, Accuracy: 5111/5139 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/30596 (0%)]\tLoss: 0.105714\n",
      "Train Epoch: 10 [640/30596 (2%)]\tLoss: 0.049394\n",
      "Train Epoch: 10 [1280/30596 (4%)]\tLoss: 0.037601\n",
      "Train Epoch: 10 [1920/30596 (6%)]\tLoss: 0.016576\n",
      "Train Epoch: 10 [2560/30596 (8%)]\tLoss: 0.011128\n",
      "Train Epoch: 10 [3200/30596 (10%)]\tLoss: 0.020415\n",
      "Train Epoch: 10 [3840/30596 (13%)]\tLoss: 0.034317\n",
      "Train Epoch: 10 [4480/30596 (15%)]\tLoss: 0.044336\n",
      "Train Epoch: 10 [5120/30596 (17%)]\tLoss: 0.066062\n",
      "Train Epoch: 10 [5760/30596 (19%)]\tLoss: 0.065808\n",
      "Train Epoch: 10 [6400/30596 (21%)]\tLoss: 0.018589\n",
      "Train Epoch: 10 [7040/30596 (23%)]\tLoss: 0.245379\n",
      "Train Epoch: 10 [7680/30596 (25%)]\tLoss: 0.033357\n",
      "Train Epoch: 10 [8320/30596 (27%)]\tLoss: 0.013369\n",
      "Train Epoch: 10 [8960/30596 (29%)]\tLoss: 0.050188\n",
      "Train Epoch: 10 [9600/30596 (31%)]\tLoss: 0.005644\n",
      "Train Epoch: 10 [10240/30596 (33%)]\tLoss: 0.095327\n",
      "Train Epoch: 10 [10880/30596 (35%)]\tLoss: 0.021695\n",
      "Train Epoch: 10 [11520/30596 (38%)]\tLoss: 0.027904\n",
      "Train Epoch: 10 [12160/30596 (40%)]\tLoss: 0.046029\n",
      "Train Epoch: 10 [12800/30596 (42%)]\tLoss: 0.072524\n",
      "Train Epoch: 10 [13440/30596 (44%)]\tLoss: 0.071996\n",
      "Train Epoch: 10 [14080/30596 (46%)]\tLoss: 0.046824\n",
      "Train Epoch: 10 [14720/30596 (48%)]\tLoss: 0.025748\n",
      "Train Epoch: 10 [15360/30596 (50%)]\tLoss: 0.028218\n",
      "Train Epoch: 10 [16000/30596 (52%)]\tLoss: 0.023430\n",
      "Train Epoch: 10 [16640/30596 (54%)]\tLoss: 0.048311\n",
      "Train Epoch: 10 [17280/30596 (56%)]\tLoss: 0.004840\n",
      "Train Epoch: 10 [17920/30596 (58%)]\tLoss: 0.088242\n",
      "Train Epoch: 10 [18560/30596 (61%)]\tLoss: 0.014929\n",
      "Train Epoch: 10 [19200/30596 (63%)]\tLoss: 0.102706\n",
      "Train Epoch: 10 [19840/30596 (65%)]\tLoss: 0.095100\n",
      "Train Epoch: 10 [20480/30596 (67%)]\tLoss: 0.041726\n",
      "Train Epoch: 10 [21120/30596 (69%)]\tLoss: 0.146808\n",
      "Train Epoch: 10 [21760/30596 (71%)]\tLoss: 0.097694\n",
      "Train Epoch: 10 [22400/30596 (73%)]\tLoss: 0.032606\n",
      "Train Epoch: 10 [23040/30596 (75%)]\tLoss: 0.208248\n",
      "Train Epoch: 10 [23680/30596 (77%)]\tLoss: 0.084383\n",
      "Train Epoch: 10 [24320/30596 (79%)]\tLoss: 0.080343\n",
      "Train Epoch: 10 [24960/30596 (81%)]\tLoss: 0.009702\n",
      "Train Epoch: 10 [25600/30596 (84%)]\tLoss: 0.186214\n",
      "Train Epoch: 10 [26240/30596 (86%)]\tLoss: 0.045976\n",
      "Train Epoch: 10 [26880/30596 (88%)]\tLoss: 0.071715\n",
      "Train Epoch: 10 [27520/30596 (90%)]\tLoss: 0.184132\n",
      "Train Epoch: 10 [28160/30596 (92%)]\tLoss: 0.018305\n",
      "Train Epoch: 10 [28800/30596 (94%)]\tLoss: 0.099712\n",
      "Train Epoch: 10 [29440/30596 (96%)]\tLoss: 0.041990\n",
      "Train Epoch: 10 [30080/30596 (98%)]\tLoss: 0.034673\n",
      "\n",
      "Test set: Avg. loss: 0.0158, Accuracy: 5110/5139 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net_c5 = Net_c5().cuda()\n",
    "n_epochs = 10\n",
    "optimizer = optim.SGD(net_c5.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader5.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "test(net_c5, test_loader5)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net_c5, train_loader5, epoch)\n",
    "    test(net_c5, test_loader5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00708355, 0.        , 0.        , 0.01062532, 0.01062532,\n",
       "        0.01062532, 0.01770887, 0.03541774, 0.03895951, 0.04250128,\n",
       "        0.07083547, 0.05666838, 0.05666838, 0.0672937 , 0.05312661,\n",
       "        0.10271144, 0.11687853, 0.07437725, 0.11687853, 0.18063046,\n",
       "        0.16646336, 0.17000514, 0.18771401, 0.19125578, 0.24438239,\n",
       "        0.2018811 , 0.2018811 , 0.23375706, 0.17354691, 0.23021529,\n",
       "        0.21958997, 0.21958997, 0.2160482 , 0.23375706, 0.19479755,\n",
       "        0.21958997, 0.23729884, 0.19479755, 0.11333676, 0.17708868,\n",
       "        0.18417223, 0.16646336, 0.12396208, 0.12042031, 0.12750385,\n",
       "        0.11333676, 0.09916966, 0.0814608 , 0.09562789, 0.06021015,\n",
       "        0.0814608 , 0.06375193, 0.0672937 , 0.05312661, 0.06375193,\n",
       "        0.04958483, 0.05312661, 0.02479242, 0.02833419, 0.02125064,\n",
       "        0.03895951, 0.03541774, 0.02125064, 0.02479242, 0.01770887,\n",
       "        0.02125064, 0.01062532, 0.00708355, 0.01770887, 0.01416709,\n",
       "        0.01770887, 0.01062532, 0.00708355, 0.01416709, 0.        ,\n",
       "        0.00354177, 0.00708355, 0.00708355, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00354177, 0.00354177, 0.00354177,\n",
       "        0.00354177, 0.        , 0.00354177, 0.        , 0.00354177,\n",
       "        0.        , 0.        , 0.        , 0.00354177, 0.        ,\n",
       "        0.00354177, 0.        , 0.        , 0.        , 0.00354177]),\n",
       " array([ 4.90223319,  5.0434054 ,  5.1845776 ,  5.3257498 ,  5.46692201,\n",
       "         5.60809421,  5.74926642,  5.89043862,  6.03161083,  6.17278303,\n",
       "         6.31395523,  6.45512744,  6.59629964,  6.73747185,  6.87864405,\n",
       "         7.01981626,  7.16098846,  7.30216066,  7.44333287,  7.58450507,\n",
       "         7.72567728,  7.86684948,  8.00802169,  8.14919389,  8.29036609,\n",
       "         8.4315383 ,  8.5727105 ,  8.71388271,  8.85505491,  8.99622712,\n",
       "         9.13739932,  9.27857152,  9.41974373,  9.56091593,  9.70208814,\n",
       "         9.84326034,  9.98443255, 10.12560475, 10.26677696, 10.40794916,\n",
       "        10.54912136, 10.69029357, 10.83146577, 10.97263798, 11.11381018,\n",
       "        11.25498239, 11.39615459, 11.53732679, 11.678499  , 11.8196712 ,\n",
       "        11.96084341, 12.10201561, 12.24318782, 12.38436002, 12.52553222,\n",
       "        12.66670443, 12.80787663, 12.94904884, 13.09022104, 13.23139325,\n",
       "        13.37256545, 13.51373765, 13.65490986, 13.79608206, 13.93725427,\n",
       "        14.07842647, 14.21959868, 14.36077088, 14.50194308, 14.64311529,\n",
       "        14.78428749, 14.9254597 , 15.0666319 , 15.20780411, 15.34897631,\n",
       "        15.49014851, 15.63132072, 15.77249292, 15.91366513, 16.05483733,\n",
       "        16.19600954, 16.33718174, 16.47835394, 16.61952615, 16.76069835,\n",
       "        16.90187056, 17.04304276, 17.18421497, 17.32538717, 17.46655938,\n",
       "        17.60773158, 17.74890378, 17.89007599, 18.03124819, 18.1724204 ,\n",
       "        18.3135926 , 18.45476481, 18.59593701, 18.73710921, 18.87828142,\n",
       "        19.01945362]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = net_c5(noise.cuda())\n",
    "ll = net_c5.last\n",
    "print(ll.shape)\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net1_c5 = LID(ll, ll, k=50)\n",
    "plt.hist(lid_net1_c5, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.61678358585131\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lid_net1_c5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network using 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_c2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_c2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.last = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.6933, Accuracy: 1135/2115 (53%)\n",
      "\n",
      "Train Epoch: 1 [0/12665 (0%)]\tLoss: 0.685686\n",
      "Train Epoch: 1 [640/12665 (5%)]\tLoss: 0.663261\n",
      "Train Epoch: 1 [1280/12665 (10%)]\tLoss: 0.596664\n",
      "Train Epoch: 1 [1920/12665 (15%)]\tLoss: 0.495721\n",
      "Train Epoch: 1 [2560/12665 (20%)]\tLoss: 0.338835\n",
      "Train Epoch: 1 [3200/12665 (25%)]\tLoss: 0.194393\n",
      "Train Epoch: 1 [3840/12665 (30%)]\tLoss: 0.126059\n",
      "Train Epoch: 1 [4480/12665 (35%)]\tLoss: 0.105655\n",
      "Train Epoch: 1 [5120/12665 (40%)]\tLoss: 0.062918\n",
      "Train Epoch: 1 [5760/12665 (45%)]\tLoss: 0.055405\n",
      "Train Epoch: 1 [6400/12665 (51%)]\tLoss: 0.046140\n",
      "Train Epoch: 1 [7040/12665 (56%)]\tLoss: 0.039839\n",
      "Train Epoch: 1 [7680/12665 (61%)]\tLoss: 0.050970\n",
      "Train Epoch: 1 [8320/12665 (66%)]\tLoss: 0.052352\n",
      "Train Epoch: 1 [8960/12665 (71%)]\tLoss: 0.017355\n",
      "Train Epoch: 1 [9600/12665 (76%)]\tLoss: 0.017583\n",
      "Train Epoch: 1 [10240/12665 (81%)]\tLoss: 0.017922\n",
      "Train Epoch: 1 [10880/12665 (86%)]\tLoss: 0.024625\n",
      "Train Epoch: 1 [11520/12665 (91%)]\tLoss: 0.027999\n",
      "Train Epoch: 1 [12160/12665 (96%)]\tLoss: 0.083122\n",
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 2111/2115 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/12665 (0%)]\tLoss: 0.018036\n",
      "Train Epoch: 2 [640/12665 (5%)]\tLoss: 0.023362\n",
      "Train Epoch: 2 [1280/12665 (10%)]\tLoss: 0.007235\n",
      "Train Epoch: 2 [1920/12665 (15%)]\tLoss: 0.040154\n",
      "Train Epoch: 2 [2560/12665 (20%)]\tLoss: 0.003802\n",
      "Train Epoch: 2 [3200/12665 (25%)]\tLoss: 0.008740\n",
      "Train Epoch: 2 [3840/12665 (30%)]\tLoss: 0.011192\n",
      "Train Epoch: 2 [4480/12665 (35%)]\tLoss: 0.017069\n",
      "Train Epoch: 2 [5120/12665 (40%)]\tLoss: 0.092713\n",
      "Train Epoch: 2 [5760/12665 (45%)]\tLoss: 0.092741\n",
      "Train Epoch: 2 [6400/12665 (51%)]\tLoss: 0.004127\n",
      "Train Epoch: 2 [7040/12665 (56%)]\tLoss: 0.018090\n",
      "Train Epoch: 2 [7680/12665 (61%)]\tLoss: 0.035075\n",
      "Train Epoch: 2 [8320/12665 (66%)]\tLoss: 0.016500\n",
      "Train Epoch: 2 [8960/12665 (71%)]\tLoss: 0.018208\n",
      "Train Epoch: 2 [9600/12665 (76%)]\tLoss: 0.032709\n",
      "Train Epoch: 2 [10240/12665 (81%)]\tLoss: 0.009962\n",
      "Train Epoch: 2 [10880/12665 (86%)]\tLoss: 0.004295\n",
      "Train Epoch: 2 [11520/12665 (91%)]\tLoss: 0.012506\n",
      "Train Epoch: 2 [12160/12665 (96%)]\tLoss: 0.019842\n",
      "\n",
      "Test set: Avg. loss: 0.0038, Accuracy: 2111/2115 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/12665 (0%)]\tLoss: 0.005918\n",
      "Train Epoch: 3 [640/12665 (5%)]\tLoss: 0.016147\n",
      "Train Epoch: 3 [1280/12665 (10%)]\tLoss: 0.004632\n",
      "Train Epoch: 3 [1920/12665 (15%)]\tLoss: 0.058875\n",
      "Train Epoch: 3 [2560/12665 (20%)]\tLoss: 0.004886\n",
      "Train Epoch: 3 [3200/12665 (25%)]\tLoss: 0.004275\n",
      "Train Epoch: 3 [3840/12665 (30%)]\tLoss: 0.010522\n",
      "Train Epoch: 3 [4480/12665 (35%)]\tLoss: 0.001189\n",
      "Train Epoch: 3 [5120/12665 (40%)]\tLoss: 0.012698\n",
      "Train Epoch: 3 [5760/12665 (45%)]\tLoss: 0.002301\n",
      "Train Epoch: 3 [6400/12665 (51%)]\tLoss: 0.022944\n",
      "Train Epoch: 3 [7040/12665 (56%)]\tLoss: 0.015117\n",
      "Train Epoch: 3 [7680/12665 (61%)]\tLoss: 0.013378\n",
      "Train Epoch: 3 [8320/12665 (66%)]\tLoss: 0.058506\n",
      "Train Epoch: 3 [8960/12665 (71%)]\tLoss: 0.016846\n",
      "Train Epoch: 3 [9600/12665 (76%)]\tLoss: 0.016215\n",
      "Train Epoch: 3 [10240/12665 (81%)]\tLoss: 0.031658\n",
      "Train Epoch: 3 [10880/12665 (86%)]\tLoss: 0.007662\n",
      "Train Epoch: 3 [11520/12665 (91%)]\tLoss: 0.006361\n",
      "Train Epoch: 3 [12160/12665 (96%)]\tLoss: 0.008462\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/12665 (0%)]\tLoss: 0.015596\n",
      "Train Epoch: 4 [640/12665 (5%)]\tLoss: 0.023211\n",
      "Train Epoch: 4 [1280/12665 (10%)]\tLoss: 0.008734\n",
      "Train Epoch: 4 [1920/12665 (15%)]\tLoss: 0.002739\n",
      "Train Epoch: 4 [2560/12665 (20%)]\tLoss: 0.001089\n",
      "Train Epoch: 4 [3200/12665 (25%)]\tLoss: 0.004205\n",
      "Train Epoch: 4 [3840/12665 (30%)]\tLoss: 0.002518\n",
      "Train Epoch: 4 [4480/12665 (35%)]\tLoss: 0.020237\n",
      "Train Epoch: 4 [5120/12665 (40%)]\tLoss: 0.004238\n",
      "Train Epoch: 4 [5760/12665 (45%)]\tLoss: 0.006066\n",
      "Train Epoch: 4 [6400/12665 (51%)]\tLoss: 0.000451\n",
      "Train Epoch: 4 [7040/12665 (56%)]\tLoss: 0.008797\n",
      "Train Epoch: 4 [7680/12665 (61%)]\tLoss: 0.007716\n",
      "Train Epoch: 4 [8320/12665 (66%)]\tLoss: 0.002735\n",
      "Train Epoch: 4 [8960/12665 (71%)]\tLoss: 0.022972\n",
      "Train Epoch: 4 [9600/12665 (76%)]\tLoss: 0.003409\n",
      "Train Epoch: 4 [10240/12665 (81%)]\tLoss: 0.045800\n",
      "Train Epoch: 4 [10880/12665 (86%)]\tLoss: 0.000676\n",
      "Train Epoch: 4 [11520/12665 (91%)]\tLoss: 0.002232\n",
      "Train Epoch: 4 [12160/12665 (96%)]\tLoss: 0.012719\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/12665 (0%)]\tLoss: 0.005491\n",
      "Train Epoch: 5 [640/12665 (5%)]\tLoss: 0.013141\n",
      "Train Epoch: 5 [1280/12665 (10%)]\tLoss: 0.007550\n",
      "Train Epoch: 5 [1920/12665 (15%)]\tLoss: 0.005342\n",
      "Train Epoch: 5 [2560/12665 (20%)]\tLoss: 0.003461\n",
      "Train Epoch: 5 [3200/12665 (25%)]\tLoss: 0.009165\n",
      "Train Epoch: 5 [3840/12665 (30%)]\tLoss: 0.001379\n",
      "Train Epoch: 5 [4480/12665 (35%)]\tLoss: 0.013568\n",
      "Train Epoch: 5 [5120/12665 (40%)]\tLoss: 0.008202\n",
      "Train Epoch: 5 [5760/12665 (45%)]\tLoss: 0.003020\n",
      "Train Epoch: 5 [6400/12665 (51%)]\tLoss: 0.078803\n",
      "Train Epoch: 5 [7040/12665 (56%)]\tLoss: 0.005396\n",
      "Train Epoch: 5 [7680/12665 (61%)]\tLoss: 0.001857\n",
      "Train Epoch: 5 [8320/12665 (66%)]\tLoss: 0.011490\n",
      "Train Epoch: 5 [8960/12665 (71%)]\tLoss: 0.001605\n",
      "Train Epoch: 5 [9600/12665 (76%)]\tLoss: 0.043834\n",
      "Train Epoch: 5 [10240/12665 (81%)]\tLoss: 0.003372\n",
      "Train Epoch: 5 [10880/12665 (86%)]\tLoss: 0.038235\n",
      "Train Epoch: 5 [11520/12665 (91%)]\tLoss: 0.105588\n",
      "Train Epoch: 5 [12160/12665 (96%)]\tLoss: 0.005530\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/12665 (0%)]\tLoss: 0.013278\n",
      "Train Epoch: 6 [640/12665 (5%)]\tLoss: 0.001072\n",
      "Train Epoch: 6 [1280/12665 (10%)]\tLoss: 0.002728\n",
      "Train Epoch: 6 [1920/12665 (15%)]\tLoss: 0.010227\n",
      "Train Epoch: 6 [2560/12665 (20%)]\tLoss: 0.009469\n",
      "Train Epoch: 6 [3200/12665 (25%)]\tLoss: 0.005256\n",
      "Train Epoch: 6 [3840/12665 (30%)]\tLoss: 0.004162\n",
      "Train Epoch: 6 [4480/12665 (35%)]\tLoss: 0.004565\n",
      "Train Epoch: 6 [5120/12665 (40%)]\tLoss: 0.003130\n",
      "Train Epoch: 6 [5760/12665 (45%)]\tLoss: 0.000558\n",
      "Train Epoch: 6 [6400/12665 (51%)]\tLoss: 0.000319\n",
      "Train Epoch: 6 [7040/12665 (56%)]\tLoss: 0.000208\n",
      "Train Epoch: 6 [7680/12665 (61%)]\tLoss: 0.003021\n",
      "Train Epoch: 6 [8320/12665 (66%)]\tLoss: 0.000428\n",
      "Train Epoch: 6 [8960/12665 (71%)]\tLoss: 0.002362\n",
      "Train Epoch: 6 [9600/12665 (76%)]\tLoss: 0.002163\n",
      "Train Epoch: 6 [10240/12665 (81%)]\tLoss: 0.001594\n",
      "Train Epoch: 6 [10880/12665 (86%)]\tLoss: 0.003119\n",
      "Train Epoch: 6 [11520/12665 (91%)]\tLoss: 0.014001\n",
      "Train Epoch: 6 [12160/12665 (96%)]\tLoss: 0.001354\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/12665 (0%)]\tLoss: 0.007812\n",
      "Train Epoch: 7 [640/12665 (5%)]\tLoss: 0.000451\n",
      "Train Epoch: 7 [1280/12665 (10%)]\tLoss: 0.003283\n",
      "Train Epoch: 7 [1920/12665 (15%)]\tLoss: 0.002234\n",
      "Train Epoch: 7 [2560/12665 (20%)]\tLoss: 0.000472\n",
      "Train Epoch: 7 [3200/12665 (25%)]\tLoss: 0.003885\n",
      "Train Epoch: 7 [3840/12665 (30%)]\tLoss: 0.003666\n",
      "Train Epoch: 7 [4480/12665 (35%)]\tLoss: 0.000876\n",
      "Train Epoch: 7 [5120/12665 (40%)]\tLoss: 0.004592\n",
      "Train Epoch: 7 [5760/12665 (45%)]\tLoss: 0.005623\n",
      "Train Epoch: 7 [6400/12665 (51%)]\tLoss: 0.000877\n",
      "Train Epoch: 7 [7040/12665 (56%)]\tLoss: 0.001890\n",
      "Train Epoch: 7 [7680/12665 (61%)]\tLoss: 0.020251\n",
      "Train Epoch: 7 [8320/12665 (66%)]\tLoss: 0.015682\n",
      "Train Epoch: 7 [8960/12665 (71%)]\tLoss: 0.011732\n",
      "Train Epoch: 7 [9600/12665 (76%)]\tLoss: 0.007683\n",
      "Train Epoch: 7 [10240/12665 (81%)]\tLoss: 0.000424\n",
      "Train Epoch: 7 [10880/12665 (86%)]\tLoss: 0.002005\n",
      "Train Epoch: 7 [11520/12665 (91%)]\tLoss: 0.001835\n",
      "Train Epoch: 7 [12160/12665 (96%)]\tLoss: 0.001630\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/12665 (0%)]\tLoss: 0.005882\n",
      "Train Epoch: 8 [640/12665 (5%)]\tLoss: 0.126719\n",
      "Train Epoch: 8 [1280/12665 (10%)]\tLoss: 0.001699\n",
      "Train Epoch: 8 [1920/12665 (15%)]\tLoss: 0.092068\n",
      "Train Epoch: 8 [2560/12665 (20%)]\tLoss: 0.061371\n",
      "Train Epoch: 8 [3200/12665 (25%)]\tLoss: 0.006092\n",
      "Train Epoch: 8 [3840/12665 (30%)]\tLoss: 0.001436\n",
      "Train Epoch: 8 [4480/12665 (35%)]\tLoss: 0.005368\n",
      "Train Epoch: 8 [5120/12665 (40%)]\tLoss: 0.021030\n",
      "Train Epoch: 8 [5760/12665 (45%)]\tLoss: 0.001427\n",
      "Train Epoch: 8 [6400/12665 (51%)]\tLoss: 0.085869\n",
      "Train Epoch: 8 [7040/12665 (56%)]\tLoss: 0.002857\n",
      "Train Epoch: 8 [7680/12665 (61%)]\tLoss: 0.000085\n",
      "Train Epoch: 8 [8320/12665 (66%)]\tLoss: 0.001988\n",
      "Train Epoch: 8 [8960/12665 (71%)]\tLoss: 0.004373\n",
      "Train Epoch: 8 [9600/12665 (76%)]\tLoss: 0.004738\n",
      "Train Epoch: 8 [10240/12665 (81%)]\tLoss: 0.006302\n",
      "Train Epoch: 8 [10880/12665 (86%)]\tLoss: 0.007151\n",
      "Train Epoch: 8 [11520/12665 (91%)]\tLoss: 0.013699\n",
      "Train Epoch: 8 [12160/12665 (96%)]\tLoss: 0.012620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/12665 (0%)]\tLoss: 0.004618\n",
      "Train Epoch: 9 [640/12665 (5%)]\tLoss: 0.004156\n",
      "Train Epoch: 9 [1280/12665 (10%)]\tLoss: 0.001954\n",
      "Train Epoch: 9 [1920/12665 (15%)]\tLoss: 0.006490\n",
      "Train Epoch: 9 [2560/12665 (20%)]\tLoss: 0.000560\n",
      "Train Epoch: 9 [3200/12665 (25%)]\tLoss: 0.005093\n",
      "Train Epoch: 9 [3840/12665 (30%)]\tLoss: 0.002231\n",
      "Train Epoch: 9 [4480/12665 (35%)]\tLoss: 0.006715\n",
      "Train Epoch: 9 [5120/12665 (40%)]\tLoss: 0.000738\n",
      "Train Epoch: 9 [5760/12665 (45%)]\tLoss: 0.000499\n",
      "Train Epoch: 9 [6400/12665 (51%)]\tLoss: 0.000617\n",
      "Train Epoch: 9 [7040/12665 (56%)]\tLoss: 0.004566\n",
      "Train Epoch: 9 [7680/12665 (61%)]\tLoss: 0.001347\n",
      "Train Epoch: 9 [8320/12665 (66%)]\tLoss: 0.002721\n",
      "Train Epoch: 9 [8960/12665 (71%)]\tLoss: 0.001050\n",
      "Train Epoch: 9 [9600/12665 (76%)]\tLoss: 0.003005\n",
      "Train Epoch: 9 [10240/12665 (81%)]\tLoss: 0.008370\n",
      "Train Epoch: 9 [10880/12665 (86%)]\tLoss: 0.004661\n",
      "Train Epoch: 9 [11520/12665 (91%)]\tLoss: 0.010927\n",
      "Train Epoch: 9 [12160/12665 (96%)]\tLoss: 0.001081\n",
      "\n",
      "Test set: Avg. loss: 0.0036, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/12665 (0%)]\tLoss: 0.005569\n",
      "Train Epoch: 10 [640/12665 (5%)]\tLoss: 0.001710\n",
      "Train Epoch: 10 [1280/12665 (10%)]\tLoss: 0.001659\n",
      "Train Epoch: 10 [1920/12665 (15%)]\tLoss: 0.001239\n",
      "Train Epoch: 10 [2560/12665 (20%)]\tLoss: 0.005487\n",
      "Train Epoch: 10 [3200/12665 (25%)]\tLoss: 0.015738\n",
      "Train Epoch: 10 [3840/12665 (30%)]\tLoss: 0.067233\n",
      "Train Epoch: 10 [4480/12665 (35%)]\tLoss: 0.003078\n",
      "Train Epoch: 10 [5120/12665 (40%)]\tLoss: 0.000409\n",
      "Train Epoch: 10 [5760/12665 (45%)]\tLoss: 0.003148\n",
      "Train Epoch: 10 [6400/12665 (51%)]\tLoss: 0.003630\n",
      "Train Epoch: 10 [7040/12665 (56%)]\tLoss: 0.004513\n",
      "Train Epoch: 10 [7680/12665 (61%)]\tLoss: 0.005949\n",
      "Train Epoch: 10 [8320/12665 (66%)]\tLoss: 0.004721\n",
      "Train Epoch: 10 [8960/12665 (71%)]\tLoss: 0.003489\n",
      "Train Epoch: 10 [9600/12665 (76%)]\tLoss: 0.018947\n",
      "Train Epoch: 10 [10240/12665 (81%)]\tLoss: 0.000671\n",
      "Train Epoch: 10 [10880/12665 (86%)]\tLoss: 0.000460\n",
      "Train Epoch: 10 [11520/12665 (91%)]\tLoss: 0.001166\n",
      "Train Epoch: 10 [12160/12665 (96%)]\tLoss: 0.003644\n",
      "\n",
      "Test set: Avg. loss: 0.0038, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/12665 (0%)]\tLoss: 0.000807\n",
      "Train Epoch: 11 [640/12665 (5%)]\tLoss: 0.001376\n",
      "Train Epoch: 11 [1280/12665 (10%)]\tLoss: 0.000398\n",
      "Train Epoch: 11 [1920/12665 (15%)]\tLoss: 0.001260\n",
      "Train Epoch: 11 [2560/12665 (20%)]\tLoss: 0.004591\n",
      "Train Epoch: 11 [3200/12665 (25%)]\tLoss: 0.000094\n",
      "Train Epoch: 11 [3840/12665 (30%)]\tLoss: 0.007452\n",
      "Train Epoch: 11 [4480/12665 (35%)]\tLoss: 0.000394\n",
      "Train Epoch: 11 [5120/12665 (40%)]\tLoss: 0.000982\n",
      "Train Epoch: 11 [5760/12665 (45%)]\tLoss: 0.000288\n",
      "Train Epoch: 11 [6400/12665 (51%)]\tLoss: 0.022093\n",
      "Train Epoch: 11 [7040/12665 (56%)]\tLoss: 0.001324\n",
      "Train Epoch: 11 [7680/12665 (61%)]\tLoss: 0.000287\n",
      "Train Epoch: 11 [8320/12665 (66%)]\tLoss: 0.003857\n",
      "Train Epoch: 11 [8960/12665 (71%)]\tLoss: 0.004491\n",
      "Train Epoch: 11 [9600/12665 (76%)]\tLoss: 0.003336\n",
      "Train Epoch: 11 [10240/12665 (81%)]\tLoss: 0.000053\n",
      "Train Epoch: 11 [10880/12665 (86%)]\tLoss: 0.001285\n",
      "Train Epoch: 11 [11520/12665 (91%)]\tLoss: 0.004097\n",
      "Train Epoch: 11 [12160/12665 (96%)]\tLoss: 0.001626\n",
      "\n",
      "Test set: Avg. loss: 0.0029, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/12665 (0%)]\tLoss: 0.000773\n",
      "Train Epoch: 12 [640/12665 (5%)]\tLoss: 0.000164\n",
      "Train Epoch: 12 [1280/12665 (10%)]\tLoss: 0.038953\n",
      "Train Epoch: 12 [1920/12665 (15%)]\tLoss: 0.017097\n",
      "Train Epoch: 12 [2560/12665 (20%)]\tLoss: 0.001274\n",
      "Train Epoch: 12 [3200/12665 (25%)]\tLoss: 0.001041\n",
      "Train Epoch: 12 [3840/12665 (30%)]\tLoss: 0.000653\n",
      "Train Epoch: 12 [4480/12665 (35%)]\tLoss: 0.000415\n",
      "Train Epoch: 12 [5120/12665 (40%)]\tLoss: 0.000126\n",
      "Train Epoch: 12 [5760/12665 (45%)]\tLoss: 0.002116\n",
      "Train Epoch: 12 [6400/12665 (51%)]\tLoss: 0.036743\n",
      "Train Epoch: 12 [7040/12665 (56%)]\tLoss: 0.004861\n",
      "Train Epoch: 12 [7680/12665 (61%)]\tLoss: 0.000899\n",
      "Train Epoch: 12 [8320/12665 (66%)]\tLoss: 0.013260\n",
      "Train Epoch: 12 [8960/12665 (71%)]\tLoss: 0.000256\n",
      "Train Epoch: 12 [9600/12665 (76%)]\tLoss: 0.001851\n",
      "Train Epoch: 12 [10240/12665 (81%)]\tLoss: 0.004078\n",
      "Train Epoch: 12 [10880/12665 (86%)]\tLoss: 0.001134\n",
      "Train Epoch: 12 [11520/12665 (91%)]\tLoss: 0.001054\n",
      "Train Epoch: 12 [12160/12665 (96%)]\tLoss: 0.000518\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/12665 (0%)]\tLoss: 0.001476\n",
      "Train Epoch: 13 [640/12665 (5%)]\tLoss: 0.001020\n",
      "Train Epoch: 13 [1280/12665 (10%)]\tLoss: 0.000386\n",
      "Train Epoch: 13 [1920/12665 (15%)]\tLoss: 0.002119\n",
      "Train Epoch: 13 [2560/12665 (20%)]\tLoss: 0.010169\n",
      "Train Epoch: 13 [3200/12665 (25%)]\tLoss: 0.001069\n",
      "Train Epoch: 13 [3840/12665 (30%)]\tLoss: 0.001677\n",
      "Train Epoch: 13 [4480/12665 (35%)]\tLoss: 0.001479\n",
      "Train Epoch: 13 [5120/12665 (40%)]\tLoss: 0.000764\n",
      "Train Epoch: 13 [5760/12665 (45%)]\tLoss: 0.002707\n",
      "Train Epoch: 13 [6400/12665 (51%)]\tLoss: 0.000027\n",
      "Train Epoch: 13 [7040/12665 (56%)]\tLoss: 0.000667\n",
      "Train Epoch: 13 [7680/12665 (61%)]\tLoss: 0.022733\n",
      "Train Epoch: 13 [8320/12665 (66%)]\tLoss: 0.000858\n",
      "Train Epoch: 13 [8960/12665 (71%)]\tLoss: 0.002594\n",
      "Train Epoch: 13 [9600/12665 (76%)]\tLoss: 0.000067\n",
      "Train Epoch: 13 [10240/12665 (81%)]\tLoss: 0.005332\n",
      "Train Epoch: 13 [10880/12665 (86%)]\tLoss: 0.003053\n",
      "Train Epoch: 13 [11520/12665 (91%)]\tLoss: 0.001260\n",
      "Train Epoch: 13 [12160/12665 (96%)]\tLoss: 0.000243\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/12665 (0%)]\tLoss: 0.000971\n",
      "Train Epoch: 14 [640/12665 (5%)]\tLoss: 0.003903\n",
      "Train Epoch: 14 [1280/12665 (10%)]\tLoss: 0.005334\n",
      "Train Epoch: 14 [1920/12665 (15%)]\tLoss: 0.000389\n",
      "Train Epoch: 14 [2560/12665 (20%)]\tLoss: 0.001453\n",
      "Train Epoch: 14 [3200/12665 (25%)]\tLoss: 0.009410\n",
      "Train Epoch: 14 [3840/12665 (30%)]\tLoss: 0.043377\n",
      "Train Epoch: 14 [4480/12665 (35%)]\tLoss: 0.000731\n",
      "Train Epoch: 14 [5120/12665 (40%)]\tLoss: 0.000141\n",
      "Train Epoch: 14 [5760/12665 (45%)]\tLoss: 0.000510\n",
      "Train Epoch: 14 [6400/12665 (51%)]\tLoss: 0.000186\n",
      "Train Epoch: 14 [7040/12665 (56%)]\tLoss: 0.001045\n",
      "Train Epoch: 14 [7680/12665 (61%)]\tLoss: 0.007084\n",
      "Train Epoch: 14 [8320/12665 (66%)]\tLoss: 0.000562\n",
      "Train Epoch: 14 [8960/12665 (71%)]\tLoss: 0.000365\n",
      "Train Epoch: 14 [9600/12665 (76%)]\tLoss: 0.004442\n",
      "Train Epoch: 14 [10240/12665 (81%)]\tLoss: 0.000284\n",
      "Train Epoch: 14 [10880/12665 (86%)]\tLoss: 0.000503\n",
      "Train Epoch: 14 [11520/12665 (91%)]\tLoss: 0.006958\n",
      "Train Epoch: 14 [12160/12665 (96%)]\tLoss: 0.000181\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/12665 (0%)]\tLoss: 0.001136\n",
      "Train Epoch: 15 [640/12665 (5%)]\tLoss: 0.000740\n",
      "Train Epoch: 15 [1280/12665 (10%)]\tLoss: 0.001691\n",
      "Train Epoch: 15 [1920/12665 (15%)]\tLoss: 0.002102\n",
      "Train Epoch: 15 [2560/12665 (20%)]\tLoss: 0.001094\n",
      "Train Epoch: 15 [3200/12665 (25%)]\tLoss: 0.001777\n",
      "Train Epoch: 15 [3840/12665 (30%)]\tLoss: 0.002249\n",
      "Train Epoch: 15 [4480/12665 (35%)]\tLoss: 0.005860\n",
      "Train Epoch: 15 [5120/12665 (40%)]\tLoss: 0.000683\n",
      "Train Epoch: 15 [5760/12665 (45%)]\tLoss: 0.002629\n",
      "Train Epoch: 15 [6400/12665 (51%)]\tLoss: 0.002892\n",
      "Train Epoch: 15 [7040/12665 (56%)]\tLoss: 0.004270\n",
      "Train Epoch: 15 [7680/12665 (61%)]\tLoss: 0.035723\n",
      "Train Epoch: 15 [8320/12665 (66%)]\tLoss: 0.001099\n",
      "Train Epoch: 15 [8960/12665 (71%)]\tLoss: 0.000399\n",
      "Train Epoch: 15 [9600/12665 (76%)]\tLoss: 0.001068\n",
      "Train Epoch: 15 [10240/12665 (81%)]\tLoss: 0.000080\n",
      "Train Epoch: 15 [10880/12665 (86%)]\tLoss: 0.000246\n",
      "Train Epoch: 15 [11520/12665 (91%)]\tLoss: 0.000435\n",
      "Train Epoch: 15 [12160/12665 (96%)]\tLoss: 0.002774\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/12665 (0%)]\tLoss: 0.007691\n",
      "Train Epoch: 16 [640/12665 (5%)]\tLoss: 0.001566\n",
      "Train Epoch: 16 [1280/12665 (10%)]\tLoss: 0.000021\n",
      "Train Epoch: 16 [1920/12665 (15%)]\tLoss: 0.000781\n",
      "Train Epoch: 16 [2560/12665 (20%)]\tLoss: 0.000086\n",
      "Train Epoch: 16 [3200/12665 (25%)]\tLoss: 0.000084\n",
      "Train Epoch: 16 [3840/12665 (30%)]\tLoss: 0.000265\n",
      "Train Epoch: 16 [4480/12665 (35%)]\tLoss: 0.001201\n",
      "Train Epoch: 16 [5120/12665 (40%)]\tLoss: 0.000955\n",
      "Train Epoch: 16 [5760/12665 (45%)]\tLoss: 0.006739\n",
      "Train Epoch: 16 [6400/12665 (51%)]\tLoss: 0.000552\n",
      "Train Epoch: 16 [7040/12665 (56%)]\tLoss: 0.003686\n",
      "Train Epoch: 16 [7680/12665 (61%)]\tLoss: 0.010784\n",
      "Train Epoch: 16 [8320/12665 (66%)]\tLoss: 0.001816\n",
      "Train Epoch: 16 [8960/12665 (71%)]\tLoss: 0.004284\n",
      "Train Epoch: 16 [9600/12665 (76%)]\tLoss: 0.003821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [10240/12665 (81%)]\tLoss: 0.000214\n",
      "Train Epoch: 16 [10880/12665 (86%)]\tLoss: 0.000952\n",
      "Train Epoch: 16 [11520/12665 (91%)]\tLoss: 0.002269\n",
      "Train Epoch: 16 [12160/12665 (96%)]\tLoss: 0.001974\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/12665 (0%)]\tLoss: 0.001558\n",
      "Train Epoch: 17 [640/12665 (5%)]\tLoss: 0.000827\n",
      "Train Epoch: 17 [1280/12665 (10%)]\tLoss: 0.000195\n",
      "Train Epoch: 17 [1920/12665 (15%)]\tLoss: 0.000710\n",
      "Train Epoch: 17 [2560/12665 (20%)]\tLoss: 0.002552\n",
      "Train Epoch: 17 [3200/12665 (25%)]\tLoss: 0.000265\n",
      "Train Epoch: 17 [3840/12665 (30%)]\tLoss: 0.000798\n",
      "Train Epoch: 17 [4480/12665 (35%)]\tLoss: 0.000539\n",
      "Train Epoch: 17 [5120/12665 (40%)]\tLoss: 0.021029\n",
      "Train Epoch: 17 [5760/12665 (45%)]\tLoss: 0.003806\n",
      "Train Epoch: 17 [6400/12665 (51%)]\tLoss: 0.004040\n",
      "Train Epoch: 17 [7040/12665 (56%)]\tLoss: 0.000716\n",
      "Train Epoch: 17 [7680/12665 (61%)]\tLoss: 0.000605\n",
      "Train Epoch: 17 [8320/12665 (66%)]\tLoss: 0.003625\n",
      "Train Epoch: 17 [8960/12665 (71%)]\tLoss: 0.000816\n",
      "Train Epoch: 17 [9600/12665 (76%)]\tLoss: 0.000157\n",
      "Train Epoch: 17 [10240/12665 (81%)]\tLoss: 0.000377\n",
      "Train Epoch: 17 [10880/12665 (86%)]\tLoss: 0.003852\n",
      "Train Epoch: 17 [11520/12665 (91%)]\tLoss: 0.131872\n",
      "Train Epoch: 17 [12160/12665 (96%)]\tLoss: 0.000758\n",
      "\n",
      "Test set: Avg. loss: 0.0031, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/12665 (0%)]\tLoss: 0.000821\n",
      "Train Epoch: 18 [640/12665 (5%)]\tLoss: 0.002412\n",
      "Train Epoch: 18 [1280/12665 (10%)]\tLoss: 0.000395\n",
      "Train Epoch: 18 [1920/12665 (15%)]\tLoss: 0.003959\n",
      "Train Epoch: 18 [2560/12665 (20%)]\tLoss: 0.002579\n",
      "Train Epoch: 18 [3200/12665 (25%)]\tLoss: 0.000200\n",
      "Train Epoch: 18 [3840/12665 (30%)]\tLoss: 0.002044\n",
      "Train Epoch: 18 [4480/12665 (35%)]\tLoss: 0.000161\n",
      "Train Epoch: 18 [5120/12665 (40%)]\tLoss: 0.005536\n",
      "Train Epoch: 18 [5760/12665 (45%)]\tLoss: 0.003076\n",
      "Train Epoch: 18 [6400/12665 (51%)]\tLoss: 0.000241\n",
      "Train Epoch: 18 [7040/12665 (56%)]\tLoss: 0.000283\n",
      "Train Epoch: 18 [7680/12665 (61%)]\tLoss: 0.003911\n",
      "Train Epoch: 18 [8320/12665 (66%)]\tLoss: 0.004683\n",
      "Train Epoch: 18 [8960/12665 (71%)]\tLoss: 0.001832\n",
      "Train Epoch: 18 [9600/12665 (76%)]\tLoss: 0.009252\n",
      "Train Epoch: 18 [10240/12665 (81%)]\tLoss: 0.001179\n",
      "Train Epoch: 18 [10880/12665 (86%)]\tLoss: 0.000404\n",
      "Train Epoch: 18 [11520/12665 (91%)]\tLoss: 0.007943\n",
      "Train Epoch: 18 [12160/12665 (96%)]\tLoss: 0.000576\n",
      "\n",
      "Test set: Avg. loss: 0.0033, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/12665 (0%)]\tLoss: 0.000384\n",
      "Train Epoch: 19 [640/12665 (5%)]\tLoss: 0.001214\n",
      "Train Epoch: 19 [1280/12665 (10%)]\tLoss: 0.007525\n",
      "Train Epoch: 19 [1920/12665 (15%)]\tLoss: 0.001091\n",
      "Train Epoch: 19 [2560/12665 (20%)]\tLoss: 0.000108\n",
      "Train Epoch: 19 [3200/12665 (25%)]\tLoss: 0.000161\n",
      "Train Epoch: 19 [3840/12665 (30%)]\tLoss: 0.001610\n",
      "Train Epoch: 19 [4480/12665 (35%)]\tLoss: 0.003342\n",
      "Train Epoch: 19 [5120/12665 (40%)]\tLoss: 0.000697\n",
      "Train Epoch: 19 [5760/12665 (45%)]\tLoss: 0.004901\n",
      "Train Epoch: 19 [6400/12665 (51%)]\tLoss: 0.004580\n",
      "Train Epoch: 19 [7040/12665 (56%)]\tLoss: 0.000062\n",
      "Train Epoch: 19 [7680/12665 (61%)]\tLoss: 0.001802\n",
      "Train Epoch: 19 [8320/12665 (66%)]\tLoss: 0.000414\n",
      "Train Epoch: 19 [8960/12665 (71%)]\tLoss: 0.000294\n",
      "Train Epoch: 19 [9600/12665 (76%)]\tLoss: 0.000444\n",
      "Train Epoch: 19 [10240/12665 (81%)]\tLoss: 0.000324\n",
      "Train Epoch: 19 [10880/12665 (86%)]\tLoss: 0.000067\n",
      "Train Epoch: 19 [11520/12665 (91%)]\tLoss: 0.001619\n",
      "Train Epoch: 19 [12160/12665 (96%)]\tLoss: 0.001201\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/12665 (0%)]\tLoss: 0.000922\n",
      "Train Epoch: 20 [640/12665 (5%)]\tLoss: 0.000430\n",
      "Train Epoch: 20 [1280/12665 (10%)]\tLoss: 0.001002\n",
      "Train Epoch: 20 [1920/12665 (15%)]\tLoss: 0.000167\n",
      "Train Epoch: 20 [2560/12665 (20%)]\tLoss: 0.000637\n",
      "Train Epoch: 20 [3200/12665 (25%)]\tLoss: 0.000015\n",
      "Train Epoch: 20 [3840/12665 (30%)]\tLoss: 0.056581\n",
      "Train Epoch: 20 [4480/12665 (35%)]\tLoss: 0.000251\n",
      "Train Epoch: 20 [5120/12665 (40%)]\tLoss: 0.005010\n",
      "Train Epoch: 20 [5760/12665 (45%)]\tLoss: 0.000240\n",
      "Train Epoch: 20 [6400/12665 (51%)]\tLoss: 0.002701\n",
      "Train Epoch: 20 [7040/12665 (56%)]\tLoss: 0.003467\n",
      "Train Epoch: 20 [7680/12665 (61%)]\tLoss: 0.002502\n",
      "Train Epoch: 20 [8320/12665 (66%)]\tLoss: 0.000256\n",
      "Train Epoch: 20 [8960/12665 (71%)]\tLoss: 0.001873\n",
      "Train Epoch: 20 [9600/12665 (76%)]\tLoss: 0.000215\n",
      "Train Epoch: 20 [10240/12665 (81%)]\tLoss: 0.000258\n",
      "Train Epoch: 20 [10880/12665 (86%)]\tLoss: 0.000085\n",
      "Train Epoch: 20 [11520/12665 (91%)]\tLoss: 0.000719\n",
      "Train Epoch: 20 [12160/12665 (96%)]\tLoss: 0.000215\n",
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/12665 (0%)]\tLoss: 0.001450\n",
      "Train Epoch: 21 [640/12665 (5%)]\tLoss: 0.000607\n",
      "Train Epoch: 21 [1280/12665 (10%)]\tLoss: 0.012898\n",
      "Train Epoch: 21 [1920/12665 (15%)]\tLoss: 0.023293\n",
      "Train Epoch: 21 [2560/12665 (20%)]\tLoss: 0.004476\n",
      "Train Epoch: 21 [3200/12665 (25%)]\tLoss: 0.000661\n",
      "Train Epoch: 21 [3840/12665 (30%)]\tLoss: 0.000620\n",
      "Train Epoch: 21 [4480/12665 (35%)]\tLoss: 0.001568\n",
      "Train Epoch: 21 [5120/12665 (40%)]\tLoss: 0.000445\n",
      "Train Epoch: 21 [5760/12665 (45%)]\tLoss: 0.001072\n",
      "Train Epoch: 21 [6400/12665 (51%)]\tLoss: 0.000333\n",
      "Train Epoch: 21 [7040/12665 (56%)]\tLoss: 0.001466\n",
      "Train Epoch: 21 [7680/12665 (61%)]\tLoss: 0.001793\n",
      "Train Epoch: 21 [8320/12665 (66%)]\tLoss: 0.000054\n",
      "Train Epoch: 21 [8960/12665 (71%)]\tLoss: 0.000675\n",
      "Train Epoch: 21 [9600/12665 (76%)]\tLoss: 0.000065\n",
      "Train Epoch: 21 [10240/12665 (81%)]\tLoss: 0.000209\n",
      "Train Epoch: 21 [10880/12665 (86%)]\tLoss: 0.049995\n",
      "Train Epoch: 21 [11520/12665 (91%)]\tLoss: 0.001544\n",
      "Train Epoch: 21 [12160/12665 (96%)]\tLoss: 0.000032\n",
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/12665 (0%)]\tLoss: 0.010677\n",
      "Train Epoch: 22 [640/12665 (5%)]\tLoss: 0.014710\n",
      "Train Epoch: 22 [1280/12665 (10%)]\tLoss: 0.000111\n",
      "Train Epoch: 22 [1920/12665 (15%)]\tLoss: 0.000491\n",
      "Train Epoch: 22 [2560/12665 (20%)]\tLoss: 0.078879\n",
      "Train Epoch: 22 [3200/12665 (25%)]\tLoss: 0.000818\n",
      "Train Epoch: 22 [3840/12665 (30%)]\tLoss: 0.000879\n",
      "Train Epoch: 22 [4480/12665 (35%)]\tLoss: 0.000690\n",
      "Train Epoch: 22 [5120/12665 (40%)]\tLoss: 0.000755\n",
      "Train Epoch: 22 [5760/12665 (45%)]\tLoss: 0.000515\n",
      "Train Epoch: 22 [6400/12665 (51%)]\tLoss: 0.000623\n",
      "Train Epoch: 22 [7040/12665 (56%)]\tLoss: 0.001207\n",
      "Train Epoch: 22 [7680/12665 (61%)]\tLoss: 0.000144\n",
      "Train Epoch: 22 [8320/12665 (66%)]\tLoss: 0.000059\n",
      "Train Epoch: 22 [8960/12665 (71%)]\tLoss: 0.054021\n",
      "Train Epoch: 22 [9600/12665 (76%)]\tLoss: 0.003193\n",
      "Train Epoch: 22 [10240/12665 (81%)]\tLoss: 0.000254\n",
      "Train Epoch: 22 [10880/12665 (86%)]\tLoss: 0.000192\n",
      "Train Epoch: 22 [11520/12665 (91%)]\tLoss: 0.000147\n",
      "Train Epoch: 22 [12160/12665 (96%)]\tLoss: 0.000251\n",
      "\n",
      "Test set: Avg. loss: 0.0030, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/12665 (0%)]\tLoss: 0.000692\n",
      "Train Epoch: 23 [640/12665 (5%)]\tLoss: 0.000906\n",
      "Train Epoch: 23 [1280/12665 (10%)]\tLoss: 0.000106\n",
      "Train Epoch: 23 [1920/12665 (15%)]\tLoss: 0.000327\n",
      "Train Epoch: 23 [2560/12665 (20%)]\tLoss: 0.000548\n",
      "Train Epoch: 23 [3200/12665 (25%)]\tLoss: 0.000534\n",
      "Train Epoch: 23 [3840/12665 (30%)]\tLoss: 0.001411\n",
      "Train Epoch: 23 [4480/12665 (35%)]\tLoss: 0.002582\n",
      "Train Epoch: 23 [5120/12665 (40%)]\tLoss: 0.050639\n",
      "Train Epoch: 23 [5760/12665 (45%)]\tLoss: 0.000200\n",
      "Train Epoch: 23 [6400/12665 (51%)]\tLoss: 0.000977\n",
      "Train Epoch: 23 [7040/12665 (56%)]\tLoss: 0.017636\n",
      "Train Epoch: 23 [7680/12665 (61%)]\tLoss: 0.000971\n",
      "Train Epoch: 23 [8320/12665 (66%)]\tLoss: 0.000075\n",
      "Train Epoch: 23 [8960/12665 (71%)]\tLoss: 0.001499\n",
      "Train Epoch: 23 [9600/12665 (76%)]\tLoss: 0.020466\n",
      "Train Epoch: 23 [10240/12665 (81%)]\tLoss: 0.001468\n",
      "Train Epoch: 23 [10880/12665 (86%)]\tLoss: 0.000355\n",
      "Train Epoch: 23 [11520/12665 (91%)]\tLoss: 0.000424\n",
      "Train Epoch: 23 [12160/12665 (96%)]\tLoss: 0.013827\n",
      "\n",
      "Test set: Avg. loss: 0.0029, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/12665 (0%)]\tLoss: 0.000135\n",
      "Train Epoch: 24 [640/12665 (5%)]\tLoss: 0.002131\n",
      "Train Epoch: 24 [1280/12665 (10%)]\tLoss: 0.019638\n",
      "Train Epoch: 24 [1920/12665 (15%)]\tLoss: 0.000949\n",
      "Train Epoch: 24 [2560/12665 (20%)]\tLoss: 0.000127\n",
      "Train Epoch: 24 [3200/12665 (25%)]\tLoss: 0.000130\n",
      "Train Epoch: 24 [3840/12665 (30%)]\tLoss: 0.000044\n",
      "Train Epoch: 24 [4480/12665 (35%)]\tLoss: 0.000989\n",
      "Train Epoch: 24 [5120/12665 (40%)]\tLoss: 0.001311\n",
      "Train Epoch: 24 [5760/12665 (45%)]\tLoss: 0.025731\n",
      "Train Epoch: 24 [6400/12665 (51%)]\tLoss: 0.000308\n",
      "Train Epoch: 24 [7040/12665 (56%)]\tLoss: 0.000059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [7680/12665 (61%)]\tLoss: 0.000039\n",
      "Train Epoch: 24 [8320/12665 (66%)]\tLoss: 0.001427\n",
      "Train Epoch: 24 [8960/12665 (71%)]\tLoss: 0.000429\n",
      "Train Epoch: 24 [9600/12665 (76%)]\tLoss: 0.000083\n",
      "Train Epoch: 24 [10240/12665 (81%)]\tLoss: 0.001090\n",
      "Train Epoch: 24 [10880/12665 (86%)]\tLoss: 0.003407\n",
      "Train Epoch: 24 [11520/12665 (91%)]\tLoss: 0.000250\n",
      "Train Epoch: 24 [12160/12665 (96%)]\tLoss: 0.000063\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/12665 (0%)]\tLoss: 0.000224\n",
      "Train Epoch: 25 [640/12665 (5%)]\tLoss: 0.000426\n",
      "Train Epoch: 25 [1280/12665 (10%)]\tLoss: 0.000334\n",
      "Train Epoch: 25 [1920/12665 (15%)]\tLoss: 0.002926\n",
      "Train Epoch: 25 [2560/12665 (20%)]\tLoss: 0.000579\n",
      "Train Epoch: 25 [3200/12665 (25%)]\tLoss: 0.000208\n",
      "Train Epoch: 25 [3840/12665 (30%)]\tLoss: 0.000199\n",
      "Train Epoch: 25 [4480/12665 (35%)]\tLoss: 0.001616\n",
      "Train Epoch: 25 [5120/12665 (40%)]\tLoss: 0.026375\n",
      "Train Epoch: 25 [5760/12665 (45%)]\tLoss: 0.000629\n",
      "Train Epoch: 25 [6400/12665 (51%)]\tLoss: 0.000294\n",
      "Train Epoch: 25 [7040/12665 (56%)]\tLoss: 0.002578\n",
      "Train Epoch: 25 [7680/12665 (61%)]\tLoss: 0.002937\n",
      "Train Epoch: 25 [8320/12665 (66%)]\tLoss: 0.000516\n",
      "Train Epoch: 25 [8960/12665 (71%)]\tLoss: 0.000267\n",
      "Train Epoch: 25 [9600/12665 (76%)]\tLoss: 0.001748\n",
      "Train Epoch: 25 [10240/12665 (81%)]\tLoss: 0.000014\n",
      "Train Epoch: 25 [10880/12665 (86%)]\tLoss: 0.000942\n",
      "Train Epoch: 25 [11520/12665 (91%)]\tLoss: 0.002394\n",
      "Train Epoch: 25 [12160/12665 (96%)]\tLoss: 0.001006\n",
      "\n",
      "Test set: Avg. loss: 0.0034, Accuracy: 2112/2115 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/12665 (0%)]\tLoss: 0.003180\n",
      "Train Epoch: 26 [640/12665 (5%)]\tLoss: 0.000010\n",
      "Train Epoch: 26 [1280/12665 (10%)]\tLoss: 0.000207\n",
      "Train Epoch: 26 [1920/12665 (15%)]\tLoss: 0.001545\n",
      "Train Epoch: 26 [2560/12665 (20%)]\tLoss: 0.000267\n",
      "Train Epoch: 26 [3200/12665 (25%)]\tLoss: 0.000717\n",
      "Train Epoch: 26 [3840/12665 (30%)]\tLoss: 0.000076\n",
      "Train Epoch: 26 [4480/12665 (35%)]\tLoss: 0.000324\n",
      "Train Epoch: 26 [5120/12665 (40%)]\tLoss: 0.000190\n",
      "Train Epoch: 26 [5760/12665 (45%)]\tLoss: 0.001109\n",
      "Train Epoch: 26 [6400/12665 (51%)]\tLoss: 0.000168\n",
      "Train Epoch: 26 [7040/12665 (56%)]\tLoss: 0.000078\n",
      "Train Epoch: 26 [7680/12665 (61%)]\tLoss: 0.000035\n",
      "Train Epoch: 26 [8320/12665 (66%)]\tLoss: 0.002387\n",
      "Train Epoch: 26 [8960/12665 (71%)]\tLoss: 0.001277\n",
      "Train Epoch: 26 [9600/12665 (76%)]\tLoss: 0.000295\n",
      "Train Epoch: 26 [10240/12665 (81%)]\tLoss: 0.000044\n",
      "Train Epoch: 26 [10880/12665 (86%)]\tLoss: 0.000225\n",
      "Train Epoch: 26 [11520/12665 (91%)]\tLoss: 0.009082\n",
      "Train Epoch: 26 [12160/12665 (96%)]\tLoss: 0.000626\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/12665 (0%)]\tLoss: 0.000272\n",
      "Train Epoch: 27 [640/12665 (5%)]\tLoss: 0.000336\n",
      "Train Epoch: 27 [1280/12665 (10%)]\tLoss: 0.026199\n",
      "Train Epoch: 27 [1920/12665 (15%)]\tLoss: 0.001141\n",
      "Train Epoch: 27 [2560/12665 (20%)]\tLoss: 0.017482\n",
      "Train Epoch: 27 [3200/12665 (25%)]\tLoss: 0.000272\n",
      "Train Epoch: 27 [3840/12665 (30%)]\tLoss: 0.000144\n",
      "Train Epoch: 27 [4480/12665 (35%)]\tLoss: 0.008728\n",
      "Train Epoch: 27 [5120/12665 (40%)]\tLoss: 0.000943\n",
      "Train Epoch: 27 [5760/12665 (45%)]\tLoss: 0.000025\n",
      "Train Epoch: 27 [6400/12665 (51%)]\tLoss: 0.000262\n",
      "Train Epoch: 27 [7040/12665 (56%)]\tLoss: 0.000399\n",
      "Train Epoch: 27 [7680/12665 (61%)]\tLoss: 0.001660\n",
      "Train Epoch: 27 [8320/12665 (66%)]\tLoss: 0.000070\n",
      "Train Epoch: 27 [8960/12665 (71%)]\tLoss: 0.000492\n",
      "Train Epoch: 27 [9600/12665 (76%)]\tLoss: 0.000037\n",
      "Train Epoch: 27 [10240/12665 (81%)]\tLoss: 0.000213\n",
      "Train Epoch: 27 [10880/12665 (86%)]\tLoss: 0.002389\n",
      "Train Epoch: 27 [11520/12665 (91%)]\tLoss: 0.002630\n",
      "Train Epoch: 27 [12160/12665 (96%)]\tLoss: 0.001817\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2113/2115 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/12665 (0%)]\tLoss: 0.000047\n",
      "Train Epoch: 28 [640/12665 (5%)]\tLoss: 0.000181\n",
      "Train Epoch: 28 [1280/12665 (10%)]\tLoss: 0.000106\n",
      "Train Epoch: 28 [1920/12665 (15%)]\tLoss: 0.000141\n",
      "Train Epoch: 28 [2560/12665 (20%)]\tLoss: 0.000227\n",
      "Train Epoch: 28 [3200/12665 (25%)]\tLoss: 0.000197\n",
      "Train Epoch: 28 [3840/12665 (30%)]\tLoss: 0.000390\n",
      "Train Epoch: 28 [4480/12665 (35%)]\tLoss: 0.001224\n",
      "Train Epoch: 28 [5120/12665 (40%)]\tLoss: 0.000258\n",
      "Train Epoch: 28 [5760/12665 (45%)]\tLoss: 0.001085\n",
      "Train Epoch: 28 [6400/12665 (51%)]\tLoss: 0.000559\n",
      "Train Epoch: 28 [7040/12665 (56%)]\tLoss: 0.000026\n",
      "Train Epoch: 28 [7680/12665 (61%)]\tLoss: 0.000161\n",
      "Train Epoch: 28 [8320/12665 (66%)]\tLoss: 0.001161\n",
      "Train Epoch: 28 [8960/12665 (71%)]\tLoss: 0.000615\n",
      "Train Epoch: 28 [9600/12665 (76%)]\tLoss: 0.001581\n",
      "Train Epoch: 28 [10240/12665 (81%)]\tLoss: 0.000405\n",
      "Train Epoch: 28 [10880/12665 (86%)]\tLoss: 0.000494\n",
      "Train Epoch: 28 [11520/12665 (91%)]\tLoss: 0.000356\n",
      "Train Epoch: 28 [12160/12665 (96%)]\tLoss: 0.000446\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/12665 (0%)]\tLoss: 0.001512\n",
      "Train Epoch: 29 [640/12665 (5%)]\tLoss: 0.000260\n",
      "Train Epoch: 29 [1280/12665 (10%)]\tLoss: 0.000031\n",
      "Train Epoch: 29 [1920/12665 (15%)]\tLoss: 0.002100\n",
      "Train Epoch: 29 [2560/12665 (20%)]\tLoss: 0.003467\n",
      "Train Epoch: 29 [3200/12665 (25%)]\tLoss: 0.000045\n",
      "Train Epoch: 29 [3840/12665 (30%)]\tLoss: 0.000026\n",
      "Train Epoch: 29 [4480/12665 (35%)]\tLoss: 0.002236\n",
      "Train Epoch: 29 [5120/12665 (40%)]\tLoss: 0.000265\n",
      "Train Epoch: 29 [5760/12665 (45%)]\tLoss: 0.000115\n",
      "Train Epoch: 29 [6400/12665 (51%)]\tLoss: 0.000037\n",
      "Train Epoch: 29 [7040/12665 (56%)]\tLoss: 0.000535\n",
      "Train Epoch: 29 [7680/12665 (61%)]\tLoss: 0.000442\n",
      "Train Epoch: 29 [8320/12665 (66%)]\tLoss: 0.000071\n",
      "Train Epoch: 29 [8960/12665 (71%)]\tLoss: 0.000219\n",
      "Train Epoch: 29 [9600/12665 (76%)]\tLoss: 0.000057\n",
      "Train Epoch: 29 [10240/12665 (81%)]\tLoss: 0.000390\n",
      "Train Epoch: 29 [10880/12665 (86%)]\tLoss: 0.000579\n",
      "Train Epoch: 29 [11520/12665 (91%)]\tLoss: 0.000436\n",
      "Train Epoch: 29 [12160/12665 (96%)]\tLoss: 0.000049\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2114/2115 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/12665 (0%)]\tLoss: 0.000988\n",
      "Train Epoch: 30 [640/12665 (5%)]\tLoss: 0.000110\n",
      "Train Epoch: 30 [1280/12665 (10%)]\tLoss: 0.000702\n",
      "Train Epoch: 30 [1920/12665 (15%)]\tLoss: 0.000347\n",
      "Train Epoch: 30 [2560/12665 (20%)]\tLoss: 0.000026\n",
      "Train Epoch: 30 [3200/12665 (25%)]\tLoss: 0.000753\n",
      "Train Epoch: 30 [3840/12665 (30%)]\tLoss: 0.000051\n",
      "Train Epoch: 30 [4480/12665 (35%)]\tLoss: 0.000424\n",
      "Train Epoch: 30 [5120/12665 (40%)]\tLoss: 0.001073\n",
      "Train Epoch: 30 [5760/12665 (45%)]\tLoss: 0.000306\n",
      "Train Epoch: 30 [6400/12665 (51%)]\tLoss: 0.002339\n",
      "Train Epoch: 30 [7040/12665 (56%)]\tLoss: 0.000230\n",
      "Train Epoch: 30 [7680/12665 (61%)]\tLoss: 0.001001\n",
      "Train Epoch: 30 [8320/12665 (66%)]\tLoss: 0.000405\n",
      "Train Epoch: 30 [8960/12665 (71%)]\tLoss: 0.010877\n",
      "Train Epoch: 30 [9600/12665 (76%)]\tLoss: 0.000346\n",
      "Train Epoch: 30 [10240/12665 (81%)]\tLoss: 0.000980\n",
      "Train Epoch: 30 [10880/12665 (86%)]\tLoss: 0.000011\n",
      "Train Epoch: 30 [11520/12665 (91%)]\tLoss: 0.000402\n",
      "Train Epoch: 30 [12160/12665 (96%)]\tLoss: 0.000060\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2114/2115 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net_c2 = Net_c2().cuda()\n",
    "n_epochs = 30\n",
    "optimizer = optim.SGD(net_c2.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader2.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "test(net_c2, test_loader2)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(net_c2, train_loader2, epoch)\n",
    "    test(net_c2, test_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiqi/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00863144, 0.        , 0.00215786, 0.00215786, 0.00215786,\n",
       "        0.00431572, 0.        , 0.00431572, 0.0107893 , 0.        ,\n",
       "        0.00863144, 0.01510503, 0.0107893 , 0.00647358, 0.00647358,\n",
       "        0.02373647, 0.01294716, 0.01510503, 0.01942075, 0.02805219,\n",
       "        0.03021005, 0.03884149, 0.0496308 , 0.0604201 , 0.03884149,\n",
       "        0.06905155, 0.09494588, 0.07768299, 0.08415657, 0.15320812,\n",
       "        0.12731379, 0.14673453, 0.12515593, 0.18126031, 0.16615528,\n",
       "        0.15752384, 0.14241881, 0.18773389, 0.15752384, 0.16183956,\n",
       "        0.170471  , 0.14457667, 0.12731379, 0.14673453, 0.14457667,\n",
       "        0.13810309, 0.10357732, 0.12731379, 0.08199871, 0.08631443,\n",
       "        0.09278801, 0.06257796, 0.0604201 , 0.0496308 , 0.0496308 ,\n",
       "        0.02589433, 0.03236791, 0.03668363, 0.02805219, 0.03021005,\n",
       "        0.02157861, 0.02589433, 0.01294716, 0.02373647, 0.00431572,\n",
       "        0.00647358, 0.0107893 , 0.00647358, 0.        , 0.00647358,\n",
       "        0.00647358, 0.00215786, 0.00215786, 0.00431572, 0.00215786,\n",
       "        0.00215786, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00431572, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00215786]),\n",
       " array([ 4.52634799,  4.75805896,  4.98976992,  5.22148088,  5.45319184,\n",
       "         5.6849028 ,  5.91661376,  6.14832472,  6.38003568,  6.61174664,\n",
       "         6.8434576 ,  7.07516856,  7.30687952,  7.53859048,  7.77030144,\n",
       "         8.0020124 ,  8.23372337,  8.46543433,  8.69714529,  8.92885625,\n",
       "         9.16056721,  9.39227817,  9.62398913,  9.85570009, 10.08741105,\n",
       "        10.31912201, 10.55083297, 10.78254393, 11.01425489, 11.24596585,\n",
       "        11.47767681, 11.70938778, 11.94109874, 12.1728097 , 12.40452066,\n",
       "        12.63623162, 12.86794258, 13.09965354, 13.3313645 , 13.56307546,\n",
       "        13.79478642, 14.02649738, 14.25820834, 14.4899193 , 14.72163026,\n",
       "        14.95334123, 15.18505219, 15.41676315, 15.64847411, 15.88018507,\n",
       "        16.11189603, 16.34360699, 16.57531795, 16.80702891, 17.03873987,\n",
       "        17.27045083, 17.50216179, 17.73387275, 17.96558371, 18.19729467,\n",
       "        18.42900564, 18.6607166 , 18.89242756, 19.12413852, 19.35584948,\n",
       "        19.58756044, 19.8192714 , 20.05098236, 20.28269332, 20.51440428,\n",
       "        20.74611524, 20.9778262 , 21.20953716, 21.44124812, 21.67295908,\n",
       "        21.90467005, 22.13638101, 22.36809197, 22.59980293, 22.83151389,\n",
       "        23.06322485, 23.29493581, 23.52664677, 23.75835773, 23.99006869,\n",
       "        24.22177965, 24.45349061, 24.68520157, 24.91691253, 25.1486235 ,\n",
       "        25.38033446, 25.61204542, 25.84375638, 26.07546734, 26.3071783 ,\n",
       "        26.53888926, 26.77060022, 27.00231118, 27.23402214, 27.4657331 ,\n",
       "        27.69744406]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFF5JREFUeJzt3X+s3fV93/HnqyamU7ekBG4napvZGa42EiQ6jBupC+oSQZ2ljakKwQg1ICG5rWpp+6NRnGkhmUckmLZFq4ayOIUEKMRhZJQr4chNRNJNW8p8IQgwiOXieHBjFpxAUtIksBve++N8zA4n93K/5/72Pc+HdHS/5/P9fD/n8/366/s6n8/3nO9NVSFJ0s+tdAckSauDgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSc1pK92BYZx11lm1efPmle6GJJ1SHnrooe9W1dhc9U6pQNi8eTMTExMr3Q1JOqUk+d9d6jllJEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQJOsW8qa7Rt3nv/a8vHbnzfCvZEWpscIUiSAANBktQYCJIkwECQJDUGgiQJMBAkSY0fO9WK6P8IKfgxUmk1cIQgSQIMBElS0ykQkuxI8lSSySR7Z1h/cZKHk0wnubyv/J8keaTv8ZMkl7V1n0vyrb51FyzebkmShjXnNYQk64CbgUuAKeBwkvGqeqKv2jPAtcAf929bVV8FLmjtvBWYBP6ir8qHquqeheyAJGlxdLmovB2YrKqjAEkOADuB1wKhqo61da++QTuXA1+qqh/Nu7eSpCXTZcpoA/Bs3/OpVjasXcDnB8o+keTRJJ9Mcvo82pQkLZIugZAZymqYF0lyNnA+cKiv+CPAPwAuAt4KfHiWbXcnmUgyceLEiWFeVpI0hC6BMAVs6nu+ETg+5Ot8ALi3qv7vyYKqeq56XgY+S29q6mdU1f6q2lZV28bGxoZ8WUlSV10C4TCwNcmWJOvpTf2MD/k6VzEwXdRGDSQJcBnw+JBtSpIW0ZyBUFXTwB560z1PAndX1ZEk+5K8HyDJRUmmgCuATyc5cnL7JJvpjTD+cqDpO5M8BjwGnAXcsPDdkSTNV6dbV1TVQeDgQNn1fcuH6U0lzbTtMWa4CF1V7x6mo5KkpeW9jLSm+Gc2pfnz1hWSJMBAkCQ1BoIkCTAQJEmNF5W1KngxWFp5jhAkSYCBIElqDARJEuA1BK0B/dcfJM2fIwRJEmAgSJIaA0GSBBgIkqTGi8padbp8Sc0LydLic4QgSQIMBElSYyBIkgADQZLUdAqEJDuSPJVkMsneGdZfnOThJNNJLh9Y99Mkj7THeF/5liQPJvlmki8kWb/w3dFK2bz3/tcekk5NcwZCknXAzcB7gfOAq5KcN1DtGeBa4K4ZmvhxVV3QHu/vK78J+GRVbQVeBK6bR/8lSYukywhhOzBZVUer6hXgALCzv0JVHauqR4FXu7xokgDvBu5pRbcBl3XutSRp0XUJhA3As33Pp1pZVz+fZCLJXyU5+Uv/TOD7VTU9V5tJdrftJ06cODHEy0qShtHli2mZoayGeI1zqup4krcBDyR5DPjrrm1W1X5gP8C2bduGeV1J0hC6jBCmgE19zzcCx7u+QFUdbz+PAl8DfhX4LvCLSU4G0lBtSpIWX5dAOAxsbZ8KWg/sAsbn2AaAJGckOb0tnwX8OvBEVRXwVeDkJ5KuAe4btvOSpMUz55RRVU0n2QMcAtYBt1bVkST7gImqGk9yEXAvcAbw20n+VVW9HfiHwKeTvEovfG6sqida0x8GDiS5AfgGcMui751WXJf7Ei231dgnaTXodHO7qjoIHBwou75v+TC9aZ/B7f4HcP4sbR6l9wkmSdIq4N1OtWYNe9dURwsadd66QpIEGAiSpMYpI61q3htJWj6OECRJgIEgSWoMBEkS4DUE6TV+BFWjzhGCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJElNp0BIsiPJU0kmk+ydYf3FSR5OMp3k8r7yC5J8PcmRJI8mubJv3eeSfCvJI+1xweLskiRpPua8l1GSdcDNwCXAFHA4yXhVPdFX7RngWuCPBzb/EfDBqvpmkl8GHkpyqKq+39Z/qKruWehOaHVZjX/DYCF98h5HGhVdbm63HZisqqMASQ4AO4HXAqGqjrV1r/ZvWFX/q2/5eJLngTHg+0iSVpUuU0YbgGf7nk+1sqEk2Q6sB57uK/5Em0r6ZJLTh21TkrR4uowQMkNZDfMiSc4G7gCuqaqTo4iPAP+HXkjsBz4M7Jth293AboBzzjlnmJfVKrMap5Ik/X9dRghTwKa+5xuB411fIMmbgfuBf1lVf3WyvKqeq56Xgc/Sm5r6GVW1v6q2VdW2sbGxri8rSRpSl0A4DGxNsiXJemAXMN6l8Vb/XuD2qvrPA+vObj8DXAY8PkzHJUmLa85AqKppYA9wCHgSuLuqjiTZl+T9AEkuSjIFXAF8OsmRtvkHgIuBa2f4eOmdSR4DHgPOAm5Y1D2TJA2l05/QrKqDwMGBsuv7lg/Tm0oa3O7PgD+bpc13D9VTSdKS8pvKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJ6BgISXYkeSrJZJK9M6y/OMnDSaaTXD6w7pok32yPa/rKL0zyWGvzT5Jk4bsjLY7Ne+9/7SGNijkDIck64GbgvcB5wFVJzhuo9gxwLXDXwLZvBT4G/BqwHfhYkjPa6k8Bu4Gt7bFj3nshSVqwLiOE7cBkVR2tqleAA8DO/gpVdayqHgVeHdj2N4EvV9ULVfUi8GVgR5KzgTdX1derqoDbgcsWujOSpPnrEggbgGf7nk+1si5m23ZDW56zzSS7k0wkmThx4kTHl5UkDatLIMw0t18d259t285tVtX+qtpWVdvGxsY6vqwkaVhdAmEK2NT3fCNwvGP7s2071Zbn06YkaQl0CYTDwNYkW5KsB3YB4x3bPwRcmuSMdjH5UuBQVT0HvJTkne3TRR8E7ptH/yVJi2TOQKiqaWAPvV/uTwJ3V9WRJPuSvB8gyUVJpoArgE8nOdK2fQH41/RC5TCwr5UB/CHwp8Ak8DTwpUXdM0nSUE7rUqmqDgIHB8qu71s+zOungPrr3QrcOkP5BPCOYTorSVo6nQJBo63/y1nHbnzfCvZE0lLy1hWSJMARgrQoHEVpLXCEIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAnwewjSvPnnNbXWOEKQJAGOELQAvkOW1hZHCJIkwBGCNBRHRVrLHCFIkgADQZLUGAiSJKBjICTZkeSpJJNJ9s6w/vQkX2jrH0yyuZVfneSRvserSS5o677W2jy57pcWc8ckScOZ86JyknXAzcAlwBRwOMl4VT3RV+064MWqOjfJLuAm4MqquhO4s7VzPnBfVT3St93V7W8r6xThRVVp7eoyQtgOTFbV0ap6BTgA7ByosxO4rS3fA7wnSQbqXAV8fiGdlSQtnS6BsAF4tu/5VCubsU5VTQM/AM4cqHMlPxsIn23TRR+dIUAkScuoSyDM9Iu6hqmT5NeAH1XV433rr66q84F3tcfvzfjiye4kE0kmTpw40aG7kqT56BIIU8CmvucbgeOz1UlyGvAW4IW+9bsYGB1U1bfbz5eAu+hNTf2MqtpfVduqatvY2FiH7kqS5qNLIBwGtibZkmQ9vV/u4wN1xoFr2vLlwANVVQBJfg64gt61B1rZaUnOastvAn4LeBxJ0oqZ81NGVTWdZA9wCFgH3FpVR5LsAyaqahy4BbgjySS9kcGuviYuBqaq6mhf2enAoRYG64CvAJ9ZlD2SJM1Lp3sZVdVB4OBA2fV9yz+hNwqYaduvAe8cKPsb4MIh+ypJWkJ+U1mSBBgIkqTG219rRn4jWRo9jhAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGj51Ki6z/I7vHbnzfCvZEGo4jBEkS4Ahh5Pludml5fHUqcYQgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCegYCEl2JHkqyWSSvTOsPz3JF9r6B5NsbuWbk/w4ySPt8Z/6trkwyWNtmz9JksXaKUnS8OYMhCTrgJuB9wLnAVclOW+g2nXAi1V1LvBJ4Ka+dU9X1QXt8Qd95Z8CdgNb22PH/HdDkrRQXUYI24HJqjpaVa8AB4CdA3V2Are15XuA97zRO/4kZwNvrqqvV1UBtwOXDd17SdKi6RIIG4Bn+55PtbIZ61TVNPAD4My2bkuSbyT5yyTv6qs/NUebkqRl1OVeRjO906+OdZ4Dzqmq7yW5EPjzJG/v2Gav4WQ3vaklzjnnnA7d1Vz676+j5TPbcfceR1otuowQpoBNfc83Asdnq5PkNOAtwAtV9XJVfQ+gqh4CngZ+pdXfOEebtO32V9W2qto2NjbWobuSpPnoEgiHga1JtiRZD+wCxgfqjAPXtOXLgQeqqpKMtYvSJHkbvYvHR6vqOeClJO9s1xo+CNy3CPsjSZqnOaeMqmo6yR7gELAOuLWqjiTZB0xU1ThwC3BHkkngBXqhAXAxsC/JNPBT4A+q6oW27g+BzwF/C/hSe0iSVkinv4dQVQeBgwNl1/ct/wS4Yobtvgh8cZY2J4B3DNNZSdLS8ZvKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkoCO30PQqa/L/Yu8x5E02hwhSJIARwjSqtY/avOuqFpqjhAkSYCBIElqDARJEmAgSJIaLypLq4gf/dVKcoQgSQIcIaxpvttcu/w4qpaCIwRJEmAgSJKaTlNGSXYA/wFYB/xpVd04sP504HbgQuB7wJVVdSzJJcCNwHrgFeBDVfVA2+ZrwNnAj1szl1bV8wveoxHnNNHa5b+tltqcgZBkHXAzcAkwBRxOMl5VT/RVuw54sarOTbILuAm4Evgu8NtVdTzJO4BDwIa+7a6uqolF2hdJ0gJ0GSFsByar6ihAkgPATqA/EHYCH2/L9wD/MUmq6ht9dY4AP5/k9Kp6ecE9l9aIxXzn78VmLUSXawgbgGf7nk/x+nf5r6tTVdPAD4AzB+r8LvCNgTD4bJJHknw0SWZ68SS7k0wkmThx4kSH7kqS5qNLIMz0i7qGqZPk7fSmkX6/b/3VVXU+8K72+L2ZXryq9lfVtqraNjY21qG7kqT56DJlNAVs6nu+ETg+S52pJKcBbwFeAEiyEbgX+GBVPX1yg6r6dvv5UpK76E1N3T7P/ViznALQYvA8UhddRgiHga1JtiRZD+wCxgfqjAPXtOXLgQeqqpL8InA/8JGq+u8nKyc5LclZbflNwG8Bjy9sVyRJCzHnCKGqppPsofcJoXXArVV1JMk+YKKqxoFbgDuSTNIbGexqm+8BzgU+muSjrexS4G+AQy0M1gFfAT6ziPsljQw/jqrF0ul7CFV1EDg4UHZ93/JPgCtm2O4G4IZZmr2wezclSUvNexmtAb5DlLQYvHWFJAkwECRJjYEgSQIMBElS40XlZbZYXxDyQrKkxeYIQZIEGAiSpMYpo1OI00QahueLhuUIQZIEOEJYNPO5WOwdKLWaeD7KEYIkCRihEcJKvftxHlfSqcIRgiQJMBAkSc3ITBmtdk4taSXMdt7NNsU6W30vQq8NjhAkSYAjhE6GfbckrWbLed4u1Yc5/Ijs0ug0QkiyI8lTSSaT7J1h/elJvtDWP5hkc9+6j7Typ5L8Ztc2JUnLa84RQpJ1wM3AJcAUcDjJeFU90VftOuDFqjo3yS7gJuDKJOcBu4C3A78MfCXJr7Rt5mpzWfguX1q4Lv+PvP4wnJUYBXUZIWwHJqvqaFW9AhwAdg7U2Qnc1pbvAd6TJK38QFW9XFXfAiZbe13alCQtoy6BsAF4tu/5VCubsU5VTQM/AM58g227tClJWkZdLipnhrLqWGe28pmCaLDNXsPJbmB3e/rDJE/N0s/OctPrnp4FfHee2867zio01HFYwzwOA8dgqc/nhba/hP1bNefCIuzj3+tSqUsgTAGb+p5vBI7PUmcqyWnAW4AX5th2rjYBqKr9wP4O/ZyXJBNVtW2p2j9VeBx6PA4eg5NG8Th0mTI6DGxNsiXJenoXiccH6owD17Tly4EHqqpa+a72KaQtwFbgf3ZsU5K0jOYcIVTVdJI9wCFgHXBrVR1Jsg+YqKpx4BbgjiST9EYGu9q2R5LcDTwBTAN/VFU/BZipzcXfPUlSV+m9kR9dSXa3aamR5nHo8Th4DE4axeMw8oEgSerxXkaSJGDEAyHJsSSPJXkkycRK92e5JLk1yfNJHu8re2uSLyf5Zvt5xkr2canNcgw+nuTb7Xx4JMk/Xck+Lockm5J8NcmTSY4k+WetfGTOhzc4BqN3PozylFGSY8C2qloVnzVeLkkuBn4I3F5V72hl/wZ4oapubPeWOqOqPryS/VxKsxyDjwM/rKp/u5J9W05JzgbOrqqHk/wd4CHgMuBaRuR8eINj8AFG7HwY6RHCqKqq/0rv02D9+m8/chu9/xBr1izHYORU1XNV9XBbfgl4kt5dA0bmfHiDYzByRj0QCviLJA+1b0SPsr9bVc9B7z8I8Esr3J+VsifJo21Kac1Ok8yk3aX4V4EHGdHzYeAYwIidD6MeCL9eVf8IeC/wR20aQaPrU8DfBy4AngP+3cp2Z/kk+dvAF4F/XlV/vdL9WQkzHIOROx9GOhCq6nj7+TxwL727sI6q77S51JNzqs+vcH+WXVV9p6p+WlWvAp9hRM6HJG+i94vwzqr6L614pM6HmY7BKJ4PIxsISX6hXUAiyS8AlwKPv/FWa1r/7UeuAe5bwb6siJO/AJvfYQTOh3ab+luAJ6vq3/etGpnzYbZjMJLnw6h+yijJ2+iNCqB3C4+7quoTK9ilZZPk88Bv0Lub43eAjwF/DtwNnAM8A1xRVWv2oussx+A36E0PFHAM+P2T8+hrVZJ/DPw34DHg1Vb8L+jNoY/E+fAGx+AqRu18GNVAkCS93shOGUmSXs9AkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgTA/wMYsbJRmvHx6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = net_c2(noise.cuda())\n",
    "ll = net_c2.last\n",
    "print(ll.shape)\n",
    "ll = ll.cpu().detach().numpy() \n",
    "lid_net1_c2 = LID(ll, ll, k=50)\n",
    "plt.hist(lid_net1_c2, bins=100, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
